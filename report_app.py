import streamlit as st
import pandas as pd
import openai
from datetime import datetime, timedelta, date
import json
import re
from typing import Dict, List, Tuple
import base64
from io import BytesIO
import numpy as np
import sqlite3
import pickle
from pathlib import Path
import hashlib # ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆç”¨ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from dotenv import load_dotenv # è¿½åŠ 
import os # è¿½åŠ 
import pytz # æ—¥æœ¬æ™‚é–“å–å¾—ç”¨ã«è¿½åŠ 

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
import pathlib
script_dir = pathlib.Path(__file__).parent.absolute()
env_path = script_dir / '.env'
load_dotenv(dotenv_path=env_path)

# ç’°å¢ƒå¤‰æ•°ã®å†èª­ã¿è¾¼ã¿ã‚’å¼·åˆ¶
import importlib
import sys
if 'dotenv' in sys.modules:
    importlib.reload(sys.modules['dotenv'])
load_dotenv(dotenv_path=env_path, override=True)

def get_japan_time():
    """æ—¥æœ¬æ™‚é–“ã®ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—ã™ã‚‹"""
    jst = pytz.timezone('Asia/Tokyo')
    return datetime.now(jst)

# --- Streamlitã‚¢ãƒ—ãƒªã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š ---
# ã‚¢ãƒ—ãƒªå…¨ä½“ã®èƒŒæ™¯ã‚’ç™½ã€æ–‡å­—ã‚’é»’ã«è¨­å®š
st.markdown(
    """
    <style>
    body {
        background-color: white !important;
        color: black !important;
    }
    .stApp {
        background-color: white !important;
        color: black !important;
    }
    /* Streamlitã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®è¦‹ãŸç›®ã‚’ã•ã‚‰ã«èª¿æ•´ */
    h1, h2, h3, h4, h5, h6, strong, p, div, span, label {
        color: black !important;
    }
    div[data-testid="stSidebar"] {
        background-color: #f0f0f0 !important; /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®èƒŒæ™¯ã‚’å°‘ã—è–„ã„ã‚°ãƒ¬ãƒ¼ã« (å¥½ã¿ã§èª¿æ•´) */
        color: black !important;
    }
    .stTextInput label, .stTextArea label, .stSelectbox label {
        color: black !important;
    }
    textarea {
        background-color: white !important;
        color: black !important;
        border: 1px solid #ccc !important;
        border-radius: 5px !important;
        padding: 10px !important;
    }
    textarea[disabled] { /* èª­ã¿å–ã‚Šå°‚ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã®ã‚¹ã‚¿ã‚¤ãƒ« */
        background-color: #f9f9f9 !important;
        color: #555 !important;
        opacity: 0.8 !important;
    }
    input[type="text"] {
        background-color: white !important;
        color: black !important;
        border: 1px solid #ccc !important;
        border-radius: 5px !important;
        padding: 10px !important;
    }
    /* ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    button {
        background-color: #007bff !important;
        color: white !important;
        border-radius: 5px !important;
        padding: 8px 15px !important;
        transition: background-color 0.2s !important;
        border: none !important;
    }
    button:hover {
        background-color: #0056b3 !important;
    }
    button[data-testid="stFormSubmitButton"] {
        background-color: #28a745 !important;
    }
    button[data-testid="stFormSubmitButton"]:hover {
        background-color: #218838 !important;
    }
    /* æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è‰² */
    div[data-testid="stAlert"] div[role="alert"].streamlit-success {
        background-color: #d4edda !important;
        color: #155724 !important;
        border-color: #c3e6cb !important;
    }
    /* è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è‰² */
    div[data-testid="stAlert"] div[role="alert"].streamlit-warning {
        background-color: #fff3cd !important;
        color: #856404 !important;
        border-color: #ffeeba !important;
    }
    /* ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è‰² */
    div[data-testid="stAlert"] div[role="alert"].streamlit-error {
        background-color: #f8d7da !important;
        color: #721c24 !important;
        border-color: #f5c6cb !important;
    }
    .css-1ht1j8x { /* ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®èƒŒæ™¯ã‚’ç™½ã« */
        background-color: white !important;
        border-radius: 0.5rem;
        padding: 1rem;
        box-shadow: 0 0.125rem 0.25rem rgba(0, 0, 0, 0.075) !important;
        border: 1px solid #e0e0e0;
    }
    /* ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®èƒŒæ™¯ã‚’ç™½ã«è¨­å®š */
    .react-datepicker {
        background-color: white !important;
        color: black !important; /* ãƒ†ã‚­ã‚¹ãƒˆè‰²ã‚‚é»’ã« */
    }
    .react-datepicker__header {
        background-color: white !important;
        color: black !important;
    }
    .react-datepicker__month-container {
        background-color: white !important;
        color: black !important;
    }
    .react-datepicker__day-name, .react-datepicker__day, .react-datepicker__time-name {
        color: black !important;
    }
    .react-datepicker__current-month {
        color: black !important;
    }
    .react-datepicker__navigation--previous, .react-datepicker__navigation--next {
        color: black !important;
    }
    /* é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã®èƒŒæ™¯è‰²ã‚’èµ¤ã€æ–‡å­—è‰²ã‚’ç™½ã«è¨­å®š */
    .react-datepicker__day--selected,
    .react-datepicker__day--range-start,
    .react-datepicker__day--range-end,
    .react-datepicker__day--in-range {
        background-color: #ff4b4b !important; /* Streamlitã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆèµ¤è‰²ã«è¿‘ã¥ã‘ã‚‹ */
        color: white !important;
    }
    /* ãƒ›ãƒãƒ¼æ™‚ã®æ—¥ä»˜ã®èƒŒæ™¯è‰² */
    .react-datepicker__day:hover {
        background-color: #e0e0e0 !important; /* ãƒ›ãƒãƒ¼æ™‚ã®èƒŒæ™¯è‰²ã‚’è–„ã„ã‚°ãƒ¬ãƒ¼ã« */
        color: black !important;
    }
    /* é¸æŠã§ããªã„æ—¥ä»˜ï¼ˆéå»ã‚„æœªæ¥ã§min/max_valueå¤–ï¼‰ã®æ–‡å­—è‰² */
    .react-datepicker__day--disabled {
        color: #ccc !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)
# --- ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®šã“ã“ã¾ã§ ---

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚¢ãƒ‘ãƒ¬ãƒ«åº—èˆ—é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸª",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
DB_PATH = 'apparel_reports.db' # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«åå¤‰æ›´

class DBManager:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã¨æ“ä½œã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self, db_path: str = DB_PATH):
        self.db_path = db_path
        self._init_db()

    def _get_connection(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ç¢ºç«‹ã—ã€Rowãƒ•ã‚¡ã‚¯ãƒˆãƒªã‚’è¨­å®šã—ã¾ã™ã€‚"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row # ã‚«ãƒ©ãƒ åã§ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
        return conn

    def _init_db(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚æŒ‡å®šã•ã‚ŒãŸåº—èˆ—åã®ã¿ã‚’ç™»éŒ²ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        with conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS stores (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT NOT NULL UNIQUE
                );
            ''')
            conn.execute('''
                CREATE TABLE IF NOT EXISTS weekly_reports (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    store_id INTEGER NOT NULL,
                    monday_date TEXT NOT NULL, --YYYY-MM-DDå½¢å¼
                    
                    daily_reports_json TEXT,    -- å„æ›œæ—¥ã®å‹•å‘ã¨è¦å› ã‚’JSONæ–‡å­—åˆ—ã§ä¿å­˜
                    topics TEXT,
                    impact_day TEXT,
                    quantitative_data TEXT,
                    
                    generated_report_json TEXT, -- AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆï¼ˆå‹•å‘ã€è¦å› ã€è³ªå•ï¼‰ã‚’JSONã§ä¿å­˜
                    modified_report_json TEXT,  -- ä¿®æ­£å¾Œã®ãƒ¬ãƒãƒ¼ãƒˆï¼ˆå‹•å‘ã€è¦å› ã€ä¿®æ­£ç†ç”±ãªã©ï¼‰ã‚’JSONã§ä¿å­˜
                    
                    timestamp TEXT,             -- ä½œæˆ/æœ€çµ‚æ›´æ–°æ—¥æ™‚
                    FOREIGN KEY (store_id) REFERENCES stores(id),
                    UNIQUE(store_id, monday_date)
                );
            ''')
            
            conn.execute('''
                CREATE TABLE IF NOT EXISTS learning_patterns (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    input_context_hash TEXT NOT NULL UNIQUE, -- å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒã‚·ãƒ¥å€¤
                    original_output_json TEXT,
                    modified_output_json TEXT,
                    edit_reason TEXT,
                    usage_count INTEGER DEFAULT 1,
                    last_used TEXT
                )
            ''')
            
            # æŒ‡å®šã•ã‚ŒãŸåº—èˆ—åã®ã¿ã‚’æŒ¿å…¥ (æ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—)
            for store_name in ['RAY', 'RSJ', 'ROS', 'RNG']:
                conn.execute("INSERT OR IGNORE INTO stores (name) VALUES (?)", (store_name,))
            conn.commit()
        conn.close()

    def get_store_id_by_name(self, store_name: str) -> int:
        """ã‚¹ãƒˆã‚¢åã‹ã‚‰IDã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        store_id = conn.execute('SELECT id FROM stores WHERE name = ?', (store_name,)).fetchone()['id']
        conn.close()
        return store_id

    def get_store_name_by_id(self, store_id: int) -> str:
        """ã‚¹ãƒˆã‚¢IDã‹ã‚‰åå‰ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        store_name = conn.execute('SELECT name FROM stores WHERE id = ?', (store_id,)).fetchone()['name']
        conn.close()
        return store_name
    
    def get_all_stores(self) -> List[Tuple[int, str]]:
        """å…¨ã¦ã®åº—èˆ—ã®IDã¨åå‰ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        stores = conn.execute('SELECT id, name FROM stores ORDER BY name').fetchall()
        conn.close()
        return [(s['id'], s['name']) for s in stores]

    def save_weekly_data(self, store_id: int, monday_date_str: str, data: Dict, original_report: Dict, modified_report: Dict = None):
        """é€±æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’DBã«ä¿å­˜ã¾ãŸã¯æ›´æ–°ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        daily_reports_json = json.dumps(data['daily_reports'], ensure_ascii=False)
        generated_report_json = json.dumps(original_report, ensure_ascii=False)
        modified_report_json = json.dumps(modified_report, ensure_ascii=False) if modified_report else None
        
        cursor.execute(
            'SELECT id FROM weekly_reports WHERE store_id = ? AND monday_date = ?',
            (store_id, monday_date_str)
        )
        existing_record = cursor.fetchone()

        if existing_record:
            cursor.execute('''
                UPDATE weekly_reports SET
                   daily_reports_json = ?, topics = ?, impact_day = ?,
                   quantitative_data = ?, generated_report_json = ?,
                   modified_report_json = ?, timestamp = ?
                WHERE id = ?
            ''', (
                daily_reports_json,
                data.get('topics', ''),
                data.get('impact_day', ''),
                data.get('quantitative_data', ''),
                generated_report_json,
                modified_report_json,
                datetime.now().isoformat(),
                existing_record['id']
            ))
        else:
            cursor.execute('''
                INSERT INTO weekly_reports 
                (store_id, monday_date, daily_reports_json, topics, impact_day, 
                 quantitative_data, generated_report_json, modified_report_json, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                store_id,
                monday_date_str,
                daily_reports_json,
                data.get('topics', ''),
                data.get('impact_day', ''),
                data.get('quantitative_data', ''),
                generated_report_json,
                modified_report_json,
                datetime.now().isoformat()
            ))
        
        conn.commit()
        conn.close()
        return existing_record is not None

    def get_weekly_report(self, store_id: int, monday_date_str: str) -> Dict:
        """æŒ‡å®šã•ã‚ŒãŸé€±ã®ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        report_row = conn.execute(
            'SELECT * FROM weekly_reports WHERE store_id = ? AND monday_date = ?',
            (store_id, monday_date_str)
        ).fetchone()
        conn.close()

        if report_row:
            report_data = dict(report_row) # Rowã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›
            try:
                report_data['daily_reports'] = json.loads(report_data['daily_reports_json']) if report_data['daily_reports_json'] else {}
            except (json.JSONDecodeError, TypeError) as e:
                print(f"æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                report_data['daily_reports'] = {}
                
            try:
                report_data['generated_report'] = json.loads(report_data['generated_report_json']) if report_data['generated_report_json'] else {}
            except (json.JSONDecodeError, TypeError) as e:
                print(f"ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                report_data['generated_report'] = {}
                
            try:
                report_data['modified_report'] = json.loads(report_data['modified_report_json']) if report_data['modified_report_json'] else None
            except (json.JSONDecodeError, TypeError) as e:
                print(f"ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                report_data['modified_report'] = None
            
            del report_data['daily_reports_json']
            del report_data['generated_report_json']
            if 'modified_report_json' in report_data:
                del report_data['modified_report_json']

            return report_data
        return {}
    
    def get_all_weekly_reports(self, store_id: int = None) -> List[Dict]:
        """å…¨ã¦ã®é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã€ã¾ãŸã¯æŒ‡å®šã—ãŸåº—èˆ—ã®é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        if store_id:
            reports_rows = conn.execute(
                'SELECT id, store_id, monday_date, timestamp, generated_report_json, modified_report_json '
                'FROM weekly_reports WHERE store_id = ? ORDER BY monday_date DESC', (store_id,)
            ).fetchall()
        else:
            reports_rows = conn.execute(
                'SELECT id, store_id, monday_date, timestamp, generated_report_json, modified_report_json '
                'FROM weekly_reports ORDER BY monday_date DESC'
            ).fetchall()
        conn.close()

        reports = []
        for row in reports_rows:
            report_data = dict(row)
            report_data['store_name'] = self.get_store_name_by_id(report_data['store_id'])
            
            # ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆã¨ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆã®æœ‰ç„¡ã‚’ãƒ•ãƒ©ã‚°ã¨ã—ã¦è¿½åŠ 
            report_data['has_generated'] = report_data['generated_report_json'] is not None
            report_data['has_modified'] = report_data['modified_report_json'] is not None

            # JSONæ–‡å­—åˆ—ã¯ç”Ÿãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿æŒã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹
            reports.append(report_data)
        return reports

    def find_similar_cases(self, current_data: Dict) -> str:
        """é¡ä¼¼ã‚±ãƒ¼ã‚¹ã‚’æ¤œç´¢ã—ã€LLMã«æ¸¡ã™ãŸã‚ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT daily_reports_json, modified_report_json 
            FROM weekly_reports 
            WHERE modified_report_json IS NOT NULL
            ORDER BY timestamp DESC
            LIMIT 5
        ''') 
        
        results = cursor.fetchall()
        conn.close()
        
        similar_cases_context = []
        for result in results:
            try:
                past_modified_report = json.loads(result[1])
                
                context_item = (
                    f"- éå»ã®é¡ä¼¼ã‚±ãƒ¼ã‚¹ (ä¿®æ­£å¾Œ): {past_modified_report.get('trend', '')[:100]}...\n"
                    f"  è¦å› : {', '.join(past_modified_report.get('factors', []))}\n"
                    f"  (ä¿®æ­£ç†ç”±: {past_modified_report.get('edit_reason', 'ä¸æ˜')[:50]}...)\n"
                )
                similar_cases_context.append(context_item)

            except json.JSONDecodeError:
                continue
        
        if similar_cases_context:
            return "\nã€éå»ã®ä¿®æ­£æ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆä¾‹ã€‘\n" + "\n".join(similar_cases_context)
        return ""
    
    def get_learning_stats(self):
        """å­¦ç¿’ã«é–¢ã™ã‚‹çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        try:
            conn = self._get_connection()
            cursor = conn.cursor()
            
            total_reports = cursor.execute("SELECT COUNT(*) FROM weekly_reports").fetchone()[0]
            corrections = cursor.execute("SELECT COUNT(*) FROM weekly_reports WHERE modified_report_json IS NOT NULL").fetchone()[0]
            
            # learning_patternsãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
            try:
                total_patterns = cursor.execute("SELECT COUNT(*) FROM learning_patterns").fetchone()[0]
            except Exception as e:
                print(f"learning_patternsãƒ†ãƒ¼ãƒ–ãƒ«ã‚¨ãƒ©ãƒ¼: {e}")
                total_patterns = 0
            
            conn.close()
            
            return {
                'total_reports': total_reports,
                'corrections': corrections,
                'patterns': total_patterns
            }
        except Exception as e:
            print(f"get_learning_stats ã‚¨ãƒ©ãƒ¼: {e}")
            return {
                'total_reports': 0,
                'corrections': 0,
                'patterns': 0
            }

def save_draft_data(store_name: str, monday_date_str: str, daily_reports_data: Dict, topics: str = "", impact_day: str = "", quantitative_data: str = ""):
    """å…¥åŠ›é€”ä¸­ã®ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ä¿å­˜ã™ã‚‹"""
    try:
        store_id = db_manager.get_store_id_by_name(store_name)
        
        # æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        existing_report = db_manager.get_weekly_report(store_id, monday_date_str)
        
        # é¸æŠã•ã‚ŒãŸåº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’ä¿å­˜ï¼ˆåº—èˆ—ã‚­ãƒ¼ãªã—ã®æ§‹é€ ï¼‰
        # daily_reports_dataã‹ã‚‰è©²å½“åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
        store_daily_reports = daily_reports_data.get(store_name, {})
        
        # é€±ã®7æ—¥åˆ†ã‚’åˆæœŸåŒ–ï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        if not store_daily_reports:
            date_obj = datetime.strptime(monday_date_str, '%Y-%m-%d').date()
            for i in range(7):
                current_date = date_obj + timedelta(days=i)
                date_str = current_date.strftime('%Y-%m-%d')
                if date_str not in store_daily_reports:
                    store_daily_reports[date_str] = {"trend": "", "factors": []}
        
        # ä¿®æ­£å†…å®¹ã®è‡ªå‹•ä¿å­˜ã‚‚å®Ÿè¡Œï¼ˆæ–°ã—ã„æ–¹æ³•ã‚’ä½¿ç”¨ï¼‰
        auto_save_modification()
        
        draft_data = {
            'daily_reports': store_daily_reports,  # åº—èˆ—ã‚­ãƒ¼ãªã—ã§ç›´æ¥æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿
            'topics': topics or (existing_report.get('topics', '') if existing_report else ''),
            'impact_day': impact_day or (existing_report.get('impact_day', '') if existing_report else ''),
            'quantitative_data': quantitative_data or (existing_report.get('quantitative_data', '') if existing_report else '')
        }
        
        # æ—¢å­˜ã®ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆã¨ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆã¯ä¿æŒ
        original_report = existing_report.get('generated_report', {}) if existing_report else {}
        modified_report = existing_report.get('modified_report') if existing_report else None
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        db_manager.save_weekly_data(
            store_id,
            monday_date_str,
            draft_data,
            original_report,
            modified_report
        )
        
        # ä¿å­˜æ™‚åˆ»ã‚’è¨˜éŒ²ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰
        japan_time = get_japan_time()
        st.session_state['last_auto_save'] = japan_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
        st.session_state['last_auto_save_timestamp'] = japan_time.timestamp()
        
        return True
    except Exception as e:
        print(f"è‡ªå‹•ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False


class ApparelReportGenerator:
    def __init__(self):
        self.openai_client = None
        self.training_data = None
        self.text_training_data = None 
        self.memory_db = None 
        self.learning_engine = None
        
    def set_dependencies(self, memory_db_instance, learning_engine_instance):
        """å¤–éƒ¨ã‹ã‚‰ä¾å­˜é–¢ä¿‚ã‚’è¨­å®šã™ã‚‹ãŸã‚ã®ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.memory_db = memory_db_instance
        self.learning_engine = learning_engine_instance

    def initialize_openai(self, api_key: str):
        """OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        try:
            # APIã‚­ãƒ¼ã®åŸºæœ¬çš„ãªãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆãƒã‚§ãƒƒã‚¯
            if not api_key or len(api_key.strip()) == 0:
                st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒç©ºã§ã™ã€‚")
                return False
                
            api_key = api_key.strip()  # å‰å¾Œã®ç©ºç™½ã‚’é™¤å»
            
            if not api_key.startswith('sk-'):
                st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚APIã‚­ãƒ¼ã¯ 'sk-' ã§å§‹ã¾ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™ã€‚")
                return False
            
            # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–ï¼ˆã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆè¨­å®šè¿½åŠ ï¼‰
            self.openai_client = openai.OpenAI(
                api_key=api_key,
                timeout=60.0  # 60ç§’ã§ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
            )
            
            # APIã‚­ãƒ¼ã®æœ‰åŠ¹æ€§ã‚’ãƒ†ã‚¹ãƒˆï¼ˆç°¡å˜ãªå‘¼ã³å‡ºã—ã§ç¢ºèªï¼‰
            try:
                # ã‚ˆã‚Šè»½ã„å‘¼ã³å‡ºã—ã«å¤‰æ›´
                test_response = self.openai_client.chat.completions.create(
                    model="gpt-4o-mini",
                    messages=[{"role": "user", "content": "test"}],
                    max_tokens=1
                )
                return True
            except openai.AuthenticationError as auth_error:
                st.error(f"âŒ OpenAI APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™: {str(auth_error)}")
                return False
            except openai.PermissionDeniedError as perm_error:
                st.error(f"âŒ OpenAI APIã‚­ãƒ¼ã®æ¨©é™ãŒä¸è¶³ã—ã¦ã„ã¾ã™: {str(perm_error)}")
                return False
            except openai.RateLimitError as rate_error:
                st.error(f"âŒ OpenAI APIã®åˆ©ç”¨åˆ¶é™ã«é”ã—ã¦ã„ã¾ã™: {str(rate_error)}")
                return False
            except Exception as api_error:
                st.error(f"âŒ OpenAI APIæ¥ç¶šã‚¨ãƒ©ãƒ¼: {str(api_error)} (ã‚¿ã‚¤ãƒ—: {type(api_error).__name__})")
                return False
                
        except Exception as e:
            st.error(f"âŒ OpenAI APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)} (ã‚¿ã‚¤ãƒ—: {type(e).__name__})")
            return False
        
    def load_training_data(self, csv_file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿ã€æœ€åˆã®è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹å ´åˆã®å‡¦ç†
            self.training_data = pd.read_csv(csv_file_path, skiprows=1 if csv_file_path == "training_data.csv" else 0)
            # ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯
            if self.training_data.empty:
                try:
                    # Streamlitã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã®ã¿st.warningã‚’å®Ÿè¡Œ
                    st.warning(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{csv_file_path}' ãŒç©ºã§ã™ã€‚")
                except:
                    pass
                return False
            return True
        except Exception as e:
            try:
                # Streamlitã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã®ã¿st.errorã‚’å®Ÿè¡Œ
                st.error(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            except:
                pass
            return False
    
    def load_text_training_data(self, csv_file_path):
        """ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            # text_training_data.csvã¯ç‰¹åˆ¥ãªå‡¦ç†ãŒå¿…è¦
            if csv_file_path == "text_training_data.csv":
                self.text_training_data = pd.read_csv(csv_file_path, skiprows=2)  # æœ€åˆã®2è¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
            else:
                self.text_training_data = pd.read_csv(csv_file_path)
            
            # ãƒ‡ãƒ¼ã‚¿ã®æ•´åˆæ€§ã‚’ãƒã‚§ãƒƒã‚¯
            if self.text_training_data.empty:
                try:
                    # Streamlitã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã®ã¿st.warningã‚’å®Ÿè¡Œ
                    st.warning(f"ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{csv_file_path}' ãŒç©ºã§ã™ã€‚")
                except:
                    pass
                return False
            return True
        except Exception as e:
            try:
                # Streamlitã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã®ã¿st.errorã‚’å®Ÿè¡Œ
                st.error(f"ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            except:
                pass
            return False
    
    
    def analyze_trend_factors(self, daily_reports: Dict, topics: str, impact_day: str, quantitative_data: str) -> Dict:
        """æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’åˆ†æã—ã€å‹•å‘ã¨è¦å› ã‚’æŠ½å‡º"""
        
        current_data_for_context = {
            'daily_reports': daily_reports,
            'topics': topics,
            'impact_day': impact_day,
            'quantitative_data': quantitative_data
        }
        enhanced_context = ""
        if self.memory_db and self.learning_engine:
             enhanced_context = self.memory_db.find_similar_cases(current_data_for_context)
        
        system_prompt = self._build_system_prompt()
        user_prompt = self._build_user_prompt(daily_reports, topics, impact_day, quantitative_data, enhanced_context) 
        
        if not self.openai_client:
            st.error("OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return {
                'trend': 'OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚åˆ†æã§ãã¾ã›ã‚“ã§ã—ãŸ',
                'factors': ['APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„'],
                'questions': ['è¨­å®šãƒšãƒ¼ã‚¸ã§APIã‚­ãƒ¼ã‚’æ­£ã—ãå…¥åŠ›ã—ã¦ãã ã•ã„'],
            }
            
        try:
            response = self.openai_client.chat.completions.create( 
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3,
                max_tokens=1000,
                timeout=30
            )
            
            result = response.choices[0].message.content
            parsed_result = self._parse_analysis_result(result)
            return parsed_result
            
        except Exception as e:
            st.error(f"AIåˆ†æä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®åˆ†æçµæœã‚’è¿”ã™
            return {
                'trend': 'åˆ†æã§ãã¾ã›ã‚“ã§ã—ãŸ',
                'factors': ['ã‚¨ãƒ©ãƒ¼ã®ãŸã‚åˆ†æã‚’å®Ÿè¡Œã§ãã¾ã›ã‚“ã§ã—ãŸ'],
                'questions': ['å†åº¦ãŠè©¦ã—ãã ã•ã„'],
                'impact_analysis': 'åˆ†æä¸å¯',
                'next_actions': 'å†å®Ÿè¡Œã‚’æ¨å¥¨ã—ã¾ã™'
            }
            
        except openai.APIConnectionError as e:
            st.error(f"OpenAI APIã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
            return {
                'trend': 'APIæ¥ç¶šã‚¨ãƒ©ãƒ¼ã®ãŸã‚åˆ†æã§ãã¾ã›ã‚“ã§ã—ãŸ',
                'factors': ['OpenAI APIã¸ã®æ¥ç¶šã«å¤±æ•—ã—ã¾ã—ãŸ'],
                'questions': ['ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦ãã ã•ã„'],
            }
        except openai.APIStatusError as e: # ã“ã“ã¯openaiãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã®ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹ã§OK
            if e.status_code == 401: # èªè¨¼ã‚¨ãƒ©ãƒ¼ (Unauthorized)
                st.error("OpenAI APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚è¨­å®šãƒšãƒ¼ã‚¸ã§APIã‚­ãƒ¼ã‚’æ­£ã—ãå…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
                error_msg = "APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™"
            elif e.status_code == 429: # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ (Too Many Requests)
                st.error("OpenAI APIã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è¶…ãˆã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
                error_msg = "APIåˆ©ç”¨åˆ¶é™ã«é”ã—ã¾ã—ãŸ"
            elif e.status_code == 400: # Bad Request
                st.error("ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒç„¡åŠ¹ã§ã™ã€‚å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
                error_msg = "ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒç„¡åŠ¹ã§ã™"
            elif e.status_code == 500: # Server Error
                st.error("OpenAI APIã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸã€‚æ™‚é–“ã‚’ãŠã„ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
                error_msg = "APIã‚µãƒ¼ãƒãƒ¼ã‚¨ãƒ©ãƒ¼ã§ã™"
            else:
                st.error(f"OpenAI APIã‚¨ãƒ©ãƒ¼: {e.status_code} - {e.response}")
                error_msg = f"APIã‚¨ãƒ©ãƒ¼ ({e.status_code})"
            
            return {
                'trend': f'{error_msg}ã®ãŸã‚åˆ†æã§ãã¾ã›ã‚“ã§ã—ãŸ',
                'factors': ['APIã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ'],
                'questions': ['è¨­å®šã‚’ç¢ºèªã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„'],
            }
        except openai.APITimeoutError: # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼
            st.error("OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã€å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
            return {
                'trend': 'APIã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã®ãŸã‚åˆ†æã§ãã¾ã›ã‚“ã§ã—ãŸ',
                'factors': ['APIãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸ'],
                'questions': ['ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã¦å†è©¦è¡Œã—ã¦ãã ã•ã„'],
            }
        except Exception as e:
            st.error(f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return {
                'trend': f'äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã®ãŸã‚åˆ†æã§ãã¾ã›ã‚“ã§ã—ãŸ: {str(e)}',
                'factors': ['ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ'],
                'questions': ['ç®¡ç†è€…ã«é€£çµ¡ã—ã¦ãã ã•ã„'],
            }
        
    
    def _build_system_prompt(self) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        base_prompt = """
        ã‚ãªãŸã¯ã‚¢ãƒ‘ãƒ¬ãƒ«å°å£²æ¥­ç•Œã®å°‚é–€ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
        ä¸ãˆã‚‰ã‚ŒãŸæ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã€TOPICSã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ã€å®šé‡ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

        ã€åˆ†æè¦ä»¶ã€‘
        1.  å‹•å‘ã¨è¦å› ã®å› æœé–¢ä¿‚ã‚’æ˜ç¢ºã«è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚
        2.  ã€Œç›®è«–è¦‹ä»¥ä¸‹ã€ãªã©ã®çµæœè¡¨ç¾ã¯ã€å…·ä½“çš„ãªè¦å› ã¾ã§æ·±æ˜ã‚Šã—ã¦èª¬æ˜ã™ã‚‹ã“ã¨ã€‚
        3.  æä¾›ã•ã‚ŒãŸå®šé‡ãƒ‡ãƒ¼ã‚¿ã¨ã®æ•´åˆæ€§ã‚’ç¢ºèªã—ã€ãƒ¬ãƒãƒ¼ãƒˆã«åæ˜ ã•ã›ã‚‹ã“ã¨ã€‚
        4.  TOPICSã‚„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ã®äº‹è±¡ãŒé€±å…¨ä½“ã«ä¸ãˆãŸå½±éŸ¿åº¦ã‚’è©•ä¾¡ã—ã€ãƒ¬ãƒãƒ¼ãƒˆã«å«ã‚ã‚‹ã“ã¨ã€‚
        5.  ç°¡æ½”ã§ã€ã‚¢ãƒ‘ãƒ¬ãƒ«åº—èˆ—ã®ä¸Šä½éƒ¨ç½²ãŒç†è§£ã—ã‚„ã™ã„è¡¨ç¾ã‚’ç”¨ã„ã‚‹ã“ã¨ã€‚
        6.  é€±å…¨ä½“ã®å‹•å‘ã¨ã—ã¦ã€**æŒ‡å®šã•ã‚ŒãŸåº—èˆ—ã®æƒ…å ±ã‚’ä¸­å¿ƒã«**åˆ†æã™ã‚‹ã“ã¨ã€‚ï¼ˆä»–ã®åº—èˆ—ã®æƒ…å ±ã¯å‚è€ƒç¨‹åº¦ã«ã¨ã©ã‚ã‚‹ï¼‰

        ã€å‡ºåŠ›å½¢å¼ã€‘
        å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        ```json
        {
            "trend": "é€±å…¨ä½“ã®å‹•å‘ã‚’400å­—ç¨‹åº¦ã§è¨˜è¿°ã€‚å„åº—èˆ—ã®å‹•å‘ã¨è¦å› ã€å®šé‡ãƒ‡ãƒ¼ã‚¿ã€TOPICSã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ã‚’çµ±åˆã—ã€å› æœé–¢ä¿‚ã‚’é‡è¦–ã—ã¦èª¬æ˜ã™ã‚‹ã€‚",
            "factors": [
                "æœ€ã‚‚å½±éŸ¿ã®å¤§ãã‹ã£ãŸè¦å› 1 (30å­—ä»¥å†…)",
                "æ¬¡ã«å½±éŸ¿ã®å¤§ãã‹ã£ãŸè¦å› 2 (30å­—ä»¥å†…)",
                "3ç•ªç›®ã«å½±éŸ¿ã®å¤§ãã‹ã£ãŸè¦å› 3 (30å­—ä»¥å†…)"
            ],
            "questions": [
                "ä¸æ˜ç‚¹ã‚„è¿½åŠ ç¢ºèªãŒå¿…è¦ãªé …ç›®ãŒã‚ã‚Œã°ã€ç°¡æ½”ãªè³ªå•å½¢å¼ã§è¨˜è¿°ã€‚ãªã‘ã‚Œã°ç©ºã®é…åˆ—ã€‚"
            ]
        }
        ```
        - ã€Œtrendã€ã¯400å­—ç¨‹åº¦ã‚’å³å®ˆã™ã‚‹ã“ã¨ã€‚
        - ã€Œfactorsã€ã¯æœ€å¤§3ã¤ã¾ã§ã¨ã—ã€ãã‚Œãã‚Œ30å­—ä»¥å†…ã¨ã™ã‚‹ã“ã¨ã€‚
        - JSONå½¢å¼ä»¥å¤–ã§ã®å‡ºåŠ›ã¯å³ç¦ã§ã™ã€‚
        """
        
        if self.training_data is not None and not self.training_data.empty:
            training_context = self._extract_training_context()
            if training_context:
                base_prompt += f"\n\nã€ç¤¾å†…ç”¨èªãƒ»æ–‡ä½“ãƒ»éå»ã®é¡ä¼¼ä¾‹ã®å‚è€ƒæƒ…å ±ã€‘\n{training_context}"
        
        return base_prompt
    
    def _build_user_prompt(self, daily_reports: Dict, topics: str, impact_day: str, quantitative_data: str, enhanced_context: str) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        prompt = "ä»¥ä¸‹ã®æƒ…å ±ã‹ã‚‰é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"
        
        # ä¿®æ­£: daily_reports ã¯æ—¢ã«å˜ä¸€åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’æƒ³å®š
        prompt += "ã€æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã€‘\n"
        # daily_reports ã¯ { 'åº—èˆ—å': { 'æ—¥ä»˜': { 'trend': '', 'factors': [] } } ã®å½¢å¼ã§æ¥ã‚‹ã¨æƒ³å®š
        for store, data in daily_reports.items(): # ã“ã®ãƒ«ãƒ¼ãƒ—ã¯ä¸€åº¦ã—ã‹å›ã‚‰ãªã„ã¯ãš
            prompt += f"- **{store}åº—**:\n"
            for date, report in data.items():
                # å®‰å…¨ãªã‚¢ã‚¯ã‚»ã‚¹ã«ä¿®æ­£
                if isinstance(report, dict):
                    trend_text = report.get('trend', '') if report.get('trend', '') else "æœªå…¥åŠ›"
                    factors_text = ", ".join(report.get('factors', [])) if report.get('factors', []) else "ãªã—"
                else:
                    trend_text = "ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚¨ãƒ©ãƒ¼"
                    factors_text = "ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚¨ãƒ©ãƒ¼"
                prompt += f"  - {date}: å‹•å‘={trend_text}, è¦å› ={factors_text}\n"
        
        if topics:
            prompt += f"\nã€TOPICSã€‘\n{topics}\n"
        
        if impact_day:
            prompt += f"\nã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ã€‘\n{impact_day}\n"
        
        if quantitative_data:
            prompt += f"\nã€å®šé‡ãƒ‡ãƒ¼ã‚¿ã€‘\n{quantitative_data}\n"
        
        if enhanced_context:
            prompt += f"\n{enhanced_context}\n" 
        
        return prompt
    
    def _extract_training_context(self) -> str:
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç¤¾å†…ç”¨èªãƒ»æ–‡ä½“ã‚’æŠ½å‡º (ç°¡ç•¥åŒ–ã•ã‚ŒãŸä¾‹)"""
        if self.training_data is None or self.training_data.empty:
            if self.text_training_data is None or self.text_training_data.empty:
                return ""
        
        context = []
        
        # æ—¢å­˜ã®training_data.csvã‹ã‚‰ã®æ–‡è„ˆä½œæˆ
        if self.training_data is not None and not self.training_data.empty:
            # ã‚«ãƒ©ãƒ åã‚’ç¢ºèªã—ã¦é©åˆ‡ã«å‡¦ç†
            training_columns = self.training_data.columns.tolist()
            
            # example_trend ã¾ãŸã¯ trend_patterns ã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆ
            trend_col = None
            if 'example_trend' in training_columns:
                trend_col = 'example_trend'
            elif 'trend_patterns' in training_columns:
                trend_col = 'trend_patterns'
            
            if trend_col and not self.training_data[trend_col].empty:
                context.append("éå»ã®ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¿°ä¾‹ (å‹•å‘):")
                for ex in self.training_data[trend_col].dropna().head(3):
                    if ex and str(ex).strip():
                        context.append(f"- {str(ex)[:50]}...")
            
            # example_factors ã¾ãŸã¯ factor_patterns ã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆ
            factor_col = None
            if 'example_factors' in training_columns:
                factor_col = 'example_factors'
            elif 'factor_patterns' in training_columns:
                factor_col = 'factor_patterns'
                
            if factor_col and not self.training_data[factor_col].empty:
                context.append("éå»ã®ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¿°ä¾‹ (è¦å› ):")
                for ex in self.training_data[factor_col].dropna().head(3):
                    if ex and str(ex).strip():
                        context.append(f"- {str(ex)[:30]}...")
            
            # expected_output ã‚«ãƒ©ãƒ ãŒã‚ã‚‹å ´åˆ
            if 'expected_output' in training_columns and not self.training_data['expected_output'].empty:
                context.append("éå»ã®ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¿°ä¾‹ (æœŸå¾…å‡ºåŠ›):")
                for ex in self.training_data['expected_output'].dropna().head(3):
                    if ex and str(ex).strip():
                        context.append(f"- {str(ex)[:60]}...")
        
        # text_training_data.csvã‹ã‚‰ã®æ–‡è„ˆä½œæˆ
        if self.text_training_data is not None and not self.text_training_data.empty:
            text_columns = self.text_training_data.columns.tolist()
            
            if 'output' in text_columns and not self.text_training_data['output'].empty:
                context.append("éå»ã®ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¿°ä¾‹ (ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿):")
                for ex in self.text_training_data['output'].dropna().head(3):
                    if ex and str(ex).strip():
                        context.append(f"- {str(ex)[:60]}...")
        
        return "\n".join(context)
    
    def _parse_analysis_result(self, result: str) -> Dict:
        """åˆ†æçµæœï¼ˆJSONæ–‡å­—åˆ—ï¼‰ã‚’ãƒ‘ãƒ¼ã‚¹"""
        parsed = {
            'trend': '',
            'factors': [],
            'questions': [],
            'original_result_raw': result # LLMã®ç”Ÿã®å‡ºåŠ›ã‚’ä¿æŒ
        }
        
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', result, re.DOTALL)
        if not json_match:
            try:
                json_data = json.loads(result)
            except json.JSONDecodeError as e:
                # JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’trendãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«è¨­å®š
                error_msg = f"ã‚¨ãƒ©ãƒ¼: AIã‹ã‚‰ã®å‡ºåŠ›ãŒæœ‰åŠ¹ãªJSONå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚ç”Ÿã®å‡ºåŠ›: {result[:200]}..."
                parsed['trend'] = error_msg
                try:
                    # Streamlitã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã®ã¿st.errorã‚’å®Ÿè¡Œ
                    st.error("AIã‹ã‚‰ã®å‡ºåŠ›ãŒæœ‰åŠ¹ãªJSONå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚é–‹ç™ºè€…å‘ã‘æƒ…å ±: \n" + result)
                except:
                    # Streamlitã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤–ã§ã¯ç„¡è¦–
                    pass
                return parsed
        else:
            try:
                json_string = json_match.group(1)
                json_data = json.loads(json_string)
            except json.JSONDecodeError as e:
                # JSONãƒ‘ãƒ¼ã‚¹ã‚¨ãƒ©ãƒ¼ã®å ´åˆã€ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’trendãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«è¨­å®š
                error_msg = f"ã‚¨ãƒ©ãƒ¼: AIã‹ã‚‰ã®JSONå‡ºåŠ›ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ç”Ÿã®å‡ºåŠ›: {json_string[:200]}..."
                parsed['trend'] = error_msg
                try:
                    # Streamlitã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãŒã‚ã‚‹å ´åˆã®ã¿st.errorã‚’å®Ÿè¡Œ
                    st.error("AIã‹ã‚‰ã®JSONå‡ºåŠ›ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚é–‹ç™ºè€…å‘ã‘æƒ…å ±: \n" + json_string)
                except:
                    # Streamlitã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆå¤–ã§ã¯ç„¡è¦–
                    pass
                return parsed

        parsed['trend'] = json_data.get('trend', '').strip()
        parsed['factors'] = [f.strip() for f in json_data.get('factors', []) if f.strip()][:3]
        parsed['questions'] = [q.strip() for q in json_data.get('questions', []) if q.strip()]
        
        return parsed
        
        return parsed

class LearningEngine:
    """å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã‚¯ãƒ©ã‚¹ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿®æ­£ã‹ã‚‰å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆãƒ»ç®¡ç†ã—ã¾ã™ã€‚"""
    
    def __init__(self, db_manager: DBManager):
        self.db_manager = db_manager
    
    def learn_from_correction(self, input_data: Dict, original_output: Dict, modified_output: Dict):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿®æ­£ã‹ã‚‰å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã€DBã«ä¿å­˜ã—ã¾ã™ã€‚"""
        # å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆï¼ˆç°¡æ˜“çš„ãªæ–¹æ³•ï¼‰
        input_context_str = json.dumps(input_data, ensure_ascii=False, sort_keys=True)
        input_context_hash = hashlib.sha256(input_context_str.encode('utf-8')).hexdigest()
        
        conn = self.db_manager._get_connection() # DBManagerã‹ã‚‰æ¥ç¶šã‚’å–å¾—
        cursor = conn.cursor()

        original_output_json = json.dumps(original_output, ensure_ascii=False)
        modified_output_json = json.dumps(modified_output, ensure_ascii=False)
        edit_reason = modified_output.get('edit_reason', '')

        cursor.execute('''
            SELECT id, usage_count FROM learning_patterns 
            WHERE input_context_hash = ? AND modified_output_json = ?
        ''', (input_context_hash, modified_output_json))
        
        existing_pattern = cursor.fetchone()

        if existing_pattern:
            pattern_id, usage_count = existing_pattern
            cursor.execute('''
                UPDATE learning_patterns 
                SET usage_count = ?, last_used = ?
                WHERE id = ?
            ''', (usage_count + 1, datetime.now().isoformat(), pattern_id))
            st.info("æ—¢å­˜ã®å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
        else:
            cursor.execute('''
                INSERT INTO learning_patterns 
                (input_context_hash, original_output_json, modified_output_json, edit_reason, usage_count, last_used)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                input_context_hash,
                original_output_json,
                modified_output_json,
                edit_reason,
                1,
                datetime.now().isoformat()
            ))
            st.success("æ–°ã—ã„å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼AIã®ç²¾åº¦å‘ä¸Šã«å½¹ç«‹ã¡ã¾ã™ã€‚")
        
        conn.commit()
        conn.close()


# --- Streamlit UI Components ---

def get_base64_of_bin_file(bin_file):
    with open(bin_file, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()

def get_file_download_link(df, filename, text):
    """Generates a link for downloading a pandas DataFrame as CSV."""
    csv = df.to_csv(index=False, encoding='utf-8-sig') # UTF-8 BOMä»˜ãã§Excelå¯¾å¿œ
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
    return href

def get_excel_download_link(df, filename, text):
    """Generates a link for downloading a pandas DataFrame as Excel."""
    try:
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False, sheet_name='ãƒ¬ãƒãƒ¼ãƒˆ')
        b64 = base64.b64encode(output.getvalue()).decode()
        href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="{filename}">{text}</a>'
        return href
    except ImportError:
        # xlsxwriterãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯CSVã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        st.warning("Excelå½¢å¼ã§ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒã§ãã¾ã›ã‚“ã€‚CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚")
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        b64 = base64.b64encode(csv.encode()).decode()
        csv_filename = filename.replace('.xlsx', '.csv')
        href = f'<a href="data:file/csv;base64,{b64}" download="{csv_filename}">{text}</a>'
        return href

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®åˆæœŸåŒ–
db_manager = DBManager()
report_generator = ApparelReportGenerator()
learning_engine = LearningEngine(db_manager)

# ä¾å­˜é–¢ä¿‚ã‚’è¨­å®š
report_generator.set_dependencies(db_manager, learning_engine)

# â˜…ã“ã“ã‹ã‚‰è¿½åŠ ã™ã‚‹ã‚³ãƒ¼ãƒ‰â˜…
TRAINING_CSV_FILE = "training_data.csv" # ã“ã“ã‚’å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«ç½®ãæ›ãˆã¦ãã ã•ã„ï¼
TEXT_TRAINING_CSV_FILE = "text_training_data.csv" # ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«

# training_data.csvã®èª­ã¿è¾¼ã¿ï¼ˆè¡¨ç¤ºãªã—ï¼‰
if Path(TRAINING_CSV_FILE).exists():
    report_generator.load_training_data(TRAINING_CSV_FILE)
    # st.sidebar.success(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TRAINING_CSV_FILE}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")  # è¡¨ç¤ºå‰Šé™¤
    # èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã®ã¿ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    # else:
    #     st.sidebar.warning(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TRAINING_CSV_FILE}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
# else:
    # st.sidebar.info(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TRAINING_CSV_FILE}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")  # è¡¨ç¤ºå‰Šé™¤

# text_training_data.csvã®èª­ã¿è¾¼ã¿ï¼ˆè¡¨ç¤ºãªã—ï¼‰
if Path(TEXT_TRAINING_CSV_FILE).exists():
    report_generator.load_text_training_data(TEXT_TRAINING_CSV_FILE)
    # st.sidebar.success(f"ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TEXT_TRAINING_CSV_FILE}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")  # è¡¨ç¤ºå‰Šé™¤
    # èª­ã¿è¾¼ã¿å¤±æ•—æ™‚ã®ã¿ã‚¨ãƒ©ãƒ¼è¡¨ç¤ºï¼ˆãƒ‡ãƒãƒƒã‚°ç”¨ï¼‰
    # else:
    #     st.sidebar.warning(f"ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TEXT_TRAINING_CSV_FILE}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
# else:
    # st.sidebar.info(f"ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TEXT_TRAINING_CSV_FILE}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")  # è¡¨ç¤ºå‰Šé™¤

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç„¡ã‚’ç¢ºèªï¼ˆæ©Ÿèƒ½ã¯ç¶­æŒï¼‰
has_training_data = (report_generator.training_data is not None and not report_generator.training_data.empty)
has_text_training_data = (report_generator.text_training_data is not None and not report_generator.text_training_data.empty)

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒå…¨ããªã„å ´åˆã®ã¿è­¦å‘Šè¡¨ç¤ºï¼ˆé‡è¦ãªã‚¨ãƒ©ãƒ¼æƒ…å ±ã¨ã—ã¦æ®‹ã™ï¼‰
if not has_training_data and not has_text_training_data:
    st.sidebar.warning("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å­¦ç¿’æ©Ÿèƒ½ã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™ã€‚")
# â˜…ã“ã“ã¾ã§è¿½åŠ ã™ã‚‹ã‚³ãƒ¼ãƒ‰â˜…

def get_monday_of_week(selected_date: date) -> date:
    """ä¸ãˆã‚‰ã‚ŒãŸæ—¥ä»˜ãŒå±ã™ã‚‹é€±ã®æœˆæ›œæ—¥ã‚’è¨ˆç®—ã—ã¾ã™ã€‚"""
    # é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã®æ›œæ—¥ã‚’å–å¾— (æœˆæ›œæ—¥=0, æ—¥æ›œæ—¥=6)
    weekday = selected_date.weekday()
    # æœˆæ›œæ—¥ã«æˆ»ã‚‹ãŸã‚ã®æ—¥æ•°ã‚’è¨ˆç®—
    days_since_monday = weekday
    monday = selected_date - timedelta(days=days_since_monday)
    return monday

def get_current_week_monday() -> date:
    """ç¾åœ¨ã®é€±ã®æœˆæ›œæ—¥ã‚’å–å¾—ã—ã¾ã™ã€‚"""
    today = date.today()
    return get_monday_of_week(today)

# --- Streamlit UI Components ---

def auto_save_modification():
    """ä¿®æ­£å†…å®¹ã®è‡ªå‹•ä¿å­˜"""
    try:
        # ç¾åœ¨é¸æŠä¸­ã®åº—èˆ—ã¨é€±ã®æƒ…å ±ã‚’å–å¾—
        store_key = st.session_state.get('selected_store_for_report', 'default')
        week_key = st.session_state.get('selected_monday', 'default')
        session_key = f"{store_key}_{week_key}"
        
        # ä¿®æ­£å†…å®¹ç”¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚­ãƒ¼ã‚’ä½œæˆ
        saved_modifications = st.session_state.get('saved_modifications', {})
        if session_key not in saved_modifications:
            saved_modifications[session_key] = {}
        
        # ä¿®æ­£å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å€¤ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³çŠ¶æ…‹ã«ä¿å­˜
        if 'modified_trend_input' in st.session_state:
            saved_modifications[session_key]['trend'] = st.session_state['modified_trend_input']
        if 'modified_factors_input' in st.session_state:
            saved_modifications[session_key]['factors'] = st.session_state['modified_factors_input']
        if 'modified_questions_input' in st.session_state:
            saved_modifications[session_key]['questions'] = st.session_state['modified_questions_input']
        if 'edit_reason_input' in st.session_state:
            saved_modifications[session_key]['edit_reason'] = st.session_state['edit_reason_input']
        
        st.session_state['saved_modifications'] = saved_modifications
        
    except Exception as e:
        pass  # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¦ã‚‚å‡¦ç†ã‚’ç¶šè¡Œ

def get_saved_modification(field: str) -> str:
    """ä¿å­˜ã•ã‚ŒãŸä¿®æ­£å†…å®¹ã‚’å–å¾—"""
    try:
        store_key = st.session_state.get('selected_store_for_report', 'default')
        week_key = st.session_state.get('selected_monday', 'default')
        session_key = f"{store_key}_{week_key}"
        
        saved_modifications = st.session_state.get('saved_modifications', {})
        return saved_modifications.get(session_key, {}).get(field, '')
    except Exception:
        return ''

def clear_saved_modifications():
    """ä¿å­˜ã•ã‚ŒãŸä¿®æ­£å†…å®¹ã‚’ã‚¯ãƒªã‚¢"""
    try:
        store_key = st.session_state.get('selected_store_for_report', 'default')
        week_key = st.session_state.get('selected_monday', 'default')
        session_key = f"{store_key}_{week_key}"
        
        saved_modifications = st.session_state.get('saved_modifications', {})
        if session_key in saved_modifications:
            del saved_modifications[session_key]
        st.session_state['saved_modifications'] = saved_modifications
    except Exception:
        pass

def show_report_creation_page():
    st.title("ğŸ“ˆ é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ")
    st.markdown("---")

    st.info("ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€åº—èˆ—ã”ã¨ã®æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã€AIãŒé€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚AIãƒ¬ãƒãƒ¼ãƒˆã¯å¾Œã§ä¿®æ­£ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã«å­¦ç¿’ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚")

    # é€±ã®é¸æŠ
    st.header("1. ãƒ¬ãƒãƒ¼ãƒˆå¯¾è±¡é€±ã®é¸æŠ")
    # ä»Šé€±ã®æœˆæ›œæ—¥ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ã™ã‚‹
    default_monday = get_current_week_monday()
    selected_date = st.date_input(
        "ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹é€±ã®**æœˆæ›œæ—¥**ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
        value=default_monday,
        min_value=date(2023, 1, 1),
        max_value=date.today() + timedelta(days=30), # æœªæ¥ã®æ—¥ä»˜ã‚‚å°‘ã—è¨±å®¹
        format="YYYY/MM/DD"
    )
    
    # é¸æŠã•ã‚ŒãŸæ—¥ä»˜ãŒæœˆæ›œæ—¥ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ãã†ã§ãªã„å ´åˆã¯æœˆæ›œæ—¥ã«è£œæ­£
    if selected_date.weekday() != 0:
        st.warning(f"é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã¯æœˆæ›œæ—¥ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚è‡ªå‹•çš„ã«**{get_monday_of_week(selected_date).strftime('%Yå¹´%mæœˆ%dæ—¥')}**ã®é€±ã¨ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚")
        monday_of_week = get_monday_of_week(selected_date)
    else:
        monday_of_week = selected_date
    
    st.session_state['selected_monday'] = monday_of_week.strftime('%Y-%m-%d')
    
    # æ—¥ä»˜ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®å‡¦ç†
    if 'last_selected_monday' not in st.session_state or st.session_state['last_selected_monday'] != st.session_state['selected_monday']:
        # æ—¥ä»˜å¤‰æ›´æ™‚ã¯æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state['topics_loaded_for_week'] = False
        # è‡ªå‹•ä¿å­˜æ™‚åˆ»ã‚‚ãƒªã‚»ãƒƒãƒˆ
        st.session_state['last_auto_save'] = None
    
    st.subheader(f"é¸æŠé€±: {monday_of_week.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {(monday_of_week + timedelta(days=6)).strftime('%Yå¹´%mæœˆ%dæ—¥')}")
    st.markdown("---")

    # æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ­ãƒ¼ãƒ‰
    store_names = [s[1] for s in db_manager.get_all_stores()]
    if 'selected_store_for_report' not in st.session_state:
        st.session_state['selected_store_for_report'] = store_names[0] # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ€åˆã®åº—èˆ—

    # ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®åˆæœŸåŒ–
    if 'daily_reports_input' not in st.session_state:
        st.session_state['daily_reports_input'] = {store_name: {} for store_name in store_names}
    
    # é€±å…¨ä½“ã®è¿½åŠ æƒ…å ±ã‚’åº—èˆ—ã”ã¨ãƒ»é€±ã”ã¨ã«ç®¡ç†
    if 'weekly_additional_data' not in st.session_state:
        st.session_state['weekly_additional_data'] = {}
    
    # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚’åº—èˆ—ãƒ»é€±ã”ã¨ã«ç®¡ç†
    if 'weekly_report_outputs' not in st.session_state:
        st.session_state['weekly_report_outputs'] = {}
    
    # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚ã€æ—§å½¢å¼ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Œã°ç§»è¡Œ
    if 'topics_input' not in st.session_state:
        st.session_state['topics_input'] = ""
    if 'impact_day_input' not in st.session_state:
        st.session_state['impact_day_input'] = ""
    if 'quantitative_data_input' not in st.session_state:
        st.session_state['quantitative_data_input'] = ""
    
    if 'generated_report_output' not in st.session_state:
        st.session_state['generated_report_output'] = None
    if 'modified_report_output' not in st.session_state:
        st.session_state['modified_report_output'] = None
    if 'report_id_to_edit' not in st.session_state:
        st.session_state['report_id_to_edit'] = None

    # é€±å…¨ä½“ã®è¿½åŠ æƒ…å ±ã‚’ç®¡ç†ã™ã‚‹ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•°
    def get_weekly_key(store_name, monday_date):
        """åº—èˆ—ã¨é€±ã®çµ„ã¿åˆã‚ã›ã§ã‚­ãƒ¼ã‚’ç”Ÿæˆ"""
        return f"{store_name}_{monday_date}"
    
    def get_weekly_additional_data(store_name, monday_date, field):
        """æŒ‡å®šã•ã‚ŒãŸåº—èˆ—ãƒ»é€±ã®è¿½åŠ æƒ…å ±ã‚’å–å¾—"""
        key = get_weekly_key(store_name, monday_date)
        return st.session_state['weekly_additional_data'].get(key, {}).get(field, "")
    
    def set_weekly_additional_data(store_name, monday_date, field, value):
        """æŒ‡å®šã•ã‚ŒãŸåº—èˆ—ãƒ»é€±ã®è¿½åŠ æƒ…å ±ã‚’è¨­å®š"""
        key = get_weekly_key(store_name, monday_date)
        if key not in st.session_state['weekly_additional_data']:
            st.session_state['weekly_additional_data'][key] = {}
        st.session_state['weekly_additional_data'][key][field] = value
    
    def get_weekly_report_output(store_name, monday_date, field):
        """æŒ‡å®šã•ã‚ŒãŸåº—èˆ—ãƒ»é€±ã®ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—"""
        key = get_weekly_key(store_name, monday_date)
        return st.session_state['weekly_report_outputs'].get(key, {}).get(field, None)
    
    def set_weekly_report_output(store_name, monday_date, field, value):
        """æŒ‡å®šã•ã‚ŒãŸåº—èˆ—ãƒ»é€±ã®ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š"""
        key = get_weekly_key(store_name, monday_date)
        if key not in st.session_state['weekly_report_outputs']:
            st.session_state['weekly_report_outputs'][key] = {}
        st.session_state['weekly_report_outputs'][key][field] = value

    # é¸æŠã•ã‚ŒãŸé€±ã®æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
    # ã¾ãšã€ã‚¹ãƒˆã‚¢é¸æŠã‚¿ãƒ–ã®ç¾åœ¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿æŒ
    if 'active_tab_index' not in st.session_state:
        st.session_state['active_tab_index'] = 0 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ€åˆã®ã‚¿ãƒ– (RAY)

    # æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å‰ã«ã€ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹åº—èˆ—åã‚’å–å¾—
    # åˆæœŸè¡¨ç¤ºæ™‚ã‚„æ—¥ä»˜å¤‰æ›´æ™‚ã«ã€é¸æŠåº—èˆ—ã®ãƒ¬ãƒãƒ¼ãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ã‚ˆã†ã«èª¿æ•´
    # ãŸã ã—ã€ã‚¿ãƒ–ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã¯ã€ãã®ã‚¿ãƒ–ã®åº—èˆ—åã«è¿½å¾“
    # ã“ã“ã§ã¯ã€`selected_store_for_report` ã¨ `active_tab_index` ã®åŒæœŸã‚’å¼·åŒ–
    
    # å„åº—èˆ—ã®æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã‚’å€‹åˆ¥ã«èª­ã¿è¾¼ã¿ï¼ˆçµ±ä¸€ã•ã‚ŒãŸæ–¹æ³•ï¼‰
    for store_name in store_names:
        store_id = db_manager.get_store_id_by_name(store_name)
        existing_report = db_manager.get_weekly_report(store_id, st.session_state['selected_monday'])
        
        if existing_report:
            # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ï¼ˆåº—èˆ—ã‚­ãƒ¼ãªã—ï¼‰ã§ç›´æ¥æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
            if existing_report.get('daily_reports'):
                st.session_state['daily_reports_input'][store_name] = existing_report['daily_reports']
            
            # é€±å…¨ä½“ã®è¿½åŠ æƒ…å ±ã‚’åº—èˆ—ã”ã¨ãƒ»é€±ã”ã¨ã«ä¿å­˜
            set_weekly_additional_data(store_name, st.session_state['selected_monday'], 'topics', existing_report.get('topics', ''))
            set_weekly_additional_data(store_name, st.session_state['selected_monday'], 'impact_day', existing_report.get('impact_day', ''))
            set_weekly_additional_data(store_name, st.session_state['selected_monday'], 'quantitative_data', existing_report.get('quantitative_data', ''))
            
            # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚‚åº—èˆ—ãƒ»é€±ã”ã¨ã«ä¿å­˜
            set_weekly_report_output(store_name, st.session_state['selected_monday'], 'generated_report', existing_report.get('generated_report', {}))
            set_weekly_report_output(store_name, st.session_state['selected_monday'], 'modified_report', existing_report.get('modified_report'))
            set_weekly_report_output(store_name, st.session_state['selected_monday'], 'report_id', existing_report.get('id'))
            
            # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸåº—èˆ—ã®ãã®ä»–ãƒ‡ãƒ¼ã‚¿ã‚‚èª­ã¿è¾¼ã¿ï¼ˆãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã¯å…±é€šâ†’å€‹åˆ¥ç®¡ç†ã«å¤‰æ›´ï¼‰
            if not st.session_state.get('topics_loaded_for_week'):
                # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—§å½¢å¼ã‚‚æ›´æ–°ï¼ˆç¾åœ¨é¸æŠä¸­ã®åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã§æ›´æ–°ï¼‰
                if store_name == st.session_state.get('selected_store_for_report', store_names[0]):
                    st.session_state['topics_input'] = existing_report.get('topics', '')
                    st.session_state['impact_day_input'] = existing_report.get('impact_day', '')
                    st.session_state['quantitative_data_input'] = existing_report.get('quantitative_data', '')
                    st.session_state['generated_report_output'] = existing_report.get('generated_report', {})
                    st.session_state['modified_report_output'] = existing_report.get('modified_report')
                    st.session_state['report_id_to_edit'] = existing_report.get('id')
                st.session_state['topics_loaded_for_week'] = True
            
    # æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆãŒãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯ã—ã¦è¡¨ç¤º
    loaded_stores = []
    for store_name in store_names:
        if st.session_state['daily_reports_input'][store_name]:
            # ç©ºã§ãªã„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            has_data = any(
                data.get('trend') or data.get('factors') 
                for data in st.session_state['daily_reports_input'][store_name].values()
                if isinstance(data, dict)
            )
            if has_data:
                loaded_stores.append(store_name)
    
    if loaded_stores:
        st.info(f"ğŸ“ ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {', '.join(loaded_stores)}åº—")
    else:
        # æ–°è¦ä½œæˆã®å ´åˆã€æ—¢å­˜ã®å…¥åŠ›ã¯ã‚¯ãƒªã‚¢ã—ãªã„ï¼ˆæ—¥ä»˜åˆ‡ã‚Šæ›¿ãˆæ™‚ã®ãƒ‡ãƒ¼ã‚¿æ®‹å­˜ã‚’é˜²ããŸã‚ï¼‰
        # ãŸã ã—ã€é¸æŠé€±ã‚’å¤‰æ›´ã—ãŸå ´åˆã¯å„å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å€¤ã‚’ãƒªã‚»ãƒƒãƒˆ
        if 'last_selected_monday' not in st.session_state or st.session_state['last_selected_monday'] != st.session_state['selected_monday']:
            # å…¨åº—èˆ—ã®daily_reports_inputã‚’åˆæœŸåŒ–
            for store_name in store_names:
                st.session_state['daily_reports_input'][store_name] = {
                    (monday_of_week + timedelta(days=i)).strftime('%Y-%m-%d'): {"trend": "", "factors": []} for i in range(7)
                }
            
            # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—§å½¢å¼ã‚‚åˆæœŸåŒ–
            st.session_state['topics_input'] = ""
            st.session_state['impact_day_input'] = ""
            st.session_state['quantitative_data_input'] = ""
            st.session_state['generated_report_output'] = None
            st.session_state['modified_report_output'] = None
            st.session_state['report_id_to_edit'] = None
            st.session_state['topics_loaded_for_week'] = False
            
            # æ–°ã—ã„é€±ã«å¤‰æ›´ã•ã‚ŒãŸå ´åˆã¯ã€æ”¹ã‚ã¦æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ï¼ˆçµ±ä¸€ã•ã‚ŒãŸæ–¹æ³•ï¼‰
            for store_name in store_names:
                store_id = db_manager.get_store_id_by_name(store_name)
                existing_report = db_manager.get_weekly_report(store_id, st.session_state['selected_monday'])
                
                if existing_report:
                    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ï¼ˆåº—èˆ—ã‚­ãƒ¼ãªã—ï¼‰ã§ç›´æ¥æ—¥ä»˜ãƒ‡ãƒ¼ã‚¿ã‚’è¨­å®š
                    if existing_report.get('daily_reports'):
                        st.session_state['daily_reports_input'][store_name] = existing_report['daily_reports']
                    
                    # é€±å…¨ä½“ã®è¿½åŠ æƒ…å ±ã‚’åº—èˆ—ã”ã¨ãƒ»é€±ã”ã¨ã«ä¿å­˜ï¼ˆæ­£ã—ã„é€±ã‚’ä½¿ç”¨ï¼‰
                    set_weekly_additional_data(store_name, st.session_state['selected_monday'], 'topics', existing_report.get('topics', ''))
                    set_weekly_additional_data(store_name, st.session_state['selected_monday'], 'impact_day', existing_report.get('impact_day', ''))
                    set_weekly_additional_data(store_name, st.session_state['selected_monday'], 'quantitative_data', existing_report.get('quantitative_data', ''))
                    
                    # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚‚åº—èˆ—ãƒ»é€±ã”ã¨ã«ä¿å­˜
                    set_weekly_report_output(store_name, st.session_state['selected_monday'], 'generated_report', existing_report.get('generated_report', {}))
                    set_weekly_report_output(store_name, st.session_state['selected_monday'], 'modified_report', existing_report.get('modified_report'))
                    set_weekly_report_output(store_name, st.session_state['selected_monday'], 'report_id', existing_report.get('id'))
                    
                    # ç¾åœ¨é¸æŠä¸­ã®åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã§æ—§å½¢å¼ã‚’æ›´æ–°
                    if store_name == st.session_state.get('selected_store_for_report', store_names[0]) and not st.session_state.get('topics_loaded_for_week'):
                        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—§å½¢å¼ã‚‚æ›´æ–°
                        st.session_state['topics_input'] = existing_report.get('topics', '')
                        st.session_state['impact_day_input'] = existing_report.get('impact_day', '')
                        st.session_state['quantitative_data_input'] = existing_report.get('quantitative_data', '')
                        st.session_state['generated_report_output'] = existing_report.get('generated_report', {})
                        st.session_state['modified_report_output'] = existing_report.get('modified_report')
                        st.session_state['report_id_to_edit'] = existing_report.get('id')
                        st.session_state['topics_loaded_for_week'] = True
        st.session_state['last_selected_monday'] = st.session_state['selected_monday']

    st.header("2. æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®å…¥åŠ›")
    st.markdown("å„åº—èˆ—ã®**æ—¥ã”ã¨ã®å‹•å‘ã¨è¦å› **ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚è¦å› ã¯è¤‡æ•°å…¥åŠ›å¯èƒ½ã§ã™ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ã€‚")
    
    # åº—èˆ—é¸æŠã‚’ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§æ˜ç¢ºã«ã™ã‚‹
    selected_store_for_input = st.radio(
        "**ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹åº—èˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„:**",
        store_names,
        index=store_names.index(st.session_state.get('selected_store_for_report', store_names[0])),
        horizontal=True
    )
    
    # é¸æŠã•ã‚ŒãŸåº—èˆ—ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®å‡¦ç†
    if selected_store_for_input != st.session_state.get('selected_store_for_report'):
        st.session_state['selected_store_for_report'] = selected_store_for_input
        
        # å¤‰æ›´ã•ã‚ŒãŸåº—èˆ—ã®æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        store_id = db_manager.get_store_id_by_name(selected_store_for_input)
        existing_report = db_manager.get_weekly_report(store_id, st.session_state['selected_monday'])
        
        if existing_report and existing_report.get('daily_reports'):
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯å¾©å…ƒ
            st.session_state['daily_reports_input'][selected_store_for_input] = existing_report['daily_reports']
        
        # é¸æŠã•ã‚ŒãŸåº—èˆ—ãƒ»é€±ã®ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ã‚’å¾©å…ƒ
        current_monday = st.session_state['selected_monday']
        st.session_state['generated_report_output'] = get_weekly_report_output(selected_store_for_input, current_monday, 'generated_report') or {}
        st.session_state['modified_report_output'] = get_weekly_report_output(selected_store_for_input, current_monday, 'modified_report')
        st.session_state['report_id_to_edit'] = get_weekly_report_output(selected_store_for_input, current_monday, 'report_id')
        
        # é€±å…¨ä½“ã®è¿½åŠ æƒ…å ±ã‚‚å¾©å…ƒ
        st.session_state['topics_input'] = get_weekly_additional_data(selected_store_for_input, current_monday, 'topics') or ''
        st.session_state['impact_day_input'] = get_weekly_additional_data(selected_store_for_input, current_monday, 'impact_day') or ''
        st.session_state['quantitative_data_input'] = get_weekly_additional_data(selected_store_for_input, current_monday, 'quantitative_data') or ''
        
        st.rerun()  # ç”»é¢ã‚’æ›´æ–°ã—ã¦æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
    else:
        # é¸æŠã•ã‚ŒãŸåº—èˆ—ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
        st.session_state['selected_store_for_report'] = selected_store_for_input
    
    st.markdown(f"**ç¾åœ¨é¸æŠä¸­:** {selected_store_for_input}åº—")
    
    # è‡ªå‹•ä¿å­˜çŠ¶æ³ã‚’è¡¨ç¤º
    if 'last_auto_save' not in st.session_state:
        st.session_state['last_auto_save'] = None
    if 'last_auto_save_timestamp' not in st.session_state:
        st.session_state['last_auto_save_timestamp'] = None
    
    if st.session_state['last_auto_save']:
        # ä¿å­˜ã‹ã‚‰ã®çµŒéæ™‚é–“ã‚’è¨ˆç®—
        if st.session_state['last_auto_save_timestamp']:
            current_time = get_japan_time().timestamp()
            elapsed_seconds = int(current_time - st.session_state['last_auto_save_timestamp'])
            
            if elapsed_seconds < 60:
                elapsed_text = f"ï¼ˆ{elapsed_seconds}ç§’å‰ï¼‰"
            elif elapsed_seconds < 3600:
                elapsed_minutes = elapsed_seconds // 60
                elapsed_text = f"ï¼ˆ{elapsed_minutes}åˆ†å‰ï¼‰"
            else:
                elapsed_hours = elapsed_seconds // 3600
                elapsed_text = f"ï¼ˆ{elapsed_hours}æ™‚é–“å‰ï¼‰"
        else:
            elapsed_text = ""
        
        st.success(f"âœ… è‡ªå‹•ä¿å­˜æ¸ˆã¿: {st.session_state['last_auto_save']} {elapsed_text}")
    else:
        st.info("ğŸ’¾ å…¥åŠ›å†…å®¹ã¯è‡ªå‹•çš„ã«ä¿å­˜ã•ã‚Œã¾ã™")
    
    st.markdown("---")

    # é¸æŠã•ã‚ŒãŸåº—èˆ—ã®daily_reports_inputã‚’ç¢ºå®Ÿã«åˆæœŸåŒ–
    if selected_store_for_input not in st.session_state['daily_reports_input']:
        st.session_state['daily_reports_input'][selected_store_for_input] = {
            (monday_of_week + timedelta(days=i)).strftime('%Y-%m-%d'): {"trend": "", "factors": []} for i in range(7)
        }

    # é¸æŠã•ã‚ŒãŸåº—èˆ—ã®æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆå…¥åŠ›æ¬„ã®ã¿ã‚’è¡¨ç¤º
    for j in range(7): # æœˆæ›œæ—¥ã‹ã‚‰æ—¥æ›œæ—¥ã¾ã§
        current_date = monday_of_week + timedelta(days=j)
        date_str = current_date.strftime('%Y-%m-%d')
        day_name = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"][j]

        st.subheader(f"ğŸ—“ï¸ {current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ({day_name})")
        
        # date_strè¾æ›¸ã®åˆæœŸåŒ–ã‚’ç¢ºä¿
        if date_str not in st.session_state['daily_reports_input'][selected_store_for_input]:
            st.session_state['daily_reports_input'][selected_store_for_input][date_str] = {"trend": "", "factors": []}
        
        # æ—¥æ¬¡å‹•å‘ï¼ˆä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºå®Ÿã«è¡¨ç¤ºï¼‰
        current_trend_value = st.session_state['daily_reports_input'][selected_store_for_input].get(date_str, {}).get('trend', '')
        trend_value = st.text_area(
            f"**{current_date.strftime('%m/%d')} å‹•å‘:**",
            value=current_trend_value,
            key=f"{selected_store_for_input}_{date_str}_trend",
            height=80
        )
        
        # å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã«è‡ªå‹•ä¿å­˜
        if trend_value != current_trend_value:
            st.session_state['daily_reports_input'][selected_store_for_input][date_str]['trend'] = trend_value
            
        # æ—¥æ¬¡è¦å› ï¼ˆä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’ç¢ºå®Ÿã«è¡¨ç¤ºï¼‰
        current_factors = st.session_state['daily_reports_input'][selected_store_for_input].get(date_str, {}).get('factors', [])
        factors_str = ", ".join(current_factors)
        new_factors_str = st.text_input(
            f"**{current_date.strftime('%m/%d')} è¦å›  (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š):**",
            value=factors_str,
            key=f"{selected_store_for_input}_{date_str}_factors"
        )
        
        # å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã«è‡ªå‹•ä¿å­˜
        new_factors_list = [f.strip() for f in new_factors_str.split(',') if f.strip()]
        if new_factors_list != current_factors:
            st.session_state['daily_reports_input'][selected_store_for_input][date_str]['factors'] = new_factors_list
    
    # æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿å…¥åŠ›å®Œäº†å¾Œã«è‡ªå‹•ä¿å­˜ï¼ˆå…¨ã¦ã®æ—¥ä»˜ã®å…¥åŠ›ãŒå®Œäº†ã—ã¦ã‹ã‚‰å®Ÿè¡Œï¼‰
    # ãƒ‡ãƒã‚¦ãƒ³ã‚¹å‡¦ç†: å…¥åŠ›ä¸­ã®ä¿å­˜ã‚’é¿ã‘ã‚‹ãŸã‚ã€å…¨æ—¥ä»˜ãƒ«ãƒ¼ãƒ—å®Œäº†å¾Œã«ä¸€åº¦ã ã‘ä¿å­˜
    auto_save_triggered = False
    for i in range(7):
        check_date = monday_of_week + timedelta(days=i)
        check_date_str = check_date.strftime('%Y-%m-%d')
        if (st.session_state['daily_reports_input'][selected_store_for_input].get(check_date_str, {}).get('trend') or 
            st.session_state['daily_reports_input'][selected_store_for_input].get(check_date_str, {}).get('factors')):
            auto_save_triggered = True
            break
    
    if auto_save_triggered:
        # ç¾åœ¨é¸æŠä¸­ã®åº—èˆ—ãƒ»é€±ã®è¿½åŠ æƒ…å ±ã‚’ä½¿ç”¨
        current_store = st.session_state['selected_store_for_report']
        current_monday = st.session_state['selected_monday']
        
        save_draft_data(
            current_store,
            current_monday,
            {current_store: st.session_state['daily_reports_input'][current_store]},
            get_weekly_additional_data(current_store, current_monday, 'topics') or st.session_state.get('topics_input', ''),
            get_weekly_additional_data(current_store, current_monday, 'impact_day') or st.session_state.get('impact_day_input', ''),
            get_weekly_additional_data(current_store, current_monday, 'quantitative_data') or st.session_state.get('quantitative_data_input', '')
        )
    
    st.markdown("---")

    st.header("3. é€±å…¨ä½“ã®è¿½åŠ æƒ…å ± (ä»»æ„)")
    
    # ç¾åœ¨é¸æŠä¸­ã®åº—èˆ—ã¨é€±ã«åŸºã¥ã„ã¦å€¤ã‚’å–å¾—
    current_store = st.session_state['selected_store_for_report']
    current_monday = st.session_state['selected_monday']
    
    # ç¾åœ¨ã®å€¤ã‚’æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‹ã‚‰å–å¾—ï¼ˆå¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—§å½¢å¼ã‚‚ç¢ºèªï¼‰
    current_topics = get_weekly_additional_data(current_store, current_monday, 'topics') or st.session_state.get('topics_input', '')
    current_impact_day = get_weekly_additional_data(current_store, current_monday, 'impact_day') or st.session_state.get('impact_day_input', '')
    current_quantitative_data = get_weekly_additional_data(current_store, current_monday, 'quantitative_data') or st.session_state.get('quantitative_data_input', '')
    
    # TOPICSå…¥åŠ›
    new_topics = st.text_area(
        f"**TOPICS ({current_store}åº—ç”¨):** é€±å…¨ä½“ã‚’é€šã—ã¦ç‰¹ç­†ã™ã¹ãäº‹é …ã‚„å‡ºæ¥äº‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        value=current_topics,
        height=100,
        key="topics_input_field"
    )
    if new_topics != current_topics:
        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«ä¿å­˜
        set_weekly_additional_data(current_store, current_monday, 'topics', new_topics)
        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—§å½¢å¼ã‚‚æ›´æ–°
        st.session_state['topics_input'] = new_topics
        # è‡ªå‹•ä¿å­˜
        if save_draft_data(
            current_store,
            current_monday,
            {current_store: st.session_state['daily_reports_input'][current_store]},
            new_topics,
            get_weekly_additional_data(current_store, current_monday, 'impact_day') or st.session_state.get('impact_day_input', ''),
            get_weekly_additional_data(current_store, current_monday, 'quantitative_data') or st.session_state.get('quantitative_data_input', '')
        ):
            st.rerun()  # ä¿å­˜å¾Œã«ç”»é¢ã‚’æ›´æ–°ã—ã¦æ™‚åˆ»ã‚’è¡¨ç¤º
    
    # ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§å…¥åŠ›
    new_impact_day = st.text_area(
        f"**ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ ({current_store}åº—ç”¨):** ç‰¹ã«å½±éŸ¿ã®å¤§ãã‹ã£ãŸæ—¥ã‚„ã‚¤ãƒ™ãƒ³ãƒˆã€ãã®å†…å®¹ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚",
        value=current_impact_day,
        height=100,
        key="impact_day_input_field"
    )
    if new_impact_day != current_impact_day:
        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«ä¿å­˜
        set_weekly_additional_data(current_store, current_monday, 'impact_day', new_impact_day)
        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—§å½¢å¼ã‚‚æ›´æ–°
        st.session_state['impact_day_input'] = new_impact_day
        # è‡ªå‹•ä¿å­˜
        if save_draft_data(
            current_store,
            current_monday,
            {current_store: st.session_state['daily_reports_input'][current_store]},
            get_weekly_additional_data(current_store, current_monday, 'topics') or st.session_state.get('topics_input', ''),
            new_impact_day,
            get_weekly_additional_data(current_store, current_monday, 'quantitative_data') or st.session_state.get('quantitative_data_input', '')
        ):
            st.rerun()  # ä¿å­˜å¾Œã«ç”»é¢ã‚’æ›´æ–°
    
    # å®šé‡ãƒ‡ãƒ¼ã‚¿å…¥åŠ›
    new_quantitative_data = st.text_area(
        f"**å®šé‡ãƒ‡ãƒ¼ã‚¿ ({current_store}åº—ç”¨):** å£²ä¸Šã€å®¢æ•°ã€å®¢å˜ä¾¡ã€ãƒ—ãƒ­ãƒ‘ãƒ¼æ¶ˆåŒ–ç‡ãªã©ã€é€±ã®å®šé‡ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        value=current_quantitative_data,
        height=100,
        key="quantitative_data_input_field"
    )
    if new_quantitative_data != current_quantitative_data:
        # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«ä¿å­˜
        set_weekly_additional_data(current_store, current_monday, 'quantitative_data', new_quantitative_data)
        # å¾Œæ–¹äº’æ›æ€§ã®ãŸã‚æ—§å½¢å¼ã‚‚æ›´æ–°
        st.session_state['quantitative_data_input'] = new_quantitative_data
        # è‡ªå‹•ä¿å­˜
        if save_draft_data(
            current_store,
            current_monday,
            {current_store: st.session_state['daily_reports_input'][current_store]},
            get_weekly_additional_data(current_store, current_monday, 'topics') or st.session_state.get('topics_input', ''),
            get_weekly_additional_data(current_store, current_monday, 'impact_day') or st.session_state.get('impact_day_input', ''),
            new_quantitative_data
        ):
            st.rerun()  # ä¿å­˜å¾Œã«ç”»é¢ã‚’æ›´æ–°

    st.markdown("---")

    # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒœã‚¿ãƒ³
    st.header("4. ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›")
    
    if st.button("å‡ºåŠ›", type="primary"):
        try:
            # AIç”Ÿæˆç”¨ã«æ•´å½¢ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
            # daily_reports_input ã¯å…¨åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒã£ã¦ã„ã‚‹ãŸã‚ã€ç¾åœ¨é¸æŠä¸­ã®åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æ¸¡ã™
            selected_store_name = st.session_state['selected_store_for_report']
            
            # ç¾åœ¨é¸æŠä¸­ã®åº—èˆ—ãƒ»é€±ã®è¿½åŠ æƒ…å ±ã‚’å–å¾—
            current_monday_str = st.session_state['selected_monday']
            topics_data = get_weekly_additional_data(selected_store_name, current_monday_str, 'topics') or st.session_state.get('topics_input', '')
            impact_day_data = get_weekly_additional_data(selected_store_name, current_monday_str, 'impact_day') or st.session_state.get('impact_day_input', '')
            quantitative_data_data = get_weekly_additional_data(selected_store_name, current_monday_str, 'quantitative_data') or st.session_state.get('quantitative_data_input', '')
            
            data_for_ai = {
                'daily_reports': {selected_store_name: st.session_state['daily_reports_input'][selected_store_name]},
                'topics': topics_data,
                'impact_day': impact_day_data,
                'quantitative_data': quantitative_data_data
            }

            # APIã‚­ãƒ¼ã®ç¢ºèªï¼ˆçµ¶å¯¾ãƒ‘ã‚¹ä½¿ç”¨ã§ç¢ºå®Ÿã«èª­ã¿è¾¼ã¿ï¼‰
            script_dir = pathlib.Path(__file__).parent.absolute()
            env_path = script_dir / '.env'
            load_dotenv(dotenv_path=env_path, override=True)
            openai_api_key = os.getenv("OPENAI_API_KEY")
            
            if not openai_api_key:
                st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«APIã‚­ãƒ¼ã®è¨­å®šã‚’ä¾é ¼ã—ã¦ãã ã•ã„ã€‚")
                st.info("ç®¡ç†è€…ã®æ–¹ã¯ã€`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã«`OPENAI_API_KEY=your_api_key_here`ã®å½¢å¼ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
                return
            
            # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
            if not report_generator.initialize_openai(openai_api_key):
                # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ initialize_openai å†…ã§è¡¨ç¤ºæ¸ˆã¿
                st.warning("ğŸ’¡ **OpenAI APIã‚­ãƒ¼ã®ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°:**")
                with st.expander("APIã‚­ãƒ¼ã®ç¢ºèªãƒ»æ›´æ–°æ–¹æ³•", expanded=True):
                    st.markdown("""
                **1. OpenAI Platform ã«ã‚¢ã‚¯ã‚»ã‚¹:**
                - https://platform.openai.com/ ã«ã‚¢ã‚¯ã‚»ã‚¹
                - ã‚¢ã‚«ã‚¦ãƒ³ãƒˆã«ãƒ­ã‚°ã‚¤ãƒ³
                
                **2. APIã‚­ãƒ¼ã®ç¢ºèª:**
                - å·¦ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®ã€ŒAPI Keysã€ã‚’ã‚¯ãƒªãƒƒã‚¯
                - æ—¢å­˜ã®ã‚­ãƒ¼ãŒæœ‰åŠ¹ã‹ç¢ºèªï¼ˆä½¿ç”¨åˆ¶é™ã‚„ã‚¯ãƒ¬ã‚¸ãƒƒãƒˆæ®‹é«˜ã‚‚ç¢ºèªï¼‰
                
                **3. æ–°ã—ã„APIã‚­ãƒ¼ã®ä½œæˆï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰:**
                - ã€ŒCreate new secret keyã€ã‚’ã‚¯ãƒªãƒƒã‚¯
                - åå‰ã‚’ä»˜ã‘ã¦ä½œæˆ
                - ç”Ÿæˆã•ã‚ŒãŸã‚­ãƒ¼ã‚’ã‚³ãƒ”ãƒ¼ï¼ˆ`sk-proj-`ã§å§‹ã¾ã‚‹æ–‡å­—åˆ—ï¼‰
                
                **4. .envãƒ•ã‚¡ã‚¤ãƒ«ã®æ›´æ–°:**
                    - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ•ã‚©ãƒ«ãƒ€ã®`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é–‹ã
                    - `OPENAI_API_KEY=æ–°ã—ã„ã‚­ãƒ¼`ã®å½¢å¼ã§æ›´æ–°
                    - ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä¿å­˜
                    
                    **5. ã‚¢ãƒ—ãƒªã®å†èµ·å‹•:**
                    - Streamlitã‚¢ãƒ—ãƒªã‚’å†èµ·å‹•ã—ã¦ãã ã•ã„
                    """)
                return

            with st.spinner("AIãŒãƒ¬ãƒãƒ¼ãƒˆã‚’åˆ†æãƒ»ç”Ÿæˆä¸­ã§ã™... å°‘ã€…ãŠå¾…ã¡ãã ã•ã„ã€‚"):
                generated_report = report_generator.analyze_trend_factors(
                    data_for_ai['daily_reports'], # ã“ã“ã§ã¯ã™ã§ã«é¸æŠã•ã‚ŒãŸåº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ãŒæ¸¡ã•ã‚Œã‚‹
                    data_for_ai['topics'],
                    data_for_ai['impact_day'],
                    data_for_ai['quantitative_data']
                )

                if generated_report:
                    st.session_state['generated_report_output'] = generated_report
                    st.session_state['modified_report_output'] = None # AIç”Ÿæˆæ™‚ã«ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆã¯ã‚¯ãƒªã‚¢
                    
                    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«ã‚‚ä¿å­˜
                    current_store_name = st.session_state['selected_store_for_report']
                    current_monday = st.session_state['selected_monday']
                    set_weekly_report_output(current_store_name, current_monday, 'generated_report', generated_report)
                    set_weekly_report_output(current_store_name, current_monday, 'modified_report', None)
                    
                    # å¤ã„ä¿®æ­£å†…å®¹ã‚‚ã‚¯ãƒªã‚¢
                    clear_saved_modifications()
                    
                    # è‡ªå‹•çš„ã«ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜
                    store_id = db_manager.get_store_id_by_name(st.session_state['selected_store_for_report'])
                    monday_date_str = st.session_state['selected_monday']
                    current_store_name = st.session_state['selected_store_for_report']
                    
                    # ç¾åœ¨é¸æŠä¸­ã®åº—èˆ—ãƒ»é€±ã®è¿½åŠ æƒ…å ±ã‚’å–å¾—
                    topics_to_save = get_weekly_additional_data(current_store_name, monday_date_str, 'topics') or st.session_state.get('topics_input', '')
                    impact_day_to_save = get_weekly_additional_data(current_store_name, monday_date_str, 'impact_day') or st.session_state.get('impact_day_input', '')
                    quantitative_data_to_save = get_weekly_additional_data(current_store_name, monday_date_str, 'quantitative_data') or st.session_state.get('quantitative_data_input', '')
                    
                    data_to_save = {
                        'daily_reports': st.session_state['daily_reports_input'][current_store_name],
                        'topics': topics_to_save,
                        'impact_day': impact_day_to_save,
                        'quantitative_data': quantitative_data_to_save
                    }
                    
                    is_updated = db_manager.save_weekly_data(
                        store_id,
                        monday_date_str,
                        data_to_save,
                        st.session_state['generated_report_output'],
                        st.session_state['modified_report_output']
                    )
                    
                    st.session_state['report_id_to_edit'] = db_manager.get_weekly_report(store_id, monday_date_str).get('id')
                    
                    # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«ã‚‚report_idã‚’ä¿å­˜
                    set_weekly_report_output(current_store_name, monday_date_str, 'report_id', st.session_state['report_id_to_edit'])
                    
                    if is_updated:
                        st.success("âœ… AIãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã€è‡ªå‹•ä¿å­˜ã•ã‚Œã¾ã—ãŸï¼ˆæ›´æ–°ï¼‰")
                    else:
                        st.success("âœ… AIãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã€è‡ªå‹•ä¿å­˜ã•ã‚Œã¾ã—ãŸï¼ˆæ–°è¦ï¼‰")
                else:
                    st.error("AIãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å…¥åŠ›å†…å®¹ã‚’ç¢ºèªã™ã‚‹ã‹ã€å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
                    
        except Exception as e:
            st.error(f"ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")

    if st.session_state['generated_report_output']:
        st.subheader("ç”Ÿæˆã•ã‚ŒãŸé€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ (AIç”Ÿæˆ)")
        st.markdown("**é€±å…¨ä½“ã®å‹•å‘ã¨è¦å› :**")
        
        # å®‰å…¨ãªã‚¢ã‚¯ã‚»ã‚¹ã«ä¿®æ­£
        report_output = st.session_state['generated_report_output']
        if isinstance(report_output, dict):
            st.write(report_output.get('trend', ''))
            st.markdown("**ä¸»ãªè¦å› :**")
            for i, factor in enumerate(report_output.get('factors', [])):
                st.write(f"- {factor}")
            
            if report_output.get('questions'):
                st.markdown("**AIã‹ã‚‰ã®è³ªå•:**")
                for q in report_output.get('questions', []):
                    st.write(f"- {q}")
        else:
            st.write("ãƒ¬ãƒãƒ¼ãƒˆã®å½¢å¼ãŒæ­£ã—ãã‚ã‚Šã¾ã›ã‚“ã€‚å†åº¦ç”Ÿæˆã—ã¦ãã ã•ã„ã€‚")

    st.markdown("---")

    # ãƒ¬ãƒãƒ¼ãƒˆä¿®æ­£ã‚¨ãƒªã‚¢ (ç”Ÿæˆæ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º)
    if st.session_state['generated_report_output'] or st.session_state['modified_report_output']:
        st.header("5. ãƒ¬ãƒãƒ¼ãƒˆã®ä¿®æ­£ã¨å­¦ç¿’ (ä»»æ„)")
        st.info("AIãŒç”Ÿæˆã—ãŸãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿®æ­£ã—ã€ã€Œä¿®æ­£ã—ã¦å­¦ç¿’ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€ã‚·ã‚¹ãƒ†ãƒ ãŒãã®ä¿®æ­£ã‹ã‚‰å­¦ã³ã€å°†æ¥ã®ãƒ¬ãƒãƒ¼ãƒˆç²¾åº¦å‘ä¸Šã«å½¹ç«‹ã¦ã¾ã™ã€‚")

        report_to_display = st.session_state['modified_report_output'] if st.session_state['modified_report_output'] else st.session_state['generated_report_output']

        # ä¿å­˜ã•ã‚ŒãŸä¿®æ­£å†…å®¹ãŒã‚ã‚‹å ´åˆã¯ãã‚Œã‚’ä½¿ç”¨ã€ãªã‘ã‚Œã°å…ƒã®ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ã‚’ä½¿ç”¨
        default_trend = get_saved_modification('trend') or report_to_display.get('trend', '')
        default_factors = get_saved_modification('factors') or ", ".join(report_to_display.get('factors', []))
        default_questions = get_saved_modification('questions') or "\n".join(report_to_display.get('questions', []))
        default_edit_reason = get_saved_modification('edit_reason')

        modified_trend = st.text_area(
            "**ä¿®æ­£å¾Œã®é€±å…¨ä½“ã®å‹•å‘ã¨è¦å› :**",
            value=default_trend,
            key="modified_trend_input",
            height=200,
            on_change=auto_save_modification
        )
        modified_factors_str = st.text_input(
            "**ä¿®æ­£å¾Œã®ä¸»ãªè¦å›  (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š):**",
            value=default_factors,
            key="modified_factors_input",
            on_change=auto_save_modification
        )
        modified_questions_str = st.text_area(
            "**ä¿®æ­£å¾Œã®AIã¸ã®è³ªå•:**",
            value=default_questions,
            key="modified_questions_input",
            height=100,
            on_change=auto_save_modification
        )
        edit_reason = st.text_area(
            "**ä¿®æ­£ç†ç”± (å­¦ç¿’ã®ãŸã‚ã«é‡è¦ã§ã™):** ä½•ã‚’ã€ãªãœä¿®æ­£ã—ãŸã®ã‹ã‚’å…·ä½“çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚",
            value=default_edit_reason,
            key="edit_reason_input",
            height=100,
            on_change=auto_save_modification
        )
        
        modified_factors = [f.strip() for f in modified_factors_str.split(',') if f.strip()]
        modified_questions = [q.strip() for q in modified_questions_str.split('\n') if q.strip()]

        if st.button("ä¿®æ­£ã—ã¦å­¦ç¿’", type="primary", key="learn_from_correction_button"):
            if not edit_reason.strip():
                st.error("ä¿®æ­£ç†ç”±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã¯AIã®å­¦ç¿’ã«ä¸å¯æ¬ ã§ã™ã€‚")
            else:
                modified_report_data = {
                    "trend": modified_trend,
                    "factors": modified_factors,
                    "questions": modified_questions,
                    "edit_reason": edit_reason
                }
                st.session_state['modified_report_output'] = modified_report_data

                # æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã«ã‚‚ä¿å­˜
                current_store_name = st.session_state['selected_store_for_report']
                current_monday = st.session_state['selected_monday']
                set_weekly_report_output(current_store_name, current_monday, 'modified_report', modified_report_data)

                store_id = db_manager.get_store_id_by_name(st.session_state['selected_store_for_report'])
                monday_date_str = st.session_state['selected_monday']
                current_store_name = st.session_state['selected_store_for_report']
                
                # session_stateã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºä¿
                if 'daily_reports_input' not in st.session_state:
                    st.session_state['daily_reports_input'] = {}
                if current_store_name not in st.session_state['daily_reports_input']:
                    st.session_state['daily_reports_input'][current_store_name] = {}
                
                # ç¾åœ¨é¸æŠä¸­ã®åº—èˆ—ãƒ»é€±ã®è¿½åŠ æƒ…å ±ã‚’å–å¾—
                topics_for_learning = get_weekly_additional_data(current_store_name, monday_date_str, 'topics') or st.session_state.get('topics_input', '')
                impact_day_for_learning = get_weekly_additional_data(current_store_name, monday_date_str, 'impact_day') or st.session_state.get('impact_day_input', '')
                quantitative_data_for_learning = get_weekly_additional_data(current_store_name, monday_date_str, 'quantitative_data') or st.session_state.get('quantitative_data_input', '')
                
                input_data_for_learning = {
                    'daily_reports': {current_store_name: st.session_state['daily_reports_input'][current_store_name]},
                    'topics': topics_for_learning,
                    'impact_day': impact_day_for_learning,
                    'quantitative_data': quantitative_data_for_learning
                }

                # DBã«ä¿å­˜ã—ã€å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã«æ¸¡ã™
                is_updated = db_manager.save_weekly_data(
                    store_id,
                    monday_date_str,
                    input_data_for_learning, # daily_reports_inputã‚’ç›´æ¥æ¸¡ã™
                    st.session_state['generated_report_output'],
                    modified_report_data
                )
                
                learning_engine.learn_from_correction(
                    input_data=input_data_for_learning,
                    original_output=st.session_state['generated_report_output'],
                    modified_output=modified_report_data
                )
                
                # ä¿®æ­£å†…å®¹ã®ä¿å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
                clear_saved_modifications()
                
                if is_updated:
                    st.success("âœ… ä¿®æ­£å†…å®¹ãŒä¿å­˜ã•ã‚Œã€ã‚·ã‚¹ãƒ†ãƒ ãŒå­¦ç¿’ã—ã¾ã—ãŸï¼ï¼ˆãƒ‡ãƒ¼ã‚¿æ›´æ–°ï¼‰")
                else:
                    st.success("âœ… ä¿®æ­£å†…å®¹ãŒä¿å­˜ã•ã‚Œã€ã‚·ã‚¹ãƒ†ãƒ ãŒå­¦ç¿’ã—ã¾ã—ãŸï¼ï¼ˆæ–°è¦ä¿å­˜ï¼‰")
                st.rerun()


def show_report_history_page():
    st.title("ğŸ“š ãƒ¬ãƒãƒ¼ãƒˆå±¥æ­´")
    st.markdown("---")

    st.info("ã“ã“ã§ã¯ã€ã“ã‚Œã¾ã§ã«ä½œæˆãƒ»ä¿å­˜ã•ã‚ŒãŸé€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®ä¸€è¦§ã‚’ç¢ºèªã§ãã¾ã™ã€‚")

    all_stores = db_manager.get_all_stores()
    store_names = [s[1] for s in all_stores]
    store_id_map = {s[1]: s[0] for s in all_stores}

    selected_store_name = st.selectbox("è¡¨ç¤ºã™ã‚‹åº—èˆ—ã‚’é¸æŠ:", ["å…¨åº—èˆ—"] + store_names)

    if selected_store_name == "å…¨åº—èˆ—":
        reports = db_manager.get_all_weekly_reports()
    else:
        selected_store_id = store_id_map[selected_store_name]
        reports = db_manager.get_all_weekly_reports(selected_store_id)

    if not reports:
        st.warning("è¡¨ç¤ºã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    report_data = []
    for r in reports:
        # store_name ã¯æ—¢ã« DBManager ã§è¿½åŠ ã•ã‚Œã¦ã„ã‚‹ã¯ãš
        try:
            store_name = db_manager.get_store_name_by_id(r['store_id'])
        except Exception as e:
            store_name = f"åº—èˆ—ID:{r['store_id']}"
            
        report_data.append({
            "ID": r['id'],
            "åº—èˆ—å": store_name,
            "é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ (æœˆæ›œæ—¥)": r['monday_date'],
            "æœ€çµ‚æ›´æ–°æ—¥æ™‚": datetime.fromisoformat(r['timestamp']).strftime('%Y/%m/%d %H:%M'),
            "AIç”Ÿæˆæ¸ˆã¿": "ã¯ã„" if r['has_generated'] else "ã„ã„ãˆ",
            "ä¿®æ­£æ¸ˆã¿": "ã¯ã„" if r['has_modified'] else "ã„ã„ãˆ",
            "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰": f"Download_{r['id']}" # ãƒ€ãƒŸãƒ¼ã®åˆ—å
        })
    
    df = pd.DataFrame(report_data)

    st.dataframe(df.set_index('ID'), use_container_width=True)

    # ãƒ¬ãƒãƒ¼ãƒˆè©³ç´°è¡¨ç¤ºãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    st.subheader("ãƒ¬ãƒãƒ¼ãƒˆã®è©³ç´°è¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    report_ids = [r['id'] for r in reports]
    
    if report_ids:
        selected_report_id = st.selectbox("è©³ç´°ã‚’è¡¨ç¤ºãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆã®IDã‚’é¸æŠã—ã¦ãã ã•ã„:", report_ids)

        if selected_report_id:
            # IDã®å‹ã‚’ç¢ºèªãƒ»ä¿®æ­£ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ•´æ•°ã«å¤‰æ›ï¼‰
            try:
                selected_report_id = int(selected_report_id)
            except (ValueError, TypeError):
                pass  # ã™ã§ã«é©åˆ‡ãªå‹ã®å ´åˆã¯ãã®ã¾ã¾
                
            # é¸æŠã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆIDãŒå®Ÿéš›ã«ãƒªã‚¹ãƒˆã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if selected_report_id not in report_ids:
                st.error(f"é¸æŠã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆID {selected_report_id} ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
                return
                
            selected_report_db = next((r for r in reports if r['id'] == selected_report_id), None)
            
            if not selected_report_db:
                st.error(f"ãƒ¬ãƒãƒ¼ãƒˆID {selected_report_id} ã®æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                return
                
            # DBã‹ã‚‰æœ€æ–°ã®å®Œå…¨ãªãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—
            try:
                full_report = db_manager.get_weekly_report(selected_report_db['store_id'], selected_report_db['monday_date'])
                
                if not full_report:
                    st.error(f"ãƒ¬ãƒãƒ¼ãƒˆID {selected_report_id} ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                    return
                    
            except Exception as e:
                st.error(f"ãƒ¬ãƒãƒ¼ãƒˆå–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                return
                
            if full_report:
                st.markdown(f"### ãƒ¬ãƒãƒ¼ãƒˆID: {full_report['id']} - {db_manager.get_store_name_by_id(full_report['store_id'])}åº— - é€±æ¬¡: {full_report['monday_date']}")
                st.write(f"æœ€çµ‚æ›´æ–°æ—¥æ™‚: {datetime.fromisoformat(full_report['timestamp']).strftime('%Y/%m/%d %H:%M')}")

                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒ‡ãƒ¼ã‚¿æ•´å½¢ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰
                export_data = {
                    "ãƒ¬ãƒãƒ¼ãƒˆå¯¾è±¡é€±ã®æœˆæ›œæ—¥": full_report.get('monday_date', ''),
                    "åº—èˆ—å": db_manager.get_store_name_by_id(full_report.get('store_id', 0)),
                    "TOPICS": full_report.get('topics', ''),
                    "ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§": full_report.get('impact_day', ''),
                    "å®šé‡ãƒ‡ãƒ¼ã‚¿": full_report.get('quantitative_data', '')
                }
                
                # ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨ãªå–å¾—
                generated_report = full_report.get('generated_report', {})
                if isinstance(generated_report, dict):
                    export_data.update({
                        "AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ_å‹•å‘": generated_report.get('trend', ''),
                        "AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ_è¦å› ": ", ".join(generated_report.get('factors', [])) if generated_report.get('factors') else '',
                        "AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ_è³ªå•": "\n".join(generated_report.get('questions', [])) if generated_report.get('questions') else ''
                    })
                
                # ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨ãªå–å¾—
                modified_report = full_report.get('modified_report')
                if isinstance(modified_report, dict):
                    export_data.update({
                        "ä¿®æ­£å¾Œãƒ¬ãƒãƒ¼ãƒˆ_å‹•å‘": modified_report.get('trend', ''),
                        "ä¿®æ­£å¾Œãƒ¬ãƒãƒ¼ãƒˆ_è¦å› ": ", ".join(modified_report.get('factors', [])) if modified_report.get('factors') else '',
                        "ä¿®æ­£å¾Œãƒ¬ãƒãƒ¼ãƒˆ_è³ªå•": "\n".join(modified_report.get('questions', [])) if modified_report.get('questions') else '',
                        "ä¿®æ­£ç†ç”±": modified_report.get('edit_reason', '')
                    })
                
                # æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®è©³ç´°ã‚’å®‰å…¨ã«è¿½åŠ 
                daily_reports = full_report.get('daily_reports', {})
                if isinstance(daily_reports, dict):
                    for store_name, dates_data in daily_reports.items():
                        if isinstance(dates_data, dict):
                            for date_str, report_data in dates_data.items():
                                try:
                                    if isinstance(report_data, dict):
                                        export_data[f"æ—¥æ¬¡å‹•å‘_{store_name}_{date_str}"] = str(report_data.get('trend', ''))
                                        factors = report_data.get('factors', [])
                                        export_data[f"æ—¥æ¬¡è¦å› _{store_name}_{date_str}"] = ", ".join(factors) if isinstance(factors, list) else str(factors)
                                    else:
                                        export_data[f"æ—¥æ¬¡å‹•å‘_{store_name}_{date_str}"] = ''
                                        export_data[f"æ—¥æ¬¡è¦å› _{store_name}_{date_str}"] = ''
                                except Exception as e:
                                    print(f"æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                                    export_data[f"æ—¥æ¬¡å‹•å‘_{store_name}_{date_str}"] = ''
                                    export_data[f"æ—¥æ¬¡è¦å› _{store_name}_{date_str}"] = ''

                df_export = pd.DataFrame([export_data])
                
                # Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
                try:
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df_export.to_excel(writer, index=False, sheet_name='ãƒ¬ãƒãƒ¼ãƒˆ')
                    excel_data = output.getvalue()
                    
                    st.download_button(
                        label="ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆã‚’Excelã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=excel_data,
                        file_name=f"é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ_{full_report['monday_date']}_{db_manager.get_store_name_by_id(full_report['store_id'])}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except ImportError:
                    st.warning("âš ï¸ Excelå½¢å¼ã§ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒã§ãã¾ã›ã‚“ã€‚CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                    # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦æä¾›
                    csv_data = df_export.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=csv_data,
                        file_name=f"é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ_{full_report['monday_date']}_{db_manager.get_store_name_by_id(full_report['store_id'])}.csv",
                        mime="text/csv"
                    )

                st.markdown("#### ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                
                # ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º
                modified_report = full_report.get('modified_report')
                if modified_report and isinstance(modified_report, dict):
                    st.subheader("--- æœ€çµ‚ä¿®æ­£ç‰ˆãƒ¬ãƒãƒ¼ãƒˆ ---")
                    st.markdown("**é€±å…¨ä½“ã®å‹•å‘ã¨è¦å› :**")
                    st.write(modified_report.get('trend', ''))
                    st.markdown("**ä¸»ãªè¦å› :**")
                    factors = modified_report.get('factors', [])
                    if isinstance(factors, list):
                        for factor in factors:
                            st.write(f"- {factor}")
                    
                    questions = modified_report.get('questions', [])
                    if questions and isinstance(questions, list):
                        st.markdown("**AIã¸ã®è³ªå•:**")
                        for q in questions:
                                st.write(f"- {q}")
                    
                    edit_reason = modified_report.get('edit_reason')
                    if edit_reason:
                        st.markdown("**ä¿®æ­£ç†ç”±:**")
                        st.write(edit_reason)
                
                # ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º
                generated_report = full_report.get('generated_report')
                if generated_report and isinstance(generated_report, dict):
                    st.subheader("--- AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ (ã‚ªãƒªã‚¸ãƒŠãƒ«) ---")
                    st.markdown("**é€±å…¨ä½“ã®å‹•å‘ã¨è¦å› :**")
                    st.write(generated_report.get('trend', ''))
                    st.markdown("**ä¸»ãªè¦å› :**")
                    factors = generated_report.get('factors', [])
                    if isinstance(factors, list):
                        for factor in factors:
                            st.write(f"- {factor}")
                    
                    questions = generated_report.get('questions', [])
                    if questions and isinstance(questions, list):
                        st.markdown("**AIã‹ã‚‰ã®è³ªå•:**")
                        for q in questions:
                            st.write(f"- {q}")
                
                st.subheader("--- å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ ---")
                st.markdown("**æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ:**")
                daily_reports = full_report.get('daily_reports', {})
                if daily_reports and isinstance(daily_reports, dict):
                    for store_name, dates_data in daily_reports.items():
                        st.markdown(f"**{store_name}åº—**")
                        if isinstance(dates_data, dict):
                            has_data = False
                            for date_str, report_data in dates_data.items():
                                try:
                                    if isinstance(report_data, dict):
                                        trend_text = report_data.get('trend', '').strip()
                                        factors_list = report_data.get('factors', [])
                                        
                                        # å‹•å‘ã¾ãŸã¯è¦å› ã®ã„ãšã‚Œã‹ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º
                                        if trend_text or (factors_list and len(factors_list) > 0):
                                            has_data = True
                                            if isinstance(factors_list, list):
                                                factors_text = ', '.join(factors_list) if factors_list else 'è¦å› ãªã—'
                                            else:
                                                factors_text = str(factors_list) if factors_list else 'è¦å› ãªã—'
                                            
                                            st.markdown(f"  - **{date_str}**")
                                            if trend_text:
                                                st.markdown(f"    å‹•å‘: {trend_text}")
                                            if factors_list:
                                                st.markdown(f"    è¦å› : {factors_text}")
                                            else:
                                                st.markdown(f"    è¦å› : è¦å› ãªã—")
                                    else:
                                        st.markdown(f"  - {date_str} ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚¨ãƒ©ãƒ¼")
                                except Exception as e:
                                    st.markdown(f"  - {date_str} ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼")
                            
                            if not has_data:
                                st.markdown("  - ã“ã®åº—èˆ—ã«ã¯å…¥åŠ›æ¸ˆã¿ã®æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                        else:
                            st.markdown("  - ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚¨ãƒ©ãƒ¼")
                else:
                    st.markdown("æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

                st.markdown("**TOPICS:**")
                st.write(full_report.get('topics', 'N/A'))
                st.markdown("**ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§:**")
                st.write(full_report.get('impact_day', 'N/A'))
                st.markdown("**å®šé‡ãƒ‡ãƒ¼ã‚¿:**")
                st.write(full_report.get('quantitative_data', 'N/A'))
            else:
                st.warning("é¸æŠã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã®è©³ç´°ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.info("ãƒ¬ãƒãƒ¼ãƒˆå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

def show_settings_page():
    st.title("âš™ï¸ è¨­å®š")
    st.markdown("---")

    st.subheader("OpenAI APIã‚­ãƒ¼è¨­å®š")
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ç¾åœ¨ã®APIã‚­ãƒ¼ã®è¨­å®šçŠ¶æ³ã‚’ç¢ºèª
    current_api_key = os.getenv("OPENAI_API_KEY", "")
    
    if current_api_key:
        st.success("âœ… OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚")
        st.info("APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚å¤‰æ›´ãŒå¿…è¦ãªå ´åˆã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚")
    else:
        st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.warning("ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«OpenAI APIã‚­ãƒ¼ã®è¨­å®šã‚’ä¾é ¼ã—ã¦ãã ã•ã„ã€‚")
        st.markdown("""
        **ç®¡ç†è€…å‘ã‘è¨­å®šæ‰‹é †:**
        1. `.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã¾ãŸã¯ç·¨é›†
        2. `OPENAI_API_KEY=your_api_key_here` ã®å½¢å¼ã§APIã‚­ãƒ¼ã‚’è¨­å®š
        3. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•
        """)

    st.markdown("---")

    st.subheader("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç®¡ç† (é–‹ç™ºä¸­)")
    st.info("AIã®ç²¾åº¦å‘ä¸Šã«ä½¿ç”¨ã•ã‚Œã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã—ã¾ã™ã€‚")

    try:
        learning_stats = db_manager.get_learning_stats()
        st.write(f"ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ¬ãƒãƒ¼ãƒˆæ•°: **{learning_stats['total_reports']}**")
        st.write(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¿®æ­£æ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆæ•°: **{learning_stats['corrections']}**")
        st.write(f"å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: **{learning_stats['patterns']}**")
    except Exception as e:
        st.error(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
        st.info("ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®åˆæœŸåŒ–ãŒå¿…è¦ãªå¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½ (ä¾‹)
    st.markdown("---")
    st.subheader("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    if st.button("å…¨å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (é–‹ç™ºè€…å‘ã‘)"):
        # ä»®ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå®Ÿéš›ã«ã¯learning_patternsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—ï¼‰
        conn = db_manager._get_connection()
        learning_data_df = pd.read_sql_query("SELECT * FROM learning_patterns", conn)
        conn.close()

        if not learning_data_df.empty:
            st.download_button(
                label="å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=learning_data_df.to_csv(index=False, encoding='utf-8-sig'),
                file_name="learning_data_export.csv",
                mime="text/csv"
            )
            st.success("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        else:
            st.warning("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


# ãƒ¡ã‚¤ãƒ³ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
st.sidebar.title("ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")

selection = st.sidebar.radio("Go to", ["é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ", "ãƒ¬ãƒãƒ¼ãƒˆå±¥æ­´", "è¨­å®š"])

if selection == "é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ":
    show_report_creation_page()
elif selection == "ãƒ¬ãƒãƒ¼ãƒˆå±¥æ­´":
    show_report_history_page()
elif selection == "è¨­å®š":
    show_settings_page()