import streamlit as st
import pandas as pd
import openai
from datetime import datetime, timedelta, date
import json
import re
from typing import Dict, List, Tuple
import base64
from io import BytesIO
import numpy as np
import sqlite3
import pickle
from pathlib import Path
import hashlib # ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆç”¨ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from dotenv import load_dotenv # è¿½åŠ 
import os # è¿½åŠ 
import pytz # æ—¥æœ¬æ™‚é–“å–å¾—ç”¨ã«è¿½åŠ 

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
load_dotenv()

def get_japan_time():
    """æ—¥æœ¬æ™‚é–“ã®ç¾åœ¨æ™‚åˆ»ã‚’å–å¾—ã™ã‚‹"""
    jst = pytz.timezone('Asia/Tokyo')
    return datetime.now(jst)

# --- Streamlitã‚¢ãƒ—ãƒªã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š ---
# ã‚¢ãƒ—ãƒªå…¨ä½“ã®èƒŒæ™¯ã‚’ç™½ã€æ–‡å­—ã‚’é»’ã«è¨­å®š
st.markdown(
    """
    <style>
    body {
        background-color: white !important;
        color: black !important;
    }
    .stApp {
        background-color: white !important;
        color: black !important;
    }
    /* Streamlitã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®è¦‹ãŸç›®ã‚’ã•ã‚‰ã«èª¿æ•´ */
    h1, h2, h3, h4, h5, h6, strong, p, div, span, label {
        color: black !important;
    }
    div[data-testid="stSidebar"] {
        background-color: #f0f0f0 !important; /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®èƒŒæ™¯ã‚’å°‘ã—è–„ã„ã‚°ãƒ¬ãƒ¼ã« (å¥½ã¿ã§èª¿æ•´) */
        color: black !important;
    }
    .stTextInput label, .stTextArea label, .stSelectbox label {
        color: black !important;
    }
    textarea {
        background-color: white !important;
        color: black !important;
        border: 1px solid #ccc !important;
        border-radius: 5px !important;
        padding: 10px !important;
    }
    textarea[disabled] { /* èª­ã¿å–ã‚Šå°‚ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã®ã‚¹ã‚¿ã‚¤ãƒ« */
        background-color: #f9f9f9 !important;
        color: #555 !important;
        opacity: 0.8 !important;
    }
    input[type="text"] {
        background-color: white !important;
        color: black !important;
        border: 1px solid #ccc !important;
        border-radius: 5px !important;
        padding: 10px !important;
    }
    /* ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    button {
        background-color: #007bff !important;
        color: white !important;
        border-radius: 5px !important;
        padding: 8px 15px !important;
        transition: background-color 0.2s !important;
        border: none !important;
    }
    button:hover {
        background-color: #0056b3 !important;
    }
    button[data-testid="stFormSubmitButton"] {
        background-color: #28a745 !important;
    }
    button[data-testid="stFormSubmitButton"]:hover {
        background-color: #218838 !important;
    }
    /* æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è‰² */
    div[data-testid="stAlert"] div[role="alert"].streamlit-success {
        background-color: #d4edda !important;
        color: #155724 !important;
        border-color: #c3e6cb !important;
    }
    /* è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è‰² */
    div[data-testid="stAlert"] div[role="alert"].streamlit-warning {
        background-color: #fff3cd !important;
        color: #856404 !important;
        border-color: #ffeeba !important;
    }
    /* ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è‰² */
    div[data-testid="stAlert"] div[role="alert"].streamlit-error {
        background-color: #f8d7da !important;
        color: #721c24 !important;
        border-color: #f5c6cb !important;
    }
    .css-1ht1j8x { /* ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®èƒŒæ™¯ã‚’ç™½ã« */
        background-color: white !important;
        border-radius: 0.5rem;
        padding: 1rem;
        box-shadow: 0 0.125rem 0.25rem rgba(0, 0, 0, 0.075) !important;
        border: 1px solid #e0e0e0;
    }
    /* ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ã®èƒŒæ™¯ã‚’ç™½ã«è¨­å®š */
    .react-datepicker {
        background-color: white !important;
        color: black !important; /* ãƒ†ã‚­ã‚¹ãƒˆè‰²ã‚‚é»’ã« */
    }
    .react-datepicker__header {
        background-color: white !important;
        color: black !important;
    }
    .react-datepicker__month-container {
        background-color: white !important;
        color: black !important;
    }
    .react-datepicker__day-name, .react-datepicker__day, .react-datepicker__time-name {
        color: black !important;
    }
    .react-datepicker__current-month {
        color: black !important;
    }
    .react-datepicker__navigation--previous, .react-datepicker__navigation--next {
        color: black !important;
    }
    /* é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã®èƒŒæ™¯è‰²ã‚’èµ¤ã€æ–‡å­—è‰²ã‚’ç™½ã«è¨­å®š */
    .react-datepicker__day--selected,
    .react-datepicker__day--range-start,
    .react-datepicker__day--range-end,
    .react-datepicker__day--in-range {
        background-color: #ff4b4b !important; /* Streamlitã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆèµ¤è‰²ã«è¿‘ã¥ã‘ã‚‹ */
        color: white !important;
    }
    /* ãƒ›ãƒãƒ¼æ™‚ã®æ—¥ä»˜ã®èƒŒæ™¯è‰² */
    .react-datepicker__day:hover {
        background-color: #e0e0e0 !important; /* ãƒ›ãƒãƒ¼æ™‚ã®èƒŒæ™¯è‰²ã‚’è–„ã„ã‚°ãƒ¬ãƒ¼ã« */
        color: black !important;
    }
    /* é¸æŠã§ããªã„æ—¥ä»˜ï¼ˆéå»ã‚„æœªæ¥ã§min/max_valueå¤–ï¼‰ã®æ–‡å­—è‰² */
    .react-datepicker__day--disabled {
        color: #ccc !important;
    }
    </style>
    """,
    unsafe_allow_html=True
)
# --- ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®šã“ã“ã¾ã§ ---

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚¢ãƒ‘ãƒ¬ãƒ«åº—èˆ—é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸª",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
DB_PATH = 'apparel_reports.db' # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«åå¤‰æ›´

class DBManager:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã¨æ“ä½œã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self, db_path: str = DB_PATH):
        self.db_path = db_path
        self._init_db()

    def _get_connection(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ç¢ºç«‹ã—ã€Rowãƒ•ã‚¡ã‚¯ãƒˆãƒªã‚’è¨­å®šã—ã¾ã™ã€‚"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row # ã‚«ãƒ©ãƒ åã§ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
        return conn

    def _init_db(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚æŒ‡å®šã•ã‚ŒãŸåº—èˆ—åã®ã¿ã‚’ç™»éŒ²ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        with conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS stores (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT NOT NULL UNIQUE
                );
            ''')
            conn.execute('''
                CREATE TABLE IF NOT EXISTS weekly_reports (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    store_id INTEGER NOT NULL,
                    monday_date TEXT NOT NULL, --YYYY-MM-DDå½¢å¼
                    
                    daily_reports_json TEXT,    -- å„æ›œæ—¥ã®å‹•å‘ã¨è¦å› ã‚’JSONæ–‡å­—åˆ—ã§ä¿å­˜
                    topics TEXT,
                    impact_day TEXT,
                    quantitative_data TEXT,
                    
                    generated_report_json TEXT, -- AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆï¼ˆå‹•å‘ã€è¦å› ã€è³ªå•ï¼‰ã‚’JSONã§ä¿å­˜
                    modified_report_json TEXT,  -- ä¿®æ­£å¾Œã®ãƒ¬ãƒãƒ¼ãƒˆï¼ˆå‹•å‘ã€è¦å› ã€ä¿®æ­£ç†ç”±ãªã©ï¼‰ã‚’JSONã§ä¿å­˜
                    
                    timestamp TEXT,             -- ä½œæˆ/æœ€çµ‚æ›´æ–°æ—¥æ™‚
                    FOREIGN KEY (store_id) REFERENCES stores(id),
                    UNIQUE(store_id, monday_date)
                );
            ''')
            
            conn.execute('''
                CREATE TABLE IF NOT EXISTS learning_patterns (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    input_context_hash TEXT NOT NULL UNIQUE, -- å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒã‚·ãƒ¥å€¤
                    original_output_json TEXT,
                    modified_output_json TEXT,
                    edit_reason TEXT,
                    usage_count INTEGER DEFAULT 1,
                    last_used TEXT
                )
            ''')
            
            # æŒ‡å®šã•ã‚ŒãŸåº—èˆ—åã®ã¿ã‚’æŒ¿å…¥ (æ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—)
            for store_name in ['RAY', 'RSJ', 'ROS', 'RNG']:
                conn.execute("INSERT OR IGNORE INTO stores (name) VALUES (?)", (store_name,))
            conn.commit()
        conn.close()

    def get_store_id_by_name(self, store_name: str) -> int:
        """ã‚¹ãƒˆã‚¢åã‹ã‚‰IDã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        store_id = conn.execute('SELECT id FROM stores WHERE name = ?', (store_name,)).fetchone()['id']
        conn.close()
        return store_id

    def get_store_name_by_id(self, store_id: int) -> str:
        """ã‚¹ãƒˆã‚¢IDã‹ã‚‰åå‰ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        store_name = conn.execute('SELECT name FROM stores WHERE id = ?', (store_id,)).fetchone()['name']
        conn.close()
        return store_name
    
    def get_all_stores(self) -> List[Tuple[int, str]]:
        """å…¨ã¦ã®åº—èˆ—ã®IDã¨åå‰ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        stores = conn.execute('SELECT id, name FROM stores ORDER BY name').fetchall()
        conn.close()
        return [(s['id'], s['name']) for s in stores]

    def save_weekly_data(self, store_id: int, monday_date_str: str, data: Dict, original_report: Dict, modified_report: Dict = None):
        """é€±æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’DBã«ä¿å­˜ã¾ãŸã¯æ›´æ–°ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        daily_reports_json = json.dumps(data['daily_reports'], ensure_ascii=False)
        generated_report_json = json.dumps(original_report, ensure_ascii=False)
        modified_report_json = json.dumps(modified_report, ensure_ascii=False) if modified_report else None
        
        cursor.execute(
            'SELECT id FROM weekly_reports WHERE store_id = ? AND monday_date = ?',
            (store_id, monday_date_str)
        )
        existing_record = cursor.fetchone()

        if existing_record:
            cursor.execute('''
                UPDATE weekly_reports SET
                   daily_reports_json = ?, topics = ?, impact_day = ?,
                   quantitative_data = ?, generated_report_json = ?,
                   modified_report_json = ?, timestamp = ?
                WHERE id = ?
            ''', (
                daily_reports_json,
                data.get('topics', ''),
                data.get('impact_day', ''),
                data.get('quantitative_data', ''),
                generated_report_json,
                modified_report_json,
                datetime.now().isoformat(),
                existing_record['id']
            ))
        else:
            cursor.execute('''
                INSERT INTO weekly_reports 
                (store_id, monday_date, daily_reports_json, topics, impact_day, 
                 quantitative_data, generated_report_json, modified_report_json, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                store_id,
                monday_date_str,
                daily_reports_json,
                data.get('topics', ''),
                data.get('impact_day', ''),
                data.get('quantitative_data', ''),
                generated_report_json,
                modified_report_json,
                datetime.now().isoformat()
            ))
        
        conn.commit()
        conn.close()
        return existing_record is not None

    def get_weekly_report(self, store_id: int, monday_date_str: str) -> Dict:
        """æŒ‡å®šã•ã‚ŒãŸé€±ã®ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        report_row = conn.execute(
            'SELECT * FROM weekly_reports WHERE store_id = ? AND monday_date = ?',
            (store_id, monday_date_str)
        ).fetchone()
        conn.close()

        if report_row:
            report_data = dict(report_row) # Rowã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›
            try:
                report_data['daily_reports'] = json.loads(report_data['daily_reports_json']) if report_data['daily_reports_json'] else {}
            except (json.JSONDecodeError, TypeError) as e:
                print(f"æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                report_data['daily_reports'] = {}
                
            try:
                report_data['generated_report'] = json.loads(report_data['generated_report_json']) if report_data['generated_report_json'] else {}
            except (json.JSONDecodeError, TypeError) as e:
                print(f"ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                report_data['generated_report'] = {}
                
            try:
                report_data['modified_report'] = json.loads(report_data['modified_report_json']) if report_data['modified_report_json'] else None
            except (json.JSONDecodeError, TypeError) as e:
                print(f"ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®è§£æã«å¤±æ•—ã—ã¾ã—ãŸ: {str(e)}")
                report_data['modified_report'] = None
            
            del report_data['daily_reports_json']
            del report_data['generated_report_json']
            if 'modified_report_json' in report_data:
                del report_data['modified_report_json']

            return report_data
        return {}
    
    def get_all_weekly_reports(self, store_id: int = None) -> List[Dict]:
        """å…¨ã¦ã®é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã€ã¾ãŸã¯æŒ‡å®šã—ãŸåº—èˆ—ã®é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        if store_id:
            reports_rows = conn.execute(
                'SELECT id, store_id, monday_date, timestamp, generated_report_json, modified_report_json '
                'FROM weekly_reports WHERE store_id = ? ORDER BY monday_date DESC', (store_id,)
            ).fetchall()
        else:
            reports_rows = conn.execute(
                'SELECT id, store_id, monday_date, timestamp, generated_report_json, modified_report_json '
                'FROM weekly_reports ORDER BY monday_date DESC'
            ).fetchall()
        conn.close()

        reports = []
        for row in reports_rows:
            report_data = dict(row)
            report_data['store_name'] = self.get_store_name_by_id(report_data['store_id'])
            
            # ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆã¨ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆã®æœ‰ç„¡ã‚’ãƒ•ãƒ©ã‚°ã¨ã—ã¦è¿½åŠ 
            report_data['has_generated'] = report_data['generated_report_json'] is not None
            report_data['has_modified'] = report_data['modified_report_json'] is not None

            # JSONæ–‡å­—åˆ—ã¯ç”Ÿãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿æŒã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹
            reports.append(report_data)
        return reports

    def find_similar_cases(self, current_data: Dict) -> str:
        """é¡ä¼¼ã‚±ãƒ¼ã‚¹ã‚’æ¤œç´¢ã—ã€LLMã«æ¸¡ã™ãŸã‚ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT daily_reports_json, modified_report_json 
            FROM weekly_reports 
            WHERE modified_report_json IS NOT NULL
            ORDER BY timestamp DESC
            LIMIT 5
        ''') 
        
        results = cursor.fetchall()
        conn.close()
        
        similar_cases_context = []
        for result in results:
            try:
                past_modified_report = json.loads(result[1])
                
                context_item = (
                    f"- éå»ã®é¡ä¼¼ã‚±ãƒ¼ã‚¹ (ä¿®æ­£å¾Œ): {past_modified_report.get('trend', '')[:100]}...\n"
                    f"  è¦å› : {', '.join(past_modified_report.get('factors', []))}\n"
                    f"  (ä¿®æ­£ç†ç”±: {past_modified_report.get('edit_reason', 'ä¸æ˜')[:50]}...)\n"
                )
                similar_cases_context.append(context_item)

            except json.JSONDecodeError:
                continue
        
        if similar_cases_context:
            return "\nã€éå»ã®ä¿®æ­£æ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆä¾‹ã€‘\n" + "\n".join(similar_cases_context)
        return ""

def save_draft_data(store_name: str, monday_date_str: str, daily_reports_data: Dict, topics: str = "", impact_day: str = "", quantitative_data: str = ""):
    """å…¥åŠ›é€”ä¸­ã®ãƒ‡ãƒ¼ã‚¿ã‚’è‡ªå‹•ä¿å­˜ã™ã‚‹"""
    try:
        store_id = db_manager.get_store_id_by_name(store_name)
        
        # æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
        existing_report = db_manager.get_weekly_report(store_id, monday_date_str)
        
        # æ—¢å­˜ã®æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã€æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã§ãƒãƒ¼ã‚¸
        if existing_report and existing_report.get('daily_reports'):
            merged_daily_reports = existing_report['daily_reports'].copy()
            # ç¾åœ¨ã®åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
            merged_daily_reports.update(daily_reports_data)
        else:
            # æ–°è¦ã®å ´åˆã¯å…¨åº—èˆ—ã®ç©ºãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ä½œæˆ
            merged_daily_reports = {}
            all_stores = db_manager.get_all_stores()
            for _, store_name_db in all_stores:
                merged_daily_reports[store_name_db] = {}
                # é€±ã®7æ—¥åˆ†ã‚’åˆæœŸåŒ–
                for i in range(7):
                    date_obj = datetime.strptime(monday_date_str, '%Y-%m-%d').date()
                    current_date = date_obj + timedelta(days=i)
                    date_str = current_date.strftime('%Y-%m-%d')
                    merged_daily_reports[store_name_db][date_str] = {"trend": "", "factors": []}
            # ç¾åœ¨ã®åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’æ›´æ–°
            merged_daily_reports.update(daily_reports_data)
        
        draft_data = {
            'daily_reports': merged_daily_reports,
            'topics': topics or (existing_report.get('topics', '') if existing_report else ''),
            'impact_day': impact_day or (existing_report.get('impact_day', '') if existing_report else ''),
            'quantitative_data': quantitative_data or (existing_report.get('quantitative_data', '') if existing_report else '')
        }
        
        # æ—¢å­˜ã®ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆã¨ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆã¯ä¿æŒ
        original_report = existing_report.get('generated_report', {}) if existing_report else {}
        modified_report = existing_report.get('modified_report') if existing_report else None
        
        # ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜
        db_manager.save_weekly_data(
            store_id,
            monday_date_str,
            draft_data,
            original_report,
            modified_report
        )
        
        # ä¿å­˜æ™‚åˆ»ã‚’è¨˜éŒ²ï¼ˆæ—¥æœ¬æ™‚é–“ï¼‰
        japan_time = get_japan_time()
        st.session_state['last_auto_save'] = japan_time.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')
        st.session_state['last_auto_save_timestamp'] = japan_time.timestamp()
        
        return True
    except Exception as e:
        print(f"è‡ªå‹•ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}")
        return False
    
    def get_learning_stats(self) -> Dict:
        """å­¦ç¿’ã«é–¢ã™ã‚‹çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        total_reports = cursor.execute("SELECT COUNT(*) FROM weekly_reports").fetchone()[0]
        corrections = cursor.execute("SELECT COUNT(*) FROM weekly_reports WHERE modified_report_json IS NOT NULL").fetchone()[0]
        total_patterns = cursor.execute("SELECT COUNT(*) FROM learning_patterns").fetchone()[0]
        
        conn.close()
        
        return {
            'total_reports': total_reports,
            'corrections': corrections,
            'patterns': total_patterns
        }

class ApparelReportGenerator:
    def __init__(self):
        self.openai_client = None
        self.training_data = None
        self.text_training_data = None 
        self.memory_db = None 
        self.learning_engine = None
        
    def set_dependencies(self, memory_db_instance, learning_engine_instance):
        """å¤–éƒ¨ã‹ã‚‰ä¾å­˜é–¢ä¿‚ã‚’è¨­å®šã™ã‚‹ãŸã‚ã®ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.memory_db = memory_db_instance
        self.learning_engine = learning_engine_instance

    def initialize_openai(self, api_key: str):
        """OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        try:
            # ã“ã“ã‚’openai.OpenAI()ã«ä¿®æ­£ (ãƒãƒ¼ã‚¸ãƒ§ãƒ³1.0ä»¥é™ã®è¨˜æ³•)
            self.openai_client = openai.OpenAI(api_key=api_key) 
            return True
        except Exception as e:
            st.error(f"OpenAI APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
        
    def load_training_data(self, csv_file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            self.training_data = pd.read_csv(csv_file_path)
            return True
        except Exception as e:
            st.error(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    def load_text_training_data(self, csv_file_path):
        """ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            self.text_training_data = pd.read_csv(csv_file_path)
            return True
        except Exception as e:
            st.error(f"ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    
    def analyze_trend_factors(self, daily_reports: Dict, topics: str, impact_day: str, quantitative_data: str) -> Dict:
        """æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’åˆ†æã—ã€å‹•å‘ã¨è¦å› ã‚’æŠ½å‡º"""
        
        current_data_for_context = {
            'daily_reports': daily_reports,
            'topics': topics,
            'impact_day': impact_day,
            'quantitative_data': quantitative_data
        }
        enhanced_context = ""
        if self.memory_db and self.learning_engine:
             enhanced_context = self.memory_db.find_similar_cases(current_data_for_context) # find_similar_casesã‚’ä½¿ç”¨
        
        system_prompt = self._build_system_prompt()
        # ä¿®æ­£: _build_user_prompt ã«æ¸¡ã™ daily_reports ã¯ã€ã™ã§ã«é¸æŠã•ã‚ŒãŸã‚¹ãƒˆã‚¢ã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ã«ãªã£ã¦ã„ã‚‹
        user_prompt = self._build_user_prompt(daily_reports, topics, impact_day, quantitative_data, enhanced_context) 
        
        if not self.openai_client:
            st.error("OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return None
        try:
            # ä¿®æ­£: openai.ChatCompletion.create ã‚’ self.openai_client.chat.completions.create ã«å¤‰æ›´
            response = self.openai_client.chat.completions.create( 
                model="gpt-4o-mini", # ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3, # ç”Ÿæˆã®å¤šæ§˜æ€§ã‚’èª¿æ•´ (ä½ã‚ã«ã—ã¦å®‰å®šæ€§ã‚’å„ªå…ˆ)
                max_tokens=1000 # æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’èª¿æ•´ (å‡ºåŠ›å½¢å¼ã«åˆã‚ã›ã¦)
            )
            
            result = response.choices[0].message.content
            return self._parse_analysis_result(result)
            
        except openai.APIStatusError as e: # ã“ã“ã¯openaiãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã®ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹ã§OK
            if e.status_code == 401: # èªè¨¼ã‚¨ãƒ©ãƒ¼ (Unauthorized)
                st.error("OpenAI APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚è¨­å®šãƒšãƒ¼ã‚¸ã§APIã‚­ãƒ¼ã‚’æ­£ã—ãå…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            elif e.status_code == 429: # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ (Too Many Requests)
                st.error("OpenAI APIã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è¶…ãˆã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
            else:
                st.error(f"OpenAI APIã‚¨ãƒ©ãƒ¼: {e.status_code} - {e.response}")
            return None
        except openai.APITimeoutError: # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼
            st.error("OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã€å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
            return None
        except Exception as e:
            st.error(f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
        
    
    def _build_system_prompt(self) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        base_prompt = """
        ã‚ãªãŸã¯ã‚¢ãƒ‘ãƒ¬ãƒ«å°å£²æ¥­ç•Œã®å°‚é–€ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
        ä¸ãˆã‚‰ã‚ŒãŸæ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã€TOPICSã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ã€å®šé‡ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

        ã€åˆ†æè¦ä»¶ã€‘
        1.  å‹•å‘ã¨è¦å› ã®å› æœé–¢ä¿‚ã‚’æ˜ç¢ºã«è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚
        2.  ã€Œç›®è«–è¦‹ä»¥ä¸‹ã€ãªã©ã®çµæœè¡¨ç¾ã¯ã€å…·ä½“çš„ãªè¦å› ã¾ã§æ·±æ˜ã‚Šã—ã¦èª¬æ˜ã™ã‚‹ã“ã¨ã€‚
        3.  æä¾›ã•ã‚ŒãŸå®šé‡ãƒ‡ãƒ¼ã‚¿ã¨ã®æ•´åˆæ€§ã‚’ç¢ºèªã—ã€ãƒ¬ãƒãƒ¼ãƒˆã«åæ˜ ã•ã›ã‚‹ã“ã¨ã€‚
        4.  TOPICSã‚„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ã®äº‹è±¡ãŒé€±å…¨ä½“ã«ä¸ãˆãŸå½±éŸ¿åº¦ã‚’è©•ä¾¡ã—ã€ãƒ¬ãƒãƒ¼ãƒˆã«å«ã‚ã‚‹ã“ã¨ã€‚
        5.  ç°¡æ½”ã§ã€ã‚¢ãƒ‘ãƒ¬ãƒ«åº—èˆ—ã®ä¸Šä½éƒ¨ç½²ãŒç†è§£ã—ã‚„ã™ã„è¡¨ç¾ã‚’ç”¨ã„ã‚‹ã“ã¨ã€‚
        6.  é€±å…¨ä½“ã®å‹•å‘ã¨ã—ã¦ã€**æŒ‡å®šã•ã‚ŒãŸåº—èˆ—ã®æƒ…å ±ã‚’ä¸­å¿ƒã«**åˆ†æã™ã‚‹ã“ã¨ã€‚ï¼ˆä»–ã®åº—èˆ—ã®æƒ…å ±ã¯å‚è€ƒç¨‹åº¦ã«ã¨ã©ã‚ã‚‹ï¼‰

        ã€å‡ºåŠ›å½¢å¼ã€‘
        å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        ```json
        {
            "trend": "é€±å…¨ä½“ã®å‹•å‘ã‚’400å­—ç¨‹åº¦ã§è¨˜è¿°ã€‚å„åº—èˆ—ã®å‹•å‘ã¨è¦å› ã€å®šé‡ãƒ‡ãƒ¼ã‚¿ã€TOPICSã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ã‚’çµ±åˆã—ã€å› æœé–¢ä¿‚ã‚’é‡è¦–ã—ã¦èª¬æ˜ã™ã‚‹ã€‚",
            "factors": [
                "æœ€ã‚‚å½±éŸ¿ã®å¤§ãã‹ã£ãŸè¦å› 1 (30å­—ä»¥å†…)",
                "æ¬¡ã«å½±éŸ¿ã®å¤§ãã‹ã£ãŸè¦å› 2 (30å­—ä»¥å†…)",
                "3ç•ªç›®ã«å½±éŸ¿ã®å¤§ãã‹ã£ãŸè¦å› 3 (30å­—ä»¥å†…)"
            ],
            "questions": [
                "ä¸æ˜ç‚¹ã‚„è¿½åŠ ç¢ºèªãŒå¿…è¦ãªé …ç›®ãŒã‚ã‚Œã°ã€ç°¡æ½”ãªè³ªå•å½¢å¼ã§è¨˜è¿°ã€‚ãªã‘ã‚Œã°ç©ºã®é…åˆ—ã€‚"
            ]
        }
        ```
        - ã€Œtrendã€ã¯400å­—ç¨‹åº¦ã‚’å³å®ˆã™ã‚‹ã“ã¨ã€‚
        - ã€Œfactorsã€ã¯æœ€å¤§3ã¤ã¾ã§ã¨ã—ã€ãã‚Œãã‚Œ30å­—ä»¥å†…ã¨ã™ã‚‹ã“ã¨ã€‚
        - JSONå½¢å¼ä»¥å¤–ã§ã®å‡ºåŠ›ã¯å³ç¦ã§ã™ã€‚
        """
        
        if self.training_data is not None and not self.training_data.empty:
            training_context = self._extract_training_context()
            if training_context:
                base_prompt += f"\n\nã€ç¤¾å†…ç”¨èªãƒ»æ–‡ä½“ãƒ»éå»ã®é¡ä¼¼ä¾‹ã®å‚è€ƒæƒ…å ±ã€‘\n{training_context}"
        
        return base_prompt
    
    def _build_user_prompt(self, daily_reports: Dict, topics: str, impact_day: str, quantitative_data: str, enhanced_context: str) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        prompt = "ä»¥ä¸‹ã®æƒ…å ±ã‹ã‚‰é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"
        
        # ä¿®æ­£: daily_reports ã¯æ—¢ã«å˜ä¸€åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’æƒ³å®š
        prompt += "ã€æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã€‘\n"
        # daily_reports ã¯ { 'åº—èˆ—å': { 'æ—¥ä»˜': { 'trend': '', 'factors': [] } } ã®å½¢å¼ã§æ¥ã‚‹ã¨æƒ³å®š
        for store, data in daily_reports.items(): # ã“ã®ãƒ«ãƒ¼ãƒ—ã¯ä¸€åº¦ã—ã‹å›ã‚‰ãªã„ã¯ãš
            prompt += f"- **{store}åº—**:\n"
            for date, report in data.items():
                trend_text = report['trend'] if report['trend'] else "æœªå…¥åŠ›"
                factors_text = ", ".join(report['factors']) if report['factors'] else "ãªã—"
                prompt += f"  - {date}: å‹•å‘={trend_text}, è¦å› ={factors_text}\n"
        
        if topics:
            prompt += f"\nã€TOPICSã€‘\n{topics}\n"
        
        if impact_day:
            prompt += f"\nã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ã€‘\n{impact_day}\n"
        
        if quantitative_data:
            prompt += f"\nã€å®šé‡ãƒ‡ãƒ¼ã‚¿ã€‘\n{quantitative_data}\n"
        
        if enhanced_context:
            prompt += f"\n{enhanced_context}\n" 
        
        return prompt
    
    def _extract_training_context(self) -> str:
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç¤¾å†…ç”¨èªãƒ»æ–‡ä½“ã‚’æŠ½å‡º (ç°¡ç•¥åŒ–ã•ã‚ŒãŸä¾‹)"""
        if self.training_data is None or self.training_data.empty:
            if self.text_training_data is None or self.text_training_data.empty:
                return ""
        
        context = []
        
        # æ—¢å­˜ã®training_data.csvã‹ã‚‰ã®æ–‡è„ˆä½œæˆ
        if self.training_data is not None and not self.training_data.empty:
            if 'example_trend' in self.training_data.columns and not self.training_data['example_trend'].empty:
                context.append("éå»ã®ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¿°ä¾‹ (å‹•å‘):")
                for ex in self.training_data['example_trend'].dropna().head(3):
                    context.append(f"- {ex[:50]}...")
            
            if 'example_factors' in self.training_data.columns and not self.training_data['example_factors'].empty:
                context.append("éå»ã®ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¿°ä¾‹ (è¦å› ):")
                for ex in self.training_data['example_factors'].dropna().head(3):
                    context.append(f"- {ex[:30]}...")
        
        # text_training_data.csvã‹ã‚‰ã®æ–‡è„ˆä½œæˆ
        if self.text_training_data is not None and not self.text_training_data.empty:
            if 'output' in self.text_training_data.columns and not self.text_training_data['output'].empty:
                context.append("éå»ã®ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¿°ä¾‹ (ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿):")
                for ex in self.text_training_data['output'].dropna().head(3):
                    context.append(f"- {ex[:60]}...")
        
        return "\n".join(context)
    
    def _parse_analysis_result(self, result: str) -> Dict:
        """åˆ†æçµæœï¼ˆJSONæ–‡å­—åˆ—ï¼‰ã‚’ãƒ‘ãƒ¼ã‚¹"""
        parsed = {
            'trend': '',
            'factors': [],
            'questions': [],
            'original_result_raw': result # LLMã®ç”Ÿã®å‡ºåŠ›ã‚’ä¿æŒ
        }
        
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', result, re.DOTALL)
        if not json_match:
            try:
                json_data = json.loads(result)
            except json.JSONDecodeError:
                st.error("AIã‹ã‚‰ã®å‡ºåŠ›ãŒæœ‰åŠ¹ãªJSONå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚é–‹ç™ºè€…å‘ã‘æƒ…å ±: \n" + result)
                return parsed
        else:
            try:
                json_string = json_match.group(1)
                json_data = json.loads(json_string)
            except json.JSONDecodeError:
                st.error("AIã‹ã‚‰ã®JSONå‡ºåŠ›ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚é–‹ç™ºè€…å‘ã‘æƒ…å ±: \n" + json_string)
                return parsed

        parsed['trend'] = json_data.get('trend', '').strip()
        parsed['factors'] = [f.strip() for f in json_data.get('factors', []) if f.strip()][:3]
        parsed['questions'] = [q.strip() for q in json_data.get('questions', []) if q.strip()]
        
        return parsed

class LearningEngine:
    """å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã‚¯ãƒ©ã‚¹ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿®æ­£ã‹ã‚‰å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆãƒ»ç®¡ç†ã—ã¾ã™ã€‚"""
    
    def __init__(self, db_manager: DBManager):
        self.db_manager = db_manager
    
    def learn_from_correction(self, input_data: Dict, original_output: Dict, modified_output: Dict):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿®æ­£ã‹ã‚‰å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã€DBã«ä¿å­˜ã—ã¾ã™ã€‚"""
        # å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆï¼ˆç°¡æ˜“çš„ãªæ–¹æ³•ï¼‰
        input_context_str = json.dumps(input_data, ensure_ascii=False, sort_keys=True)
        input_context_hash = hashlib.sha256(input_context_str.encode('utf-8')).hexdigest()
        
        conn = self.db_manager._get_connection() # DBManagerã‹ã‚‰æ¥ç¶šã‚’å–å¾—
        cursor = conn.cursor()

        original_output_json = json.dumps(original_output, ensure_ascii=False)
        modified_output_json = json.dumps(modified_output, ensure_ascii=False)
        edit_reason = modified_output.get('edit_reason', '')

        cursor.execute('''
            SELECT id, usage_count FROM learning_patterns 
            WHERE input_context_hash = ? AND modified_output_json = ?
        ''', (input_context_hash, modified_output_json))
        
        existing_pattern = cursor.fetchone()

        if existing_pattern:
            pattern_id, usage_count = existing_pattern
            cursor.execute('''
                UPDATE learning_patterns 
                SET usage_count = ?, last_used = ?
                WHERE id = ?
            ''', (usage_count + 1, datetime.now().isoformat(), pattern_id))
            st.info("æ—¢å­˜ã®å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
        else:
            cursor.execute('''
                INSERT INTO learning_patterns 
                (input_context_hash, original_output_json, modified_output_json, edit_reason, usage_count, last_used)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                input_context_hash,
                original_output_json,
                modified_output_json,
                edit_reason,
                1,
                datetime.now().isoformat()
            ))
            st.success("æ–°ã—ã„å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼AIã®ç²¾åº¦å‘ä¸Šã«å½¹ç«‹ã¡ã¾ã™ã€‚")
        
        conn.commit()
        conn.close()


# --- Streamlit UI Components ---

def get_base64_of_bin_file(bin_file):
    with open(bin_file, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()

def get_file_download_link(df, filename, text):
    """Generates a link for downloading a pandas DataFrame as CSV."""
    csv = df.to_csv(index=False, encoding='utf-8-sig') # UTF-8 BOMä»˜ãã§Excelå¯¾å¿œ
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
    return href

def get_excel_download_link(df, filename, text):
    """Generates a link for downloading a pandas DataFrame as Excel."""
    try:
        output = BytesIO()
        with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
            df.to_excel(writer, index=False, sheet_name='ãƒ¬ãƒãƒ¼ãƒˆ')
        b64 = base64.b64encode(output.getvalue()).decode()
        href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="{filename}">{text}</a>'
        return href
    except ImportError:
        # xlsxwriterãŒåˆ©ç”¨ã§ããªã„å ´åˆã¯CSVã«ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
        st.warning("Excelå½¢å¼ã§ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒã§ãã¾ã›ã‚“ã€‚CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã™ã€‚")
        csv = df.to_csv(index=False, encoding='utf-8-sig')
        b64 = base64.b64encode(csv.encode()).decode()
        csv_filename = filename.replace('.xlsx', '.csv')
        href = f'<a href="data:file/csv;base64,{b64}" download="{csv_filename}">{text}</a>'
        return href

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®åˆæœŸåŒ–
db_manager = DBManager()
report_generator = ApparelReportGenerator()
learning_engine = LearningEngine(db_manager)

# ä¾å­˜é–¢ä¿‚ã‚’è¨­å®š
report_generator.set_dependencies(db_manager, learning_engine)

# â˜…ã“ã“ã‹ã‚‰è¿½åŠ ã™ã‚‹ã‚³ãƒ¼ãƒ‰â˜…
TRAINING_CSV_FILE = "training_data.csv" # ã“ã“ã‚’å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«ç½®ãæ›ãˆã¦ãã ã•ã„ï¼
TEXT_TRAINING_CSV_FILE = "text_training_data.csv" # ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«

# training_data.csvã®èª­ã¿è¾¼ã¿
if Path(TRAINING_CSV_FILE).exists():
    if report_generator.load_training_data(TRAINING_CSV_FILE):
        st.sidebar.success(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TRAINING_CSV_FILE}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    else:
        st.sidebar.warning(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TRAINING_CSV_FILE}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
else:
    st.sidebar.info(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TRAINING_CSV_FILE}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# text_training_data.csvã®èª­ã¿è¾¼ã¿
if Path(TEXT_TRAINING_CSV_FILE).exists():
    if report_generator.load_text_training_data(TEXT_TRAINING_CSV_FILE):
        st.sidebar.success(f"ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TEXT_TRAINING_CSV_FILE}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    else:
        st.sidebar.warning(f"ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TEXT_TRAINING_CSV_FILE}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
else:
    st.sidebar.info(f"ãƒ†ã‚­ã‚¹ãƒˆå­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TEXT_TRAINING_CSV_FILE}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚")

# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®æœ‰ç„¡ã‚’ç¢ºèª
has_training_data = (report_generator.training_data is not None and not report_generator.training_data.empty)
has_text_training_data = (report_generator.text_training_data is not None and not report_generator.text_training_data.empty)

if not has_training_data and not has_text_training_data:
    st.sidebar.warning("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å­¦ç¿’æ©Ÿèƒ½ã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™ã€‚")
# â˜…ã“ã“ã¾ã§è¿½åŠ ã™ã‚‹ã‚³ãƒ¼ãƒ‰â˜…

def get_monday_of_week(selected_date: date) -> date:
    """ä¸ãˆã‚‰ã‚ŒãŸæ—¥ä»˜ãŒå±ã™ã‚‹é€±ã®æœˆæ›œæ—¥ã‚’è¨ˆç®—ã—ã¾ã™ã€‚"""
    # é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã®æ›œæ—¥ã‚’å–å¾— (æœˆæ›œæ—¥=0, æ—¥æ›œæ—¥=6)
    weekday = selected_date.weekday()
    # æœˆæ›œæ—¥ã«æˆ»ã‚‹ãŸã‚ã®æ—¥æ•°ã‚’è¨ˆç®—
    days_since_monday = weekday
    monday = selected_date - timedelta(days=days_since_monday)
    return monday

def get_current_week_monday() -> date:
    """ç¾åœ¨ã®é€±ã®æœˆæ›œæ—¥ã‚’å–å¾—ã—ã¾ã™ã€‚"""
    today = date.today()
    return get_monday_of_week(today)

# --- Streamlit UI Components ---

def show_report_creation_page():
    st.title("ğŸ“ˆ é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ")
    st.markdown("---")

    st.info("ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€åº—èˆ—ã”ã¨ã®æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã€AIãŒé€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚AIãƒ¬ãƒãƒ¼ãƒˆã¯å¾Œã§ä¿®æ­£ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã«å­¦ç¿’ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚")

    # é€±ã®é¸æŠ
    st.header("1. ãƒ¬ãƒãƒ¼ãƒˆå¯¾è±¡é€±ã®é¸æŠ")
    # ä»Šé€±ã®æœˆæ›œæ—¥ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ã™ã‚‹
    default_monday = get_current_week_monday()
    selected_date = st.date_input(
        "ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹é€±ã®**æœˆæ›œæ—¥**ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
        value=default_monday,
        min_value=date(2023, 1, 1),
        max_value=date.today() + timedelta(days=30), # æœªæ¥ã®æ—¥ä»˜ã‚‚å°‘ã—è¨±å®¹
        format="YYYY/MM/DD"
    )
    
    # é¸æŠã•ã‚ŒãŸæ—¥ä»˜ãŒæœˆæ›œæ—¥ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ãã†ã§ãªã„å ´åˆã¯æœˆæ›œæ—¥ã«è£œæ­£
    if selected_date.weekday() != 0:
        st.warning(f"é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã¯æœˆæ›œæ—¥ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚è‡ªå‹•çš„ã«**{get_monday_of_week(selected_date).strftime('%Yå¹´%mæœˆ%dæ—¥')}**ã®é€±ã¨ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚")
        monday_of_week = get_monday_of_week(selected_date)
    else:
        monday_of_week = selected_date
    
    st.session_state['selected_monday'] = monday_of_week.strftime('%Y-%m-%d')
    
    # æ—¥ä»˜ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®å‡¦ç†
    if 'last_selected_monday' not in st.session_state or st.session_state['last_selected_monday'] != st.session_state['selected_monday']:
        # æ—¥ä»˜å¤‰æ›´æ™‚ã¯æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ãƒ•ãƒ©ã‚°ã‚’ãƒªã‚»ãƒƒãƒˆ
        st.session_state['topics_loaded_for_week'] = False
        # è‡ªå‹•ä¿å­˜æ™‚åˆ»ã‚‚ãƒªã‚»ãƒƒãƒˆ
        st.session_state['last_auto_save'] = None
    
    st.subheader(f"é¸æŠé€±: {monday_of_week.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {(monday_of_week + timedelta(days=6)).strftime('%Yå¹´%mæœˆ%dæ—¥')}")
    st.markdown("---")

    # æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ­ãƒ¼ãƒ‰
    store_names = [s[1] for s in db_manager.get_all_stores()]
    if 'selected_store_for_report' not in st.session_state:
        st.session_state['selected_store_for_report'] = store_names[0] # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ€åˆã®åº—èˆ—

    # ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®åˆæœŸåŒ–
    if 'daily_reports_input' not in st.session_state:
        st.session_state['daily_reports_input'] = {store_name: {} for store_name in store_names}
    if 'topics_input' not in st.session_state:
        st.session_state['topics_input'] = ""
    if 'impact_day_input' not in st.session_state:
        st.session_state['impact_day_input'] = ""
    if 'quantitative_data_input' not in st.session_state:
        st.session_state['quantitative_data_input'] = ""
    if 'generated_report_output' not in st.session_state:
        st.session_state['generated_report_output'] = None
    if 'modified_report_output' not in st.session_state:
        st.session_state['modified_report_output'] = None
    if 'report_id_to_edit' not in st.session_state:
        st.session_state['report_id_to_edit'] = None

    # é¸æŠã•ã‚ŒãŸé€±ã®æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
    # ã¾ãšã€ã‚¹ãƒˆã‚¢é¸æŠã‚¿ãƒ–ã®ç¾åœ¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿æŒ
    if 'active_tab_index' not in st.session_state:
        st.session_state['active_tab_index'] = 0 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ€åˆã®ã‚¿ãƒ– (RAY)

    # æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å‰ã«ã€ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹åº—èˆ—åã‚’å–å¾—
    # åˆæœŸè¡¨ç¤ºæ™‚ã‚„æ—¥ä»˜å¤‰æ›´æ™‚ã«ã€é¸æŠåº—èˆ—ã®ãƒ¬ãƒãƒ¼ãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ã‚ˆã†ã«èª¿æ•´
    # ãŸã ã—ã€ã‚¿ãƒ–ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã¯ã€ãã®ã‚¿ãƒ–ã®åº—èˆ—åã«è¿½å¾“
    # ã“ã“ã§ã¯ã€`selected_store_for_report` ã¨ `active_tab_index` ã®åŒæœŸã‚’å¼·åŒ–
    
    # å„åº—èˆ—ã®æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã‚’å€‹åˆ¥ã«èª­ã¿è¾¼ã¿
    for store_name in store_names:
        store_id = db_manager.get_store_id_by_name(store_name)
        existing_report = db_manager.get_weekly_report(store_id, st.session_state['selected_monday'])
        
        if existing_report and existing_report.get('daily_reports', {}).get(store_name):
            # å½“è©²åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹å ´åˆã®ã¿æ›´æ–°
            st.session_state['daily_reports_input'][store_name] = existing_report['daily_reports'][store_name]
            
            # æœ€åˆã«è¦‹ã¤ã‹ã£ãŸåº—èˆ—ã®ãã®ä»–ãƒ‡ãƒ¼ã‚¿ã‚‚èª­ã¿è¾¼ã¿ï¼ˆTOPICSãªã©ã¯å…±é€šï¼‰
            if not st.session_state.get('topics_loaded_for_week'):
                st.session_state['topics_input'] = existing_report.get('topics', '')
                st.session_state['impact_day_input'] = existing_report.get('impact_day', '')
                st.session_state['quantitative_data_input'] = existing_report.get('quantitative_data', '')
                st.session_state['generated_report_output'] = existing_report.get('generated_report', {})
                st.session_state['modified_report_output'] = existing_report.get('modified_report')
                st.session_state['report_id_to_edit'] = existing_report.get('id')
                st.session_state['topics_loaded_for_week'] = True
            
    # æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆãŒãƒ­ãƒ¼ãƒ‰ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯ã—ã¦è¡¨ç¤º
    loaded_stores = []
    for store_name in store_names:
        if st.session_state['daily_reports_input'][store_name]:
            # ç©ºã§ãªã„ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            has_data = any(
                data.get('trend') or data.get('factors') 
                for data in st.session_state['daily_reports_input'][store_name].values()
                if isinstance(data, dict)
            )
            if has_data:
                loaded_stores.append(store_name)
    
    if loaded_stores:
        st.info(f"ğŸ“ ä¿å­˜æ¸ˆã¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ: {', '.join(loaded_stores)}åº—")
    else:
        # æ–°è¦ä½œæˆã®å ´åˆã€æ—¢å­˜ã®å…¥åŠ›ã¯ã‚¯ãƒªã‚¢ã—ãªã„ï¼ˆæ—¥ä»˜åˆ‡ã‚Šæ›¿ãˆæ™‚ã®ãƒ‡ãƒ¼ã‚¿æ®‹å­˜ã‚’é˜²ããŸã‚ï¼‰
        # ãŸã ã—ã€é¸æŠé€±ã‚’å¤‰æ›´ã—ãŸå ´åˆã¯å„å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å€¤ã‚’ãƒªã‚»ãƒƒãƒˆ
        if 'last_selected_monday' not in st.session_state or st.session_state['last_selected_monday'] != st.session_state['selected_monday']:
            # å…¨åº—èˆ—ã®daily_reports_inputã‚’åˆæœŸåŒ–
            for store_name in store_names:
                st.session_state['daily_reports_input'][store_name] = {
                    (monday_of_week + timedelta(days=i)).strftime('%Y-%m-%d'): {"trend": "", "factors": []} for i in range(7)
                }
            st.session_state['topics_input'] = ""
            st.session_state['impact_day_input'] = ""
            st.session_state['quantitative_data_input'] = ""
            st.session_state['generated_report_output'] = None
            st.session_state['modified_report_output'] = None
            st.session_state['report_id_to_edit'] = None
            st.session_state['topics_loaded_for_week'] = False
            
            # æ–°ã—ã„é€±ã«å¤‰æ›´ã•ã‚ŒãŸå ´åˆã¯ã€æ”¹ã‚ã¦æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
            for store_name in store_names:
                store_id = db_manager.get_store_id_by_name(store_name)
                existing_report = db_manager.get_weekly_report(store_id, st.session_state['selected_monday'])
                
                if existing_report and existing_report.get('daily_reports', {}).get(store_name):
                    st.session_state['daily_reports_input'][store_name] = existing_report['daily_reports'][store_name]
                    
                    if not st.session_state.get('topics_loaded_for_week'):
                        st.session_state['topics_input'] = existing_report.get('topics', '')
                        st.session_state['impact_day_input'] = existing_report.get('impact_day', '')
                        st.session_state['quantitative_data_input'] = existing_report.get('quantitative_data', '')
                        st.session_state['generated_report_output'] = existing_report.get('generated_report', {})
                        st.session_state['modified_report_output'] = existing_report.get('modified_report')
                        st.session_state['report_id_to_edit'] = existing_report.get('id')
                        st.session_state['topics_loaded_for_week'] = True
        st.session_state['last_selected_monday'] = st.session_state['selected_monday']
        st.session_state['last_selected_monday'] = st.session_state['selected_monday']

    st.header("2. æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®å…¥åŠ›")
    st.markdown("å„åº—èˆ—ã®**æ—¥ã”ã¨ã®å‹•å‘ã¨è¦å› **ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚è¦å› ã¯è¤‡æ•°å…¥åŠ›å¯èƒ½ã§ã™ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ã€‚")
    
    # åº—èˆ—é¸æŠã‚’ãƒ©ã‚¸ã‚ªãƒœã‚¿ãƒ³ã§æ˜ç¢ºã«ã™ã‚‹
    selected_store_for_input = st.radio(
        "**ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹åº—èˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„:**",
        store_names,
        index=store_names.index(st.session_state.get('selected_store_for_report', store_names[0])),
        horizontal=True
    )
    
    # é¸æŠã•ã‚ŒãŸåº—èˆ—ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã®å‡¦ç†
    if selected_store_for_input != st.session_state.get('selected_store_for_report'):
        st.session_state['selected_store_for_report'] = selected_store_for_input
        
        # å¤‰æ›´ã•ã‚ŒãŸåº—èˆ—ã®æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿
        store_id = db_manager.get_store_id_by_name(selected_store_for_input)
        existing_report = db_manager.get_weekly_report(store_id, st.session_state['selected_monday'])
        
        if existing_report and existing_report.get('daily_reports', {}).get(selected_store_for_input):
            # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã¯å¾©å…ƒ
            st.session_state['daily_reports_input'][selected_store_for_input] = existing_report['daily_reports'][selected_store_for_input]
            st.rerun()  # ç”»é¢ã‚’æ›´æ–°ã—ã¦æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
    else:
        # é¸æŠã•ã‚ŒãŸåº—èˆ—ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜
        st.session_state['selected_store_for_report'] = selected_store_for_input
    
    st.markdown(f"**ç¾åœ¨é¸æŠä¸­:** {selected_store_for_input}åº—")
    
    # è‡ªå‹•ä¿å­˜çŠ¶æ³ã‚’è¡¨ç¤º
    if 'last_auto_save' not in st.session_state:
        st.session_state['last_auto_save'] = None
    if 'last_auto_save_timestamp' not in st.session_state:
        st.session_state['last_auto_save_timestamp'] = None
    
    if st.session_state['last_auto_save']:
        # ä¿å­˜ã‹ã‚‰ã®çµŒéæ™‚é–“ã‚’è¨ˆç®—
        if st.session_state['last_auto_save_timestamp']:
            current_time = get_japan_time().timestamp()
            elapsed_seconds = int(current_time - st.session_state['last_auto_save_timestamp'])
            
            if elapsed_seconds < 60:
                elapsed_text = f"ï¼ˆ{elapsed_seconds}ç§’å‰ï¼‰"
            elif elapsed_seconds < 3600:
                elapsed_minutes = elapsed_seconds // 60
                elapsed_text = f"ï¼ˆ{elapsed_minutes}åˆ†å‰ï¼‰"
            else:
                elapsed_hours = elapsed_seconds // 3600
                elapsed_text = f"ï¼ˆ{elapsed_hours}æ™‚é–“å‰ï¼‰"
        else:
            elapsed_text = ""
        
        st.success(f"âœ… è‡ªå‹•ä¿å­˜æ¸ˆã¿: {st.session_state['last_auto_save']} {elapsed_text}")
    else:
        st.info("ğŸ’¾ å…¥åŠ›å†…å®¹ã¯è‡ªå‹•çš„ã«ä¿å­˜ã•ã‚Œã¾ã™")
    
    st.markdown("---")

    # é¸æŠã•ã‚ŒãŸåº—èˆ—ã®daily_reports_inputã‚’ç¢ºå®Ÿã«åˆæœŸåŒ–
    if selected_store_for_input not in st.session_state['daily_reports_input']:
        st.session_state['daily_reports_input'][selected_store_for_input] = {
            (monday_of_week + timedelta(days=i)).strftime('%Y-%m-%d'): {"trend": "", "factors": []} for i in range(7)
        }

    # é¸æŠã•ã‚ŒãŸåº—èˆ—ã®æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆå…¥åŠ›æ¬„ã®ã¿ã‚’è¡¨ç¤º
    for j in range(7): # æœˆæ›œæ—¥ã‹ã‚‰æ—¥æ›œæ—¥ã¾ã§
        current_date = monday_of_week + timedelta(days=j)
        date_str = current_date.strftime('%Y-%m-%d')
        day_name = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"][j]

        st.subheader(f"ğŸ—“ï¸ {current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ({day_name})")
        
        # date_strè¾æ›¸ã®åˆæœŸåŒ–ã‚’ç¢ºä¿
        if date_str not in st.session_state['daily_reports_input'][selected_store_for_input]:
            st.session_state['daily_reports_input'][selected_store_for_input][date_str] = {"trend": "", "factors": []}
        
        # æ—¥æ¬¡å‹•å‘
        trend_value = st.text_area(
            f"**{current_date.strftime('%m/%d')} å‹•å‘:**",
            value=st.session_state['daily_reports_input'][selected_store_for_input].get(date_str, {}).get('trend', ''),
            key=f"{selected_store_for_input}_{date_str}_trend",
            height=80
        )
        
        # å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã«è‡ªå‹•ä¿å­˜
        if trend_value != st.session_state['daily_reports_input'][selected_store_for_input][date_str]['trend']:
            st.session_state['daily_reports_input'][selected_store_for_input][date_str]['trend'] = trend_value
            
        # æ—¥æ¬¡è¦å› 
        factors_str = ", ".join(st.session_state['daily_reports_input'][selected_store_for_input].get(date_str, {}).get('factors', []))
        new_factors_str = st.text_input(
            f"**{current_date.strftime('%m/%d')} è¦å›  (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š):**",
            value=factors_str,
            key=f"{selected_store_for_input}_{date_str}_factors"
        )
        
        # å€¤ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã«è‡ªå‹•ä¿å­˜
        new_factors_list = [f.strip() for f in new_factors_str.split(',') if f.strip()]
        if new_factors_list != st.session_state['daily_reports_input'][selected_store_for_input][date_str]['factors']:
            st.session_state['daily_reports_input'][selected_store_for_input][date_str]['factors'] = new_factors_list
    
    # æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿å…¥åŠ›å®Œäº†å¾Œã«è‡ªå‹•ä¿å­˜ï¼ˆå…¨ã¦ã®æ—¥ä»˜ã®å…¥åŠ›ãŒå®Œäº†ã—ã¦ã‹ã‚‰å®Ÿè¡Œï¼‰
    # ãƒ‡ãƒã‚¦ãƒ³ã‚¹å‡¦ç†: å…¥åŠ›ä¸­ã®ä¿å­˜ã‚’é¿ã‘ã‚‹ãŸã‚ã€å…¨æ—¥ä»˜ãƒ«ãƒ¼ãƒ—å®Œäº†å¾Œã«ä¸€åº¦ã ã‘ä¿å­˜
    auto_save_triggered = False
    for i in range(7):
        check_date = monday_of_week + timedelta(days=i)
        check_date_str = check_date.strftime('%Y-%m-%d')
        if (st.session_state['daily_reports_input'][selected_store_for_input].get(check_date_str, {}).get('trend') or 
            st.session_state['daily_reports_input'][selected_store_for_input].get(check_date_str, {}).get('factors')):
            auto_save_triggered = True
            break
    
    if auto_save_triggered:
        save_draft_data(
            selected_store_for_input,
            st.session_state['selected_monday'],
            {selected_store_for_input: st.session_state['daily_reports_input'][selected_store_for_input]},
            st.session_state.get('topics_input', ''),
            st.session_state.get('impact_day_input', ''),
            st.session_state.get('quantitative_data_input', '')
        )
    
    st.markdown("---")

    st.header("3. é€±å…¨ä½“ã®è¿½åŠ æƒ…å ± (ä»»æ„)")
    
    # TOPICSå…¥åŠ›
    new_topics = st.text_area(
        "**TOPICS:** é€±å…¨ä½“ã‚’é€šã—ã¦ç‰¹ç­†ã™ã¹ãäº‹é …ã‚„å‡ºæ¥äº‹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        value=st.session_state['topics_input'],
        height=100,
        key="topics_input_field"
    )
    if new_topics != st.session_state['topics_input']:
        st.session_state['topics_input'] = new_topics
        # è‡ªå‹•ä¿å­˜
        if save_draft_data(
            selected_store_for_input,
            st.session_state['selected_monday'],
            {selected_store_for_input: st.session_state['daily_reports_input'][selected_store_for_input]},
            new_topics,
            st.session_state.get('impact_day_input', ''),
            st.session_state.get('quantitative_data_input', '')
        ):
            st.rerun()  # ä¿å­˜å¾Œã«ç”»é¢ã‚’æ›´æ–°ã—ã¦æ™‚åˆ»ã‚’è¡¨ç¤º
    
    # ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§å…¥åŠ›
    new_impact_day = st.text_area(
        "**ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§:** ç‰¹ã«å½±éŸ¿ã®å¤§ãã‹ã£ãŸæ—¥ã‚„ã‚¤ãƒ™ãƒ³ãƒˆã€ãã®å†…å®¹ã‚’è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚",
        value=st.session_state['impact_day_input'],
        height=100,
        key="impact_day_input_field"
    )
    if new_impact_day != st.session_state['impact_day_input']:
        st.session_state['impact_day_input'] = new_impact_day
        # è‡ªå‹•ä¿å­˜
        if save_draft_data(
            selected_store_for_input,
            st.session_state['selected_monday'],
            {selected_store_for_input: st.session_state['daily_reports_input'][selected_store_for_input]},
            st.session_state.get('topics_input', ''),
            new_impact_day,
            st.session_state.get('quantitative_data_input', '')
        ):
            st.rerun()  # ä¿å­˜å¾Œã«ç”»é¢ã‚’æ›´æ–°
    
    # å®šé‡ãƒ‡ãƒ¼ã‚¿å…¥åŠ›
    new_quantitative_data = st.text_area(
        "**å®šé‡ãƒ‡ãƒ¼ã‚¿:** å£²ä¸Šã€å®¢æ•°ã€å®¢å˜ä¾¡ã€ãƒ—ãƒ­ãƒ‘ãƒ¼æ¶ˆåŒ–ç‡ãªã©ã€é€±ã®å®šé‡ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚",
        value=st.session_state['quantitative_data_input'],
        height=100,
        key="quantitative_data_input_field"
    )
    if new_quantitative_data != st.session_state['quantitative_data_input']:
        st.session_state['quantitative_data_input'] = new_quantitative_data
        # è‡ªå‹•ä¿å­˜
        if save_draft_data(
            selected_store_for_input,
            st.session_state['selected_monday'],
            {selected_store_for_input: st.session_state['daily_reports_input'][selected_store_for_input]},
            st.session_state.get('topics_input', ''),
            st.session_state.get('impact_day_input', ''),
            new_quantitative_data
        ):
            st.rerun()  # ä¿å­˜å¾Œã«ç”»é¢ã‚’æ›´æ–°

    st.markdown("---")

    # ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›ãƒœã‚¿ãƒ³
    st.header("4. ãƒ¬ãƒãƒ¼ãƒˆå‡ºåŠ›")
    if st.button("å‡ºåŠ›", type="primary"):
        # AIç”Ÿæˆç”¨ã«æ•´å½¢ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿ã‚’ä½œæˆ
        # daily_reports_input ã¯å…¨åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‚’æŒã£ã¦ã„ã‚‹ãŸã‚ã€ç¾åœ¨é¸æŠä¸­ã®åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ã‚’æ¸¡ã™
        selected_store_name = st.session_state['selected_store_for_report']
        data_for_ai = {
            'daily_reports': {selected_store_name: st.session_state['daily_reports_input'][selected_store_name]},
            'topics': st.session_state['topics_input'],
            'impact_day': st.session_state['impact_day_input'],
            'quantitative_data': st.session_state['quantitative_data_input']
        }

        # APIã‚­ãƒ¼ã®ç¢ºèª
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«APIã‚­ãƒ¼ã®è¨­å®šã‚’ä¾é ¼ã—ã¦ãã ã•ã„ã€‚")
            st.info("ç®¡ç†è€…ã®æ–¹ã¯ã€`.env`ãƒ•ã‚¡ã‚¤ãƒ«ã«`OPENAI_API_KEY=your_api_key_here`ã®å½¢å¼ã§APIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„ã€‚")
            return
        
        # OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–
        if not report_generator.initialize_openai(openai_api_key):
            # ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯ initialize_openai å†…ã§è¡¨ç¤ºæ¸ˆã¿
            return

        with st.spinner("AIãŒãƒ¬ãƒãƒ¼ãƒˆã‚’åˆ†æãƒ»ç”Ÿæˆä¸­ã§ã™... å°‘ã€…ãŠå¾…ã¡ãã ã•ã„ã€‚"):
            generated_report = report_generator.analyze_trend_factors(
                data_for_ai['daily_reports'], # ã“ã“ã§ã¯ã™ã§ã«é¸æŠã•ã‚ŒãŸåº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã®ã¿ãŒæ¸¡ã•ã‚Œã‚‹
                data_for_ai['topics'],
                data_for_ai['impact_day'],
                data_for_ai['quantitative_data']
            )

        if generated_report:
            st.session_state['generated_report_output'] = generated_report
            st.session_state['modified_report_output'] = None # AIç”Ÿæˆæ™‚ã«ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆã¯ã‚¯ãƒªã‚¢
            st.success("AIãƒ¬ãƒãƒ¼ãƒˆã®ç”ŸæˆãŒå®Œäº†ã—ã¾ã—ãŸï¼")
            st.rerun() # ãƒšãƒ¼ã‚¸ã‚’å†æç”»ã—ã¦çµæœã‚’è¡¨ç¤º
        else:
            st.error("AIãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å…¥åŠ›å†…å®¹ã‚’ç¢ºèªã™ã‚‹ã‹ã€å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")

    if st.session_state['generated_report_output']:
        st.subheader("ç”Ÿæˆã•ã‚ŒãŸé€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ (AIç”Ÿæˆ)")
        st.markdown("**é€±å…¨ä½“ã®å‹•å‘ã¨è¦å› :**")
        st.write(st.session_state['generated_report_output'].get('trend', ''))
        st.markdown("**ä¸»ãªè¦å› :**")
        for i, factor in enumerate(st.session_state['generated_report_output'].get('factors', [])):
            st.write(f"- {factor}")
        
        if st.session_state['generated_report_output'].get('questions'):
            st.markdown("**AIã‹ã‚‰ã®è³ªå•:**")
            for q in st.session_state['generated_report_output'].get('questions', []):
                st.write(f"- {q}")
        
        # ãƒ¬ãƒãƒ¼ãƒˆä¿å­˜ãƒœã‚¿ãƒ³
        if st.button("ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿å­˜", type="secondary"):
            store_id = db_manager.get_store_id_by_name(st.session_state['selected_store_for_report'])
            monday_date_str = st.session_state['selected_monday']
            
            data_to_save = {
                'daily_reports': st.session_state['daily_reports_input'][st.session_state['selected_store_for_report']],
                'topics': st.session_state['topics_input'],
                'impact_day': st.session_state['impact_day_input'],
                'quantitative_data': st.session_state['quantitative_data_input']
            }
            
            is_updated = db_manager.save_weekly_data(
                store_id,
                monday_date_str,
                data_to_save,
                st.session_state['generated_report_output'],
                st.session_state['modified_report_output'] # ã¾ã ä¿®æ­£ãŒãªã„ã®ã§Noneã®å¯èƒ½æ€§
            )
            if is_updated:
                st.success("é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãŒæ›´æ–°ã•ã‚Œã¾ã—ãŸï¼")
            else:
                st.success("é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãŒä¿å­˜ã•ã‚Œã¾ã—ãŸï¼")
            st.session_state['report_id_to_edit'] = db_manager.get_weekly_report(store_id, monday_date_str).get('id') # ä¿å­˜ã—ãŸãƒ¬ãƒãƒ¼ãƒˆã®IDã‚’å–å¾—

    st.markdown("---")

    # ãƒ¬ãƒãƒ¼ãƒˆä¿®æ­£ã‚¨ãƒªã‚¢ (ç”Ÿæˆæ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º)
    if st.session_state['generated_report_output'] or st.session_state['modified_report_output']:
        st.header("5. ãƒ¬ãƒãƒ¼ãƒˆã®ä¿®æ­£ã¨å­¦ç¿’ (ä»»æ„)")
        st.info("AIãŒç”Ÿæˆã—ãŸãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿®æ­£ã—ã€ã€Œä¿®æ­£ã—ã¦å­¦ç¿’ã€ãƒœã‚¿ãƒ³ã‚’æŠ¼ã™ã¨ã€ã‚·ã‚¹ãƒ†ãƒ ãŒãã®ä¿®æ­£ã‹ã‚‰å­¦ã³ã€å°†æ¥ã®ãƒ¬ãƒãƒ¼ãƒˆç²¾åº¦å‘ä¸Šã«å½¹ç«‹ã¦ã¾ã™ã€‚")

        report_to_display = st.session_state['modified_report_output'] if st.session_state['modified_report_output'] else st.session_state['generated_report_output']

        modified_trend = st.text_area(
            "**ä¿®æ­£å¾Œã®é€±å…¨ä½“ã®å‹•å‘ã¨è¦å› :**",
            value=report_to_display.get('trend', ''),
            key="modified_trend_input",
            height=200
        )
        modified_factors_str = st.text_input(
            "**ä¿®æ­£å¾Œã®ä¸»ãªè¦å›  (ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š):**",
            value=", ".join(report_to_display.get('factors', [])),
            key="modified_factors_input"
        )
        modified_questions_str = st.text_area(
            "**ä¿®æ­£å¾Œã®AIã¸ã®è³ªå•:**",
            value="\n".join(report_to_display.get('questions', [])),
            key="modified_questions_input",
            height=100
        )
        edit_reason = st.text_area(
            "**ä¿®æ­£ç†ç”± (å­¦ç¿’ã®ãŸã‚ã«é‡è¦ã§ã™):** ä½•ã‚’ã€ãªãœä¿®æ­£ã—ãŸã®ã‹ã‚’å…·ä½“çš„ã«è¨˜è¿°ã—ã¦ãã ã•ã„ã€‚",
            key="edit_reason_input",
            height=100
        )
        
        modified_factors = [f.strip() for f in modified_factors_str.split(',') if f.strip()]
        modified_questions = [q.strip() for q in modified_questions_str.split('\n') if q.strip()]

        if st.button("ä¿®æ­£ã—ã¦å­¦ç¿’", type="primary", key="learn_from_correction_button"):
            if not edit_reason.strip():
                st.error("ä¿®æ­£ç†ç”±ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã¯AIã®å­¦ç¿’ã«ä¸å¯æ¬ ã§ã™ã€‚")
            else:
                modified_report_data = {
                    "trend": modified_trend,
                    "factors": modified_factors,
                    "questions": modified_questions,
                    "edit_reason": edit_reason
                }
                st.session_state['modified_report_output'] = modified_report_data

                store_id = db_manager.get_store_id_by_name(st.session_state['selected_store_for_report'])
                monday_date_str = st.session_state['selected_monday']
                
                # session_stateã®ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚’ç¢ºä¿
                if 'daily_reports_input' not in st.session_state:
                    st.session_state['daily_reports_input'] = {}
                if st.session_state['selected_store_for_report'] not in st.session_state['daily_reports_input']:
                    st.session_state['daily_reports_input'][st.session_state['selected_store_for_report']] = {}
                
                input_data_for_learning = {
                    'daily_reports': {st.session_state['selected_store_for_report']: st.session_state['daily_reports_input'][st.session_state['selected_store_for_report']]},
                    'topics': st.session_state.get('topics_input', []),
                    'impact_day': st.session_state.get('impact_day_input', ''),
                    'quantitative_data': st.session_state.get('quantitative_data_input', {})
                }

                # DBã«ä¿å­˜ã—ã€å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã«æ¸¡ã™
                db_manager.save_weekly_data(
                    store_id,
                    monday_date_str,
                    input_data_for_learning, # daily_reports_inputã‚’ç›´æ¥æ¸¡ã™
                    st.session_state['generated_report_output'],
                    modified_report_data
                )
                
                learning_engine.learn_from_correction(
                    input_data=input_data_for_learning,
                    original_output=st.session_state['generated_report_output'],
                    modified_output=modified_report_data
                )
                st.success("ä¿®æ­£å†…å®¹ãŒä¿å­˜ã•ã‚Œã€ã‚·ã‚¹ãƒ†ãƒ ãŒå­¦ç¿’ã—ã¾ã—ãŸï¼")
                st.rerun()


def show_report_history_page():
    st.title("ğŸ“š ãƒ¬ãƒãƒ¼ãƒˆå±¥æ­´")
    st.markdown("---")

    st.info("ã“ã“ã§ã¯ã€ã“ã‚Œã¾ã§ã«ä½œæˆãƒ»ä¿å­˜ã•ã‚ŒãŸé€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®ä¸€è¦§ã‚’ç¢ºèªã§ãã¾ã™ã€‚")

    all_stores = db_manager.get_all_stores()
    store_names = [s[1] for s in all_stores]
    store_id_map = {s[1]: s[0] for s in all_stores}

    selected_store_name = st.selectbox("è¡¨ç¤ºã™ã‚‹åº—èˆ—ã‚’é¸æŠ:", ["å…¨åº—èˆ—"] + store_names)

    if selected_store_name == "å…¨åº—èˆ—":
        reports = db_manager.get_all_weekly_reports()
    else:
        selected_store_id = store_id_map[selected_store_name]
        reports = db_manager.get_all_weekly_reports(selected_store_id)

    if not reports:
        st.warning("è¡¨ç¤ºã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    report_data = []
    for r in reports:
        # store_name ã¯æ—¢ã« DBManager ã§è¿½åŠ ã•ã‚Œã¦ã„ã‚‹ã¯ãš
        try:
            store_name = db_manager.get_store_name_by_id(r['store_id'])
        except Exception as e:
            store_name = f"åº—èˆ—ID:{r['store_id']}"
            
        report_data.append({
            "ID": r['id'],
            "åº—èˆ—å": store_name,
            "é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ (æœˆæ›œæ—¥)": r['monday_date'],
            "æœ€çµ‚æ›´æ–°æ—¥æ™‚": datetime.fromisoformat(r['timestamp']).strftime('%Y/%m/%d %H:%M'),
            "AIç”Ÿæˆæ¸ˆã¿": "ã¯ã„" if r['has_generated'] else "ã„ã„ãˆ",
            "ä¿®æ­£æ¸ˆã¿": "ã¯ã„" if r['has_modified'] else "ã„ã„ãˆ",
            "ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰": f"Download_{r['id']}" # ãƒ€ãƒŸãƒ¼ã®åˆ—å
        })
    
    df = pd.DataFrame(report_data)

    st.dataframe(df.set_index('ID'), use_container_width=True)

    # ãƒ¬ãƒãƒ¼ãƒˆè©³ç´°è¡¨ç¤ºãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    st.subheader("ãƒ¬ãƒãƒ¼ãƒˆã®è©³ç´°è¡¨ç¤ºã¨ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰")
    report_ids = [r['id'] for r in reports]
    
    if report_ids:
        selected_report_id = st.selectbox("è©³ç´°ã‚’è¡¨ç¤ºãƒ»ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆã®IDã‚’é¸æŠã—ã¦ãã ã•ã„:", report_ids)

        if selected_report_id:
            # IDã®å‹ã‚’ç¢ºèªãƒ»ä¿®æ­£ï¼ˆå¿…è¦ã«å¿œã˜ã¦æ•´æ•°ã«å¤‰æ›ï¼‰
            try:
                selected_report_id = int(selected_report_id)
            except (ValueError, TypeError):
                pass  # ã™ã§ã«é©åˆ‡ãªå‹ã®å ´åˆã¯ãã®ã¾ã¾
                
            # é¸æŠã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆIDãŒå®Ÿéš›ã«ãƒªã‚¹ãƒˆã«å­˜åœ¨ã™ã‚‹ã‹ãƒã‚§ãƒƒã‚¯
            if selected_report_id not in report_ids:
                st.error(f"é¸æŠã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆID {selected_report_id} ã¯å­˜åœ¨ã—ã¾ã›ã‚“ã€‚")
                return
                
            selected_report_db = next((r for r in reports if r['id'] == selected_report_id), None)
            
            if not selected_report_db:
                st.error(f"ãƒ¬ãƒãƒ¼ãƒˆID {selected_report_id} ã®æƒ…å ±ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                return
                
            # DBã‹ã‚‰æœ€æ–°ã®å®Œå…¨ãªãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å†å–å¾—
            try:
                full_report = db_manager.get_weekly_report(selected_report_db['store_id'], selected_report_db['monday_date'])
                
                if not full_report:
                    st.error(f"ãƒ¬ãƒãƒ¼ãƒˆID {selected_report_id} ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸã€‚")
                    return
                    
            except Exception as e:
                st.error(f"ãƒ¬ãƒãƒ¼ãƒˆå–å¾—ä¸­ã«ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {str(e)}")
                return
                
            if full_report:
                st.markdown(f"### ãƒ¬ãƒãƒ¼ãƒˆID: {full_report['id']} - {db_manager.get_store_name_by_id(full_report['store_id'])}åº— - é€±æ¬¡: {full_report['monday_date']}")
                st.write(f"æœ€çµ‚æ›´æ–°æ—¥æ™‚: {datetime.fromisoformat(full_report['timestamp']).strftime('%Y/%m/%d %H:%M')}")

                # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ç”¨ã®ãƒ‡ãƒ¼ã‚¿æ•´å½¢ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°å¼·åŒ–ï¼‰
                export_data = {
                    "ãƒ¬ãƒãƒ¼ãƒˆå¯¾è±¡é€±ã®æœˆæ›œæ—¥": full_report.get('monday_date', ''),
                    "åº—èˆ—å": db_manager.get_store_name_by_id(full_report.get('store_id', 0)),
                    "TOPICS": full_report.get('topics', ''),
                    "ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§": full_report.get('impact_day', ''),
                    "å®šé‡ãƒ‡ãƒ¼ã‚¿": full_report.get('quantitative_data', '')
                }
                
                # ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨ãªå–å¾—
                generated_report = full_report.get('generated_report', {})
                if isinstance(generated_report, dict):
                    export_data.update({
                        "AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ_å‹•å‘": generated_report.get('trend', ''),
                        "AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ_è¦å› ": ", ".join(generated_report.get('factors', [])) if generated_report.get('factors') else '',
                        "AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ_è³ªå•": "\n".join(generated_report.get('questions', [])) if generated_report.get('questions') else ''
                    })
                
                # ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®å®‰å…¨ãªå–å¾—
                modified_report = full_report.get('modified_report')
                if isinstance(modified_report, dict):
                    export_data.update({
                        "ä¿®æ­£å¾Œãƒ¬ãƒãƒ¼ãƒˆ_å‹•å‘": modified_report.get('trend', ''),
                        "ä¿®æ­£å¾Œãƒ¬ãƒãƒ¼ãƒˆ_è¦å› ": ", ".join(modified_report.get('factors', [])) if modified_report.get('factors') else '',
                        "ä¿®æ­£å¾Œãƒ¬ãƒãƒ¼ãƒˆ_è³ªå•": "\n".join(modified_report.get('questions', [])) if modified_report.get('questions') else '',
                        "ä¿®æ­£ç†ç”±": modified_report.get('edit_reason', '')
                    })
                
                # æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®è©³ç´°ã‚’å®‰å…¨ã«è¿½åŠ 
                daily_reports = full_report.get('daily_reports', {})
                if isinstance(daily_reports, dict):
                    for store_name, dates_data in daily_reports.items():
                        if isinstance(dates_data, dict):
                            for date_str, report_data in dates_data.items():
                                try:
                                    if isinstance(report_data, dict):
                                        export_data[f"æ—¥æ¬¡å‹•å‘_{store_name}_{date_str}"] = str(report_data.get('trend', ''))
                                        factors = report_data.get('factors', [])
                                        export_data[f"æ—¥æ¬¡è¦å› _{store_name}_{date_str}"] = ", ".join(factors) if isinstance(factors, list) else str(factors)
                                    else:
                                        export_data[f"æ—¥æ¬¡å‹•å‘_{store_name}_{date_str}"] = ''
                                        export_data[f"æ—¥æ¬¡è¦å› _{store_name}_{date_str}"] = ''
                                except Exception as e:
                                    print(f"æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                                    export_data[f"æ—¥æ¬¡å‹•å‘_{store_name}_{date_str}"] = ''
                                    export_data[f"æ—¥æ¬¡è¦å› _{store_name}_{date_str}"] = ''

                df_export = pd.DataFrame([export_data])
                
                # Excelãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼ˆã‚¨ãƒ©ãƒ¼ãƒãƒ³ãƒ‰ãƒªãƒ³ã‚°ä»˜ãï¼‰
                try:
                    output = BytesIO()
                    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
                        df_export.to_excel(writer, index=False, sheet_name='ãƒ¬ãƒãƒ¼ãƒˆ')
                    excel_data = output.getvalue()
                    
                    st.download_button(
                        label="ğŸ“Š ãƒ¬ãƒãƒ¼ãƒˆã‚’Excelã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=excel_data,
                        file_name=f"é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ_{full_report['monday_date']}_{db_manager.get_store_name_by_id(full_report['store_id'])}.xlsx",
                        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                    )
                except ImportError:
                    st.warning("âš ï¸ Excelå½¢å¼ã§ã®ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãŒã§ãã¾ã›ã‚“ã€‚CSVå½¢å¼ã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦ãã ã•ã„ã€‚")
                    # CSVãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã‚’ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã¨ã—ã¦æä¾›
                    csv_data = df_export.to_csv(index=False, encoding='utf-8-sig')
                    st.download_button(
                        label="ğŸ“„ ãƒ¬ãƒãƒ¼ãƒˆã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                        data=csv_data,
                        file_name=f"é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ_{full_report['monday_date']}_{db_manager.get_store_name_by_id(full_report['store_id'])}.csv",
                        mime="text/csv"
                    )

                st.markdown("#### ãƒ¬ãƒãƒ¼ãƒˆå†…å®¹ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
                
                # ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º
                modified_report = full_report.get('modified_report')
                if modified_report and isinstance(modified_report, dict):
                    st.subheader("--- æœ€çµ‚ä¿®æ­£ç‰ˆãƒ¬ãƒãƒ¼ãƒˆ ---")
                    st.markdown("**é€±å…¨ä½“ã®å‹•å‘ã¨è¦å› :**")
                    st.write(modified_report.get('trend', ''))
                    st.markdown("**ä¸»ãªè¦å› :**")
                    factors = modified_report.get('factors', [])
                    if isinstance(factors, list):
                        for factor in factors:
                            st.write(f"- {factor}")
                    
                    questions = modified_report.get('questions', [])
                    if questions and isinstance(questions, list):
                        st.markdown("**AIã¸ã®è³ªå•:**")
                        for q in questions:
                                st.write(f"- {q}")
                    
                    edit_reason = modified_report.get('edit_reason')
                    if edit_reason:
                        st.markdown("**ä¿®æ­£ç†ç”±:**")
                        st.write(edit_reason)
                
                # ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º
                generated_report = full_report.get('generated_report')
                if generated_report and isinstance(generated_report, dict):
                    st.subheader("--- AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ (ã‚ªãƒªã‚¸ãƒŠãƒ«) ---")
                    st.markdown("**é€±å…¨ä½“ã®å‹•å‘ã¨è¦å› :**")
                    st.write(generated_report.get('trend', ''))
                    st.markdown("**ä¸»ãªè¦å› :**")
                    factors = generated_report.get('factors', [])
                    if isinstance(factors, list):
                        for factor in factors:
                            st.write(f"- {factor}")
                    
                    questions = generated_report.get('questions', [])
                    if questions and isinstance(questions, list):
                        st.markdown("**AIã‹ã‚‰ã®è³ªå•:**")
                        for q in questions:
                            st.write(f"- {q}")
                
                st.subheader("--- å…¥åŠ›ãƒ‡ãƒ¼ã‚¿ ---")
                st.markdown("**æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ:**")
                daily_reports = full_report.get('daily_reports', {})
                if daily_reports and isinstance(daily_reports, dict):
                    for store_name, dates_data in daily_reports.items():
                        st.markdown(f"**{store_name}åº—**")
                        if isinstance(dates_data, dict):
                            has_data = False
                            for date_str, report_data in dates_data.items():
                                try:
                                    if isinstance(report_data, dict):
                                        trend_text = report_data.get('trend', '').strip()
                                        factors_list = report_data.get('factors', [])
                                        
                                        # å‹•å‘ã¾ãŸã¯è¦å› ã®ã„ãšã‚Œã‹ã«ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚‹å ´åˆã®ã¿è¡¨ç¤º
                                        if trend_text or (factors_list and len(factors_list) > 0):
                                            has_data = True
                                            if isinstance(factors_list, list):
                                                factors_text = ', '.join(factors_list) if factors_list else 'è¦å› ãªã—'
                                            else:
                                                factors_text = str(factors_list) if factors_list else 'è¦å› ãªã—'
                                            
                                            st.markdown(f"  - **{date_str}**")
                                            if trend_text:
                                                st.markdown(f"    å‹•å‘: {trend_text}")
                                            if factors_list:
                                                st.markdown(f"    è¦å› : {factors_text}")
                                            else:
                                                st.markdown(f"    è¦å› : è¦å› ãªã—")
                                    else:
                                        st.markdown(f"  - {date_str} ãƒ‡ãƒ¼ã‚¿å½¢å¼ã‚¨ãƒ©ãƒ¼")
                                except Exception as e:
                                    st.markdown(f"  - {date_str} ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼")
                            
                            if not has_data:
                                st.markdown("  - ã“ã®åº—èˆ—ã«ã¯å…¥åŠ›æ¸ˆã¿ã®æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                        else:
                            st.markdown("  - ãƒ‡ãƒ¼ã‚¿æ§‹é€ ã‚¨ãƒ©ãƒ¼")
                else:
                    st.markdown("æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

                st.markdown("**TOPICS:**")
                st.write(full_report.get('topics', 'N/A'))
                st.markdown("**ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§:**")
                st.write(full_report.get('impact_day', 'N/A'))
                st.markdown("**å®šé‡ãƒ‡ãƒ¼ã‚¿:**")
                st.write(full_report.get('quantitative_data', 'N/A'))
            else:
                st.warning("é¸æŠã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã®è©³ç´°ã‚’èª­ã¿è¾¼ã‚ã¾ã›ã‚“ã§ã—ãŸã€‚")
    else:
        st.info("ãƒ¬ãƒãƒ¼ãƒˆå±¥æ­´ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

def show_settings_page():
    st.title("âš™ï¸ è¨­å®š")
    st.markdown("---")

    st.subheader("OpenAI APIã‚­ãƒ¼è¨­å®š")
    
    # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰ç¾åœ¨ã®APIã‚­ãƒ¼ã®è¨­å®šçŠ¶æ³ã‚’ç¢ºèª
    current_api_key = os.getenv("OPENAI_API_KEY", "")
    
    if current_api_key:
        st.success("âœ… OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã™ã€‚")
        st.info("APIã‚­ãƒ¼ã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¾ã‚Œã¦ã„ã¾ã™ã€‚å¤‰æ›´ãŒå¿…è¦ãªå ´åˆã¯ã€ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„ã€‚")
    else:
        st.error("âŒ OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
        st.warning("ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…ã«OpenAI APIã‚­ãƒ¼ã®è¨­å®šã‚’ä¾é ¼ã—ã¦ãã ã•ã„ã€‚")
        st.markdown("""
        **ç®¡ç†è€…å‘ã‘è¨­å®šæ‰‹é †:**
        1. `.env`ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã¾ãŸã¯ç·¨é›†
        2. `OPENAI_API_KEY=your_api_key_here` ã®å½¢å¼ã§APIã‚­ãƒ¼ã‚’è¨­å®š
        3. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å†èµ·å‹•
        """)

    st.markdown("---")

    st.subheader("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ç®¡ç† (é–‹ç™ºä¸­)")
    st.info("AIã®ç²¾åº¦å‘ä¸Šã«ä½¿ç”¨ã•ã‚Œã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ç®¡ç†ã—ã¾ã™ã€‚")

    learning_stats = db_manager.get_learning_stats()
    st.write(f"ç™»éŒ²ã•ã‚Œã¦ã„ã‚‹ãƒ¬ãƒãƒ¼ãƒˆæ•°: **{learning_stats['total_reports']}**")
    st.write(f"ãƒ¦ãƒ¼ã‚¶ãƒ¼ä¿®æ­£æ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆæ•°: **{learning_stats['corrections']}**")
    st.write(f"å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°: **{learning_stats['patterns']}**")

    # å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆæ©Ÿèƒ½ (ä¾‹)
    st.markdown("---")
    st.subheader("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    if st.button("å…¨å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ (é–‹ç™ºè€…å‘ã‘)"):
        # ä»®ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ­ã‚¸ãƒƒã‚¯ï¼ˆå®Ÿéš›ã«ã¯learning_patternsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰å–å¾—ï¼‰
        conn = db_manager._get_connection()
        learning_data_df = pd.read_sql_query("SELECT * FROM learning_patterns", conn)
        conn.close()

        if not learning_data_df.empty:
            st.download_button(
                label="å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’CSVã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=learning_data_df.to_csv(index=False, encoding='utf-8-sig'),
                file_name="learning_data_export.csv",
                mime="text/csv"
            )
            st.success("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¾ã—ãŸã€‚")
        else:
            st.warning("ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")


# ãƒ¡ã‚¤ãƒ³ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³
st.sidebar.title("ãƒŠãƒ“ã‚²ãƒ¼ã‚·ãƒ§ãƒ³")
selection = st.sidebar.radio("Go to", ["é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ", "ãƒ¬ãƒãƒ¼ãƒˆå±¥æ­´", "è¨­å®š"])

if selection == "é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ":
    show_report_creation_page()
elif selection == "ãƒ¬ãƒãƒ¼ãƒˆå±¥æ­´":
    show_report_history_page()
elif selection == "è¨­å®š":
    show_settings_page()