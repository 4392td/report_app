import streamlit as st
import pandas as pd
import openai
from datetime import datetime, timedelta, date
import json
import re
from typing import Dict, List, Tuple
import base64
from io import BytesIO
import numpy as np
import sqlite3
import pickle
from pathlib import Path
import hashlib # ãƒãƒƒã‚·ãƒ¥ç”Ÿæˆç”¨ã«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
from dotenv import load_dotenv # è¿½åŠ 
import os # è¿½åŠ 

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‚’ãƒ­ãƒ¼ãƒ‰
load_dotenv()

# --- Streamlitã‚¢ãƒ—ãƒªã®ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®š ---
# ã‚¢ãƒ—ãƒªå…¨ä½“ã®èƒŒæ™¯ã‚’ç™½ã€æ–‡å­—ã‚’é»’ã«è¨­å®š
st.markdown(
    """
    <style>
    body {
        background-color: white !important;
        color: black !important;
    }
    .stApp {
        background-color: white !important;
        color: black !important;
    }
    /* Streamlitã‚¦ã‚£ã‚¸ã‚§ãƒƒãƒˆã®è¦‹ãŸç›®ã‚’ã•ã‚‰ã«èª¿æ•´ */
    h1, h2, h3, h4, h5, h6, strong, p, div, span, label {
        color: black !important;
    }
    div[data-testid="stSidebar"] {
        background-color: #f0f0f0 !important; /* ã‚µã‚¤ãƒ‰ãƒãƒ¼ã®èƒŒæ™¯ã‚’å°‘ã—è–„ã„ã‚°ãƒ¬ãƒ¼ã« (å¥½ã¿ã§èª¿æ•´) */
        color: black !important;
    }
    .stTextInput label, .stTextArea label, .stSelectbox label {
        color: black !important;
    }
    textarea {
        background-color: white !important;
        color: black !important;
        border: 1px solid #ccc !important;
        border-radius: 5px !important;
        padding: 10px !important;
    }
    textarea[disabled] { /* èª­ã¿å–ã‚Šå°‚ç”¨ã®ãƒ†ã‚­ã‚¹ãƒˆã‚¨ãƒªã‚¢ã®ã‚¹ã‚¿ã‚¤ãƒ« */
        background-color: #f9f9f9 !important;
        color: #555 !important;
        opacity: 0.8 !important;
    }
    input[type="text"] {
        background-color: white !important;
        color: black !important;
        border: 1px solid #ccc !important;
        border-radius: 5px !important;
        padding: 10px !important;
    }
    /* ãƒœã‚¿ãƒ³ã®ã‚¹ã‚¿ã‚¤ãƒ« */
    button {
        background-color: #007bff !important;
        color: white !important;
        border-radius: 5px !important;
        padding: 8px 15px !important;
        transition: background-color 0.2s !important;
        border: none !important;
    }
    button:hover {
        background-color: #0056b3 !important;
    }
    button[data-testid="stFormSubmitButton"] {
        background-color: #28a745 !important;
    }
    button[data-testid="stFormSubmitButton"]:hover {
        background-color: #218838 !important;
    }
    /* æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è‰² */
    div[data-testid="stAlert"] div[role="alert"].streamlit-success {
        background-color: #d4edda !important;
        color: #155724 !important;
        border-color: #c3e6cb !important;
    }
    /* è­¦å‘Šãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è‰² */
    div[data-testid="stAlert"] div[role="alert"].streamlit-warning {
        background-color: #fff3cd !important;
        color: #856404 !important;
        border-color: #ffeeba !important;
    }
    /* ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®è‰² */
    div[data-testid="stAlert"] div[role="alert"].streamlit-error {
        background-color: #f8d7da !important;
        color: #721c24 !important;
        border-color: #f5c6cb !important;
    }
    .css-1ht1j8x { /* ãƒ¡ãƒˆãƒªãƒƒã‚¯ã®èƒŒæ™¯ã‚’ç™½ã« */
        background-color: white !important;
        border-radius: 0.5rem;
        padding: 1rem;
        box-shadow: 0 0.125rem 0.25rem rgba(0, 0, 0, 0.075) !important;
        border: 1px solid #e0e0e0;
    }
    </style>
    """,
    unsafe_allow_html=True
)
# --- ã‚¹ã‚¿ã‚¤ãƒ«è¨­å®šã“ã“ã¾ã§ ---

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ã‚¢ãƒ‘ãƒ¬ãƒ«åº—èˆ—é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆã‚·ã‚¹ãƒ†ãƒ ",
    page_icon="ğŸª",
    layout="wide",
    initial_sidebar_state="expanded"
)

# --- ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹è¨­å®šã¨ãƒ˜ãƒ«ãƒ‘ãƒ¼é–¢æ•° ---
DB_PATH = 'apparel_reports.db' # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«åå¤‰æ›´

class DBManager:
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã¨æ“ä½œã‚’ç®¡ç†ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    def __init__(self, db_path: str = DB_PATH):
        self.db_path = db_path
        self._init_db()

    def _get_connection(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚’ç¢ºç«‹ã—ã€Rowãƒ•ã‚¡ã‚¯ãƒˆãƒªã‚’è¨­å®šã—ã¾ã™ã€‚"""
        conn = sqlite3.connect(self.db_path)
        conn.row_factory = sqlite3.Row # ã‚«ãƒ©ãƒ åã§ã‚¢ã‚¯ã‚»ã‚¹ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹
        return conn

    def _init_db(self):
        """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’åˆæœŸåŒ–ã—ã¾ã™ã€‚æŒ‡å®šã•ã‚ŒãŸåº—èˆ—åã®ã¿ã‚’ç™»éŒ²ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        with conn:
            conn.execute('''
                CREATE TABLE IF NOT EXISTS stores (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    name TEXT NOT NULL UNIQUE
                );
            ''')
            conn.execute('''
                CREATE TABLE IF NOT EXISTS weekly_reports (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    store_id INTEGER NOT NULL,
                    monday_date TEXT NOT NULL, -- YYYY-MM-DDå½¢å¼
                    
                    daily_reports_json TEXT,    -- å„æ›œæ—¥ã®å‹•å‘ã¨è¦å› ã‚’JSONæ–‡å­—åˆ—ã§ä¿å­˜
                    topics TEXT,
                    impact_day TEXT,
                    quantitative_data TEXT,
                    
                    generated_report_json TEXT, -- AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆï¼ˆå‹•å‘ã€è¦å› ã€è³ªå•ï¼‰ã‚’JSONã§ä¿å­˜
                    modified_report_json TEXT,  -- ä¿®æ­£å¾Œã®ãƒ¬ãƒãƒ¼ãƒˆï¼ˆå‹•å‘ã€è¦å› ã€ä¿®æ­£ç†ç”±ãªã©ï¼‰ã‚’JSONã§ä¿å­˜
                    
                    timestamp TEXT,             -- ä½œæˆ/æœ€çµ‚æ›´æ–°æ—¥æ™‚
                    FOREIGN KEY (store_id) REFERENCES stores(id),
                    UNIQUE(store_id, monday_date)
                );
            ''')
            
            conn.execute('''
                CREATE TABLE IF NOT EXISTS learning_patterns (
                    id INTEGER PRIMARY KEY AUTOINCREMENT,
                    input_context_hash TEXT NOT NULL UNIQUE, -- å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒã‚·ãƒ¥å€¤
                    original_output_json TEXT,
                    modified_output_json TEXT,
                    edit_reason TEXT,
                    usage_count INTEGER DEFAULT 1,
                    last_used TEXT
                )
            ''')
            
            # æŒ‡å®šã•ã‚ŒãŸåº—èˆ—åã®ã¿ã‚’æŒ¿å…¥ (æ—¢ã«å­˜åœ¨ã™ã‚‹å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—)
            for store_name in ['RAY', 'RSJ', 'ROS', 'RNG']:
                conn.execute("INSERT OR IGNORE INTO stores (name) VALUES (?)", (store_name,))
            conn.commit()
        conn.close()

    def get_store_id_by_name(self, store_name: str) -> int:
        """ã‚¹ãƒˆã‚¢åã‹ã‚‰IDã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        store_id = conn.execute('SELECT id FROM stores WHERE name = ?', (store_name,)).fetchone()['id']
        conn.close()
        return store_id

    def get_store_name_by_id(self, store_id: int) -> str:
        """ã‚¹ãƒˆã‚¢IDã‹ã‚‰åå‰ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        store_name = conn.execute('SELECT name FROM stores WHERE id = ?', (store_id,)).fetchone()['id']
        conn.close()
        return store_name
    
    def get_all_stores(self) -> List[Tuple[int, str]]:
        """å…¨ã¦ã®åº—èˆ—ã®IDã¨åå‰ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        stores = conn.execute('SELECT id, name FROM stores ORDER BY name').fetchall()
        conn.close()
        return [(s['id'], s['name']) for s in stores]

    def save_weekly_data(self, store_id: int, monday_date_str: str, data: Dict, original_report: Dict, modified_report: Dict = None):
        """é€±æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’DBã«ä¿å­˜ã¾ãŸã¯æ›´æ–°ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        daily_reports_json = json.dumps(data['daily_reports'], ensure_ascii=False)
        generated_report_json = json.dumps(original_report, ensure_ascii=False)
        modified_report_json = json.dumps(modified_report, ensure_ascii=False) if modified_report else None
        
        cursor.execute(
            'SELECT id FROM weekly_reports WHERE store_id = ? AND monday_date = ?',
            (store_id, monday_date_str)
        )
        existing_record = cursor.fetchone()

        if existing_record:
            cursor.execute('''
                UPDATE weekly_reports SET
                   daily_reports_json = ?, topics = ?, impact_day = ?,
                   quantitative_data = ?, generated_report_json = ?,
                   modified_report_json = ?, timestamp = ?
                WHERE id = ?
            ''', (
                daily_reports_json,
                data.get('topics', ''),
                data.get('impact_day', ''),
                data.get('quantitative_data', ''),
                generated_report_json,
                modified_report_json,
                datetime.now().isoformat(),
                existing_record['id']
            ))
        else:
            cursor.execute('''
                INSERT INTO weekly_reports 
                (store_id, monday_date, daily_reports_json, topics, impact_day, 
                 quantitative_data, generated_report_json, modified_report_json, timestamp)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                store_id,
                monday_date_str,
                daily_reports_json,
                data.get('topics', ''),
                data.get('impact_day', ''),
                data.get('quantitative_data', ''),
                generated_report_json,
                modified_report_json,
                datetime.now().isoformat()
            ))
        
        conn.commit()
        conn.close()
        return existing_record is not None

    def get_weekly_report(self, store_id: int, monday_date_str: str) -> Dict:
        """æŒ‡å®šã•ã‚ŒãŸé€±ã®ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        report_row = conn.execute(
            'SELECT * FROM weekly_reports WHERE store_id = ? AND monday_date = ?',
            (store_id, monday_date_str)
        ).fetchone()
        conn.close()

        if report_row:
            report_data = dict(report_row) # Rowã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã‚’è¾æ›¸ã«å¤‰æ›
            report_data['daily_reports'] = json.loads(report_data['daily_reports_json']) if report_data['daily_reports_json'] else {}
            report_data['generated_report'] = json.loads(report_data['generated_report_json']) if report_data['generated_report_json'] else {}
            report_data['modified_report'] = json.loads(report_data['modified_report_json']) if report_data['modified_report_json'] else None
            
            del report_data['daily_reports_json']
            del report_data['generated_report_json']
            if 'modified_report_json' in report_data:
                del report_data['modified_report_json']

            return report_data
        return {}
    
    def get_all_weekly_reports(self, store_id: int = None) -> List[Dict]:
        """å…¨ã¦ã®é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã€ã¾ãŸã¯æŒ‡å®šã—ãŸåº—èˆ—ã®é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        if store_id:
            reports_rows = conn.execute(
                'SELECT id, store_id, monday_date, timestamp, generated_report_json, modified_report_json '
                'FROM weekly_reports WHERE store_id = ? ORDER BY monday_date DESC', (store_id,)
            ).fetchall()
        else:
            reports_rows = conn.execute(
                'SELECT id, store_id, monday_date, timestamp, generated_report_json, modified_report_json '
                'FROM weekly_reports ORDER BY monday_date DESC'
            ).fetchall()
        conn.close()

        reports = []
        for row in reports_rows:
            report_data = dict(row)
            report_data['store_name'] = self.get_store_name_by_id(report_data['store_id'])
            
            # ç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆã¨ä¿®æ­£ãƒ¬ãƒãƒ¼ãƒˆã®æœ‰ç„¡ã‚’ãƒ•ãƒ©ã‚°ã¨ã—ã¦è¿½åŠ 
            report_data['has_generated'] = report_data['generated_report_json'] is not None
            report_data['has_modified'] = report_data['modified_report_json'] is not None

            # JSONæ–‡å­—åˆ—ã¯ç”Ÿãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ä¿æŒã—ã€å¿…è¦ã«å¿œã˜ã¦ãƒ‘ãƒ¼ã‚¹ã™ã‚‹
            reports.append(report_data)
        return reports

    def find_similar_cases(self, current_data: Dict) -> str:
        """é¡ä¼¼ã‚±ãƒ¼ã‚¹ã‚’æ¤œç´¢ã—ã€LLMã«æ¸¡ã™ãŸã‚ã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        cursor.execute('''
            SELECT daily_reports_json, modified_report_json 
            FROM weekly_reports 
            WHERE modified_report_json IS NOT NULL
            ORDER BY timestamp DESC
            LIMIT 5
        ''') 
        
        results = cursor.fetchall()
        conn.close()
        
        similar_cases_context = []
        for result in results:
            try:
                past_modified_report = json.loads(result[1])
                
                context_item = (
                    f"- éå»ã®é¡ä¼¼ã‚±ãƒ¼ã‚¹ (ä¿®æ­£å¾Œ): {past_modified_report.get('trend', '')[:100]}...\n"
                    f"  è¦å› : {', '.join(past_modified_report.get('factors', []))}\n"
                    f"  (ä¿®æ­£ç†ç”±: {past_modified_report.get('edit_reason', 'ä¸æ˜')[:50]}...)\n"
                )
                similar_cases_context.append(context_item)

            except json.JSONDecodeError:
                continue
        
        if similar_cases_context:
            return "\nã€éå»ã®ä¿®æ­£æ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆä¾‹ã€‘\n" + "\n".join(similar_cases_context)
        return ""
    
    def get_learning_stats(self) -> Dict:
        """å­¦ç¿’ã«é–¢ã™ã‚‹çµ±è¨ˆæƒ…å ±ã‚’å–å¾—ã—ã¾ã™ã€‚"""
        conn = self._get_connection()
        cursor = conn.cursor()
        
        total_reports = cursor.execute("SELECT COUNT(*) FROM weekly_reports").fetchone()[0]
        corrections = cursor.execute("SELECT COUNT(*) FROM weekly_reports WHERE modified_report_json IS NOT NULL").fetchone()[0]
        total_patterns = cursor.execute("SELECT COUNT(*) FROM learning_patterns").fetchone()[0]
        
        conn.close()
        
        return {
            'total_reports': total_reports,
            'corrections': corrections,
            'patterns': total_patterns
        }

class ApparelReportGenerator:
    def __init__(self):
        self.openai_client = None
        self.training_data = None 
        self.memory_db = None 
        self.learning_engine = None
        
    def set_dependencies(self, memory_db_instance, learning_engine_instance):
        """å¤–éƒ¨ã‹ã‚‰ä¾å­˜é–¢ä¿‚ã‚’è¨­å®šã™ã‚‹ãŸã‚ã®ãƒ¡ã‚½ãƒƒãƒ‰"""
        self.memory_db = memory_db_instance
        self.learning_engine = learning_engine_instance

    def initialize_openai(self, api_key: str):
        """OpenAI APIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆã‚’åˆæœŸåŒ–"""
        try:
            # ã“ã“ã‚’openai.OpenAI()ã«ä¿®æ­£ (ãƒãƒ¼ã‚¸ãƒ§ãƒ³1.0ä»¥é™ã®è¨˜æ³•)
            self.openai_client = openai.OpenAI(api_key=api_key) 
            return True
        except Exception as e:
            st.error(f"OpenAI APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
        
    def load_training_data(self, csv_file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ç”¨CSVãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        try:
            self.training_data = pd.read_csv(csv_file_path)
            return True
        except Exception as e:
            st.error(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return False
    
    
    def analyze_trend_factors(self, daily_reports: Dict, topics: str, impact_day: str, quantitative_data: str) -> Dict:
        """æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’åˆ†æã—ã€å‹•å‘ã¨è¦å› ã‚’æŠ½å‡º"""
        
        current_data_for_context = {
            'daily_reports': daily_reports,
            'topics': topics,
            'impact_day': impact_day,
            'quantitative_data': quantitative_data
        }
        enhanced_context = ""
        if self.memory_db and self.learning_engine:
             enhanced_context = self.memory_db.find_similar_cases(current_data_for_context) # find_similar_casesã‚’ä½¿ç”¨
        
        system_prompt = self._build_system_prompt()
        # ä¿®æ­£: _build_user_prompt ã«æ¸¡ã™ daily_reports ã¯ã€ã™ã§ã«é¸æŠã•ã‚ŒãŸã‚¹ãƒˆã‚¢ã®ã¿ã®ãƒ‡ãƒ¼ã‚¿ã«ãªã£ã¦ã„ã‚‹
        user_prompt = self._build_user_prompt(daily_reports, topics, impact_day, quantitative_data, enhanced_context) 
        
        if not self.openai_client:
            st.error("OpenAIã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚APIã‚­ãƒ¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
            return None
        try:
            # ä¿®æ­£: openai.ChatCompletion.create ã‚’ self.openai_client.chat.completions.create ã«å¤‰æ›´
            response = self.openai_client.chat.completions.create( 
                model="gpt-4o-mini", # ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_prompt}
                ],
                temperature=0.3, # ç”Ÿæˆã®å¤šæ§˜æ€§ã‚’èª¿æ•´ (ä½ã‚ã«ã—ã¦å®‰å®šæ€§ã‚’å„ªå…ˆ)
                max_tokens=1000 # æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’èª¿æ•´ (å‡ºåŠ›å½¢å¼ã«åˆã‚ã›ã¦)
            )
            
            result = response.choices[0].message.content
            return self._parse_analysis_result(result)
            
        except openai.APIStatusError as e: # ã“ã“ã¯openaiãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ãƒ¬ãƒ™ãƒ«ã®ã‚¨ãƒ©ãƒ¼ã‚¯ãƒ©ã‚¹ã§OK
            if e.status_code == 401: # èªè¨¼ã‚¨ãƒ©ãƒ¼ (Unauthorized)
                st.error("OpenAI APIã‚­ãƒ¼ãŒç„¡åŠ¹ã§ã™ã€‚è¨­å®šãƒšãƒ¼ã‚¸ã§APIã‚­ãƒ¼ã‚’æ­£ã—ãå…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")
            elif e.status_code == 429: # ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚¨ãƒ©ãƒ¼ (Too Many Requests)
                st.error("OpenAI APIã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è¶…ãˆã¾ã—ãŸã€‚ã—ã°ã‚‰ãå¾…ã£ã¦ã‹ã‚‰å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
            else:
                st.error(f"OpenAI APIã‚¨ãƒ©ãƒ¼: {e.status_code} - {e.response}")
            return None
        except openai.APITimeoutError: # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã‚¨ãƒ©ãƒ¼
            st.error("OpenAI APIã¸ã®ãƒªã‚¯ã‚¨ã‚¹ãƒˆãŒã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆã—ã¾ã—ãŸã€‚ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯æ¥ç¶šã‚’ç¢ºèªã—ã€å†è©¦è¡Œã—ã¦ãã ã•ã„ã€‚")
            return None
        except Exception as e:
            st.error(f"AIåˆ†æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
        
    
    def _build_system_prompt(self) -> str:
        """ã‚·ã‚¹ãƒ†ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        base_prompt = """
        ã‚ãªãŸã¯ã‚¢ãƒ‘ãƒ¬ãƒ«å°å£²æ¥­ç•Œã®å°‚é–€ã‚¢ãƒŠãƒªã‚¹ãƒˆã§ã™ã€‚
        ä¸ãˆã‚‰ã‚ŒãŸæ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã€TOPICSã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ã€å®šé‡ãƒ‡ãƒ¼ã‚¿ã‚’åŸºã«ã€é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

        ã€åˆ†æè¦ä»¶ã€‘
        1.  å‹•å‘ã¨è¦å› ã®å› æœé–¢ä¿‚ã‚’æ˜ç¢ºã«è¨˜è¿°ã™ã‚‹ã“ã¨ã€‚
        2.  ã€Œç›®è«–è¦‹ä»¥ä¸‹ã€ãªã©ã®çµæœè¡¨ç¾ã¯ã€å…·ä½“çš„ãªè¦å› ã¾ã§æ·±æ˜ã‚Šã—ã¦èª¬æ˜ã™ã‚‹ã“ã¨ã€‚
        3.  æä¾›ã•ã‚ŒãŸå®šé‡ãƒ‡ãƒ¼ã‚¿ã¨ã®æ•´åˆæ€§ã‚’ç¢ºèªã—ã€ãƒ¬ãƒãƒ¼ãƒˆã«åæ˜ ã•ã›ã‚‹ã“ã¨ã€‚
        4.  TOPICSã‚„ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ã®äº‹è±¡ãŒé€±å…¨ä½“ã«ä¸ãˆãŸå½±éŸ¿åº¦ã‚’è©•ä¾¡ã—ã€ãƒ¬ãƒãƒ¼ãƒˆã«å«ã‚ã‚‹ã“ã¨ã€‚
        5.  ç°¡æ½”ã§ã€ã‚¢ãƒ‘ãƒ¬ãƒ«åº—èˆ—ã®ä¸Šä½éƒ¨ç½²ãŒç†è§£ã—ã‚„ã™ã„è¡¨ç¾ã‚’ç”¨ã„ã‚‹ã“ã¨ã€‚
        6.  é€±å…¨ä½“ã®å‹•å‘ã¨ã—ã¦ã€**æŒ‡å®šã•ã‚ŒãŸåº—èˆ—ã®æƒ…å ±ã‚’ä¸­å¿ƒã«**åˆ†æã™ã‚‹ã“ã¨ã€‚ï¼ˆä»–ã®åº—èˆ—ã®æƒ…å ±ã¯å‚è€ƒç¨‹åº¦ã«ã¨ã©ã‚ã‚‹ï¼‰

        ã€å‡ºåŠ›å½¢å¼ã€‘
        å¿…ãšä»¥ä¸‹ã®JSONå½¢å¼ã§å‡ºåŠ›ã—ã¦ãã ã•ã„ã€‚
        ```json
        {
            "trend": "é€±å…¨ä½“ã®å‹•å‘ã‚’400å­—ç¨‹åº¦ã§è¨˜è¿°ã€‚å„åº—èˆ—ã®å‹•å‘ã¨è¦å› ã€å®šé‡ãƒ‡ãƒ¼ã‚¿ã€TOPICSã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ã‚’çµ±åˆã—ã€å› æœé–¢ä¿‚ã‚’é‡è¦–ã—ã¦èª¬æ˜ã™ã‚‹ã€‚",
            "factors": [
                "æœ€ã‚‚å½±éŸ¿ã®å¤§ãã‹ã£ãŸè¦å› 1 (30å­—ä»¥å†…)",
                "æ¬¡ã«å½±éŸ¿ã®å¤§ãã‹ã£ãŸè¦å› 2 (30å­—ä»¥å†…)",
                "3ç•ªç›®ã«å½±éŸ¿ã®å¤§ãã‹ã£ãŸè¦å› 3 (30å­—ä»¥å†…)"
            ],
            "questions": [
                "ä¸æ˜ç‚¹ã‚„è¿½åŠ ç¢ºèªãŒå¿…è¦ãªé …ç›®ãŒã‚ã‚Œã°ã€ç°¡æ½”ãªè³ªå•å½¢å¼ã§è¨˜è¿°ã€‚ãªã‘ã‚Œã°ç©ºã®é…åˆ—ã€‚"
            ]
        }
        ```
        - ã€Œtrendã€ã¯400å­—ç¨‹åº¦ã‚’å³å®ˆã™ã‚‹ã“ã¨ã€‚
        - ã€Œfactorsã€ã¯æœ€å¤§3ã¤ã¾ã§ã¨ã—ã€ãã‚Œãã‚Œ30å­—ä»¥å†…ã¨ã™ã‚‹ã“ã¨ã€‚
        - JSONå½¢å¼ä»¥å¤–ã§ã®å‡ºåŠ›ã¯å³ç¦ã§ã™ã€‚
        """
        
        if self.training_data is not None and not self.training_data.empty:
            training_context = self._extract_training_context()
            if training_context:
                base_prompt += f"\n\nã€ç¤¾å†…ç”¨èªãƒ»æ–‡ä½“ãƒ»éå»ã®é¡ä¼¼ä¾‹ã®å‚è€ƒæƒ…å ±ã€‘\n{training_context}"
        
        return base_prompt
    
    def _build_user_prompt(self, daily_reports: Dict, topics: str, impact_day: str, quantitative_data: str, enhanced_context: str) -> str:
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰"""
        prompt = "ä»¥ä¸‹ã®æƒ…å ±ã‹ã‚‰é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONå½¢å¼ã§ä½œæˆã—ã¦ãã ã•ã„ã€‚\n\n"
        
        # ä¿®æ­£: daily_reports ã¯æ—¢ã«å˜ä¸€åº—èˆ—ã®ãƒ‡ãƒ¼ã‚¿ã«ãªã£ã¦ã„ã‚‹ã“ã¨ã‚’æƒ³å®š
        prompt += "ã€æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã€‘\n"
        # daily_reports ã¯ { 'åº—èˆ—å': { 'æ—¥ä»˜': { 'trend': '', 'factors': [] } } } ã®å½¢å¼ã§æ¥ã‚‹ã¨æƒ³å®š
        for store, data in daily_reports.items(): # ã“ã®ãƒ«ãƒ¼ãƒ—ã¯ä¸€åº¦ã—ã‹å›ã‚‰ãªã„ã¯ãš
            prompt += f"- **{store}åº—**:\n"
            for date, report in data.items():
                trend_text = report['trend'] if report['trend'] else "æœªå…¥åŠ›"
                factors_text = ", ".join(report['factors']) if report['factors'] else "ãªã—"
                prompt += f"  - {date}: å‹•å‘={trend_text}, è¦å› ={factors_text}\n"
        
        if topics:
            prompt += f"\nã€TOPICSã€‘\n{topics}\n"
        
        if impact_day:
            prompt += f"\nã€ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆå¤§ã€‘\n{impact_day}\n"
        
        if quantitative_data:
            prompt += f"\nã€å®šé‡ãƒ‡ãƒ¼ã‚¿ã€‘\n{quantitative_data}\n"
        
        if enhanced_context:
            prompt += f"\n{enhanced_context}\n" 
        
        return prompt
    
    def _extract_training_context(self) -> str:
        """å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ç¤¾å†…ç”¨èªãƒ»æ–‡ä½“ã‚’æŠ½å‡º (ç°¡ç•¥åŒ–ã•ã‚ŒãŸä¾‹)"""
        if self.training_data is None or self.training_data.empty:
            return ""
        
        context = []
        
        if 'example_trend' in self.training_data.columns and not self.training_data['example_trend'].empty:
            context.append("éå»ã®ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¿°ä¾‹ (å‹•å‘):")
            for ex in self.training_data['example_trend'].dropna().head(3):
                context.append(f"- {ex[:50]}...")
        
        if 'example_factors' in self.training_data.columns and not self.training_data['example_factors'].empty:
            context.append("éå»ã®ãƒ¬ãƒãƒ¼ãƒˆè¨˜è¿°ä¾‹ (è¦å› ):")
            for ex in self.training_data['example_factors'].dropna().head(3):
                context.append(f"- {ex[:30]}...")
        
        return "\n".join(context)
    
    def _parse_analysis_result(self, result: str) -> Dict:
        """åˆ†æçµæœï¼ˆJSONæ–‡å­—åˆ—ï¼‰ã‚’ãƒ‘ãƒ¼ã‚¹"""
        parsed = {
            'trend': '',
            'factors': [],
            'questions': [],
            'original_result_raw': result # LLMã®ç”Ÿã®å‡ºåŠ›ã‚’ä¿æŒ
        }
        
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', result, re.DOTALL)
        if not json_match:
            try:
                json_data = json.loads(result)
            except json.JSONDecodeError:
                st.error("AIã‹ã‚‰ã®å‡ºåŠ›ãŒæœ‰åŠ¹ãªJSONå½¢å¼ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚é–‹ç™ºè€…å‘ã‘æƒ…å ±: \n" + result)
                return parsed
        else:
            try:
                json_string = json_match.group(1)
                json_data = json.loads(json_string)
            except json.JSONDecodeError:
                st.error("AIã‹ã‚‰ã®JSONå‡ºåŠ›ã®ãƒ‘ãƒ¼ã‚¹ã«å¤±æ•—ã—ã¾ã—ãŸã€‚é–‹ç™ºè€…å‘ã‘æƒ…å ±: \n" + json_string)
                return parsed

        parsed['trend'] = json_data.get('trend', '').strip()
        parsed['factors'] = [f.strip() for f in json_data.get('factors', []) if f.strip()][:3]
        parsed['questions'] = [q.strip() for q in json_data.get('questions', []) if q.strip()]
        
        return parsed

class LearningEngine:
    """å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã‚¯ãƒ©ã‚¹ã€‚ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿®æ­£ã‹ã‚‰å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆãƒ»ç®¡ç†ã—ã¾ã™ã€‚"""
    
    def __init__(self, db_manager: DBManager):
        self.db_manager = db_manager
    
    def learn_from_correction(self, input_data: Dict, original_output: Dict, modified_output: Dict):
        """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¿®æ­£ã‹ã‚‰å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ç”Ÿæˆã—ã€DBã«ä¿å­˜ã—ã¾ã™ã€‚"""
        # å…¥åŠ›ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆã®ãƒãƒƒã‚·ãƒ¥ã‚’ç”Ÿæˆï¼ˆç°¡æ˜“çš„ãªæ–¹æ³•ï¼‰
        input_context_str = json.dumps(input_data, ensure_ascii=False, sort_keys=True)
        input_context_hash = hashlib.sha256(input_context_str.encode('utf-8')).hexdigest()
        
        conn = self.db_manager._get_connection() # DBManagerã‹ã‚‰æ¥ç¶šã‚’å–å¾—
        cursor = conn.cursor()

        original_output_json = json.dumps(original_output, ensure_ascii=False)
        modified_output_json = json.dumps(modified_output, ensure_ascii=False)
        edit_reason = modified_output.get('edit_reason', '')

        cursor.execute('''
            SELECT id, usage_count FROM learning_patterns 
            WHERE input_context_hash = ? AND modified_output_json = ?
        ''', (input_context_hash, modified_output_json))
        
        existing_pattern = cursor.fetchone()

        if existing_pattern:
            pattern_id, usage_count = existing_pattern
            cursor.execute('''
                UPDATE learning_patterns 
                SET usage_count = ?, last_used = ?
                WHERE id = ?
            ''', (usage_count + 1, datetime.now().isoformat(), pattern_id))
            st.info("æ—¢å­˜ã®å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ›´æ–°ã—ã¾ã—ãŸã€‚")
        else:
            cursor.execute('''
                INSERT INTO learning_patterns 
                (input_context_hash, original_output_json, modified_output_json, edit_reason, usage_count, last_used)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                input_context_hash,
                original_output_json,
                modified_output_json,
                edit_reason,
                1,
                datetime.now().isoformat()
            ))
            st.success("æ–°ã—ã„å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä¿å­˜ã—ã¾ã—ãŸï¼AIã®ç²¾åº¦å‘ä¸Šã«å½¹ç«‹ã¡ã¾ã™ã€‚")
        
        conn.commit()
        conn.close()


# --- Streamlit UI Components ---

def get_base64_of_bin_file(bin_file):
    with open(bin_file, 'rb') as f:
        data = f.read()
    return base64.b64encode(data).decode()

def get_file_download_link(df, filename, text):
    """Generates a link for downloading a pandas DataFrame as CSV."""
    csv = df.to_csv(index=False, encoding='utf-8-sig') # UTF-8 BOMä»˜ãã§Excelå¯¾å¿œ
    b64 = base64.b64encode(csv.encode()).decode()
    href = f'<a href="data:file/csv;base64,{b64}" download="{filename}">{text}</a>'
    return href

def get_excel_download_link(df, filename, text):
    """Generates a link for downloading a pandas DataFrame as Excel."""
    output = BytesIO()
    with pd.ExcelWriter(output, engine='xlsxwriter') as writer:
        df.to_excel(writer, index=False, sheet_name='ãƒ¬ãƒãƒ¼ãƒˆ')
    b64 = base64.b64encode(output.getvalue()).decode()
    href = f'<a href="data:application/vnd.openxmlformats-officedocument.spreadsheetml.sheet;base64,{b64}" download="{filename}">{text}</a>'
    return href

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã®åˆæœŸåŒ–
db_manager = DBManager()
report_generator = ApparelReportGenerator()
learning_engine = LearningEngine(db_manager)

# ä¾å­˜é–¢ä¿‚ã‚’è¨­å®š
report_generator.set_dependencies(db_manager, learning_engine)

# â˜…ã“ã“ã‹ã‚‰è¿½åŠ ã™ã‚‹ã‚³ãƒ¼ãƒ‰â˜…
TRAINING_CSV_FILE = "training_data.csv" # ã“ã“ã‚’å®Ÿéš›ã®ãƒ•ã‚¡ã‚¤ãƒ«åã«ç½®ãæ›ãˆã¦ãã ã•ã„ï¼

if Path(TRAINING_CSV_FILE).exists():
    if report_generator.load_training_data(TRAINING_CSV_FILE):
        st.sidebar.success(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TRAINING_CSV_FILE}' ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸã€‚")
    else:
        st.sidebar.warning(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TRAINING_CSV_FILE}' ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚ãƒ•ã‚¡ã‚¤ãƒ«ã®å†…å®¹ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
else:
    st.sidebar.info(f"å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ '{TRAINING_CSV_FILE}' ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚å­¦ç¿’æ©Ÿèƒ½ã¯ç„¡åŠ¹ã«ãªã‚Šã¾ã™ã€‚")
# â˜…ã“ã“ã¾ã§è¿½åŠ ã™ã‚‹ã‚³ãƒ¼ãƒ‰â˜…

def get_monday_of_week(selected_date: date) -> date:
    """ä¸ãˆã‚‰ã‚ŒãŸæ—¥ä»˜ãŒå±ã™ã‚‹é€±ã®æœˆæ›œæ—¥ã‚’è¨ˆç®—ã—ã¾ã™ã€‚"""
    # é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã®æ›œæ—¥ã‚’å–å¾— (æœˆæ›œæ—¥=0, æ—¥æ›œæ—¥=6)
    weekday = selected_date.weekday()
    # æœˆæ›œæ—¥ã«æˆ»ã‚‹ãŸã‚ã®æ—¥æ•°ã‚’è¨ˆç®—
    days_since_monday = weekday
    monday = selected_date - timedelta(days=days_since_monday)
    return monday

def get_current_week_monday() -> date:
    """ç¾åœ¨ã®é€±ã®æœˆæ›œæ—¥ã‚’å–å¾—ã—ã¾ã™ã€‚"""
    today = date.today()
    return get_monday_of_week(today)

# --- Streamlit UI Components ---

def show_report_creation_page():
    st.title("ğŸ“ˆ é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ")
    st.markdown("---")

    st.info("ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€åº—èˆ—ã”ã¨ã®æ—¥æ¬¡ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã€AIãŒé€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã—ã¾ã™ã€‚AIãƒ¬ãƒãƒ¼ãƒˆã¯å¾Œã§ä¿®æ­£ã—ã€ã‚·ã‚¹ãƒ†ãƒ ã«å­¦ç¿’ã•ã›ã‚‹ã“ã¨ãŒã§ãã¾ã™ã€‚")

    # é€±ã®é¸æŠ
    st.header("1. ãƒ¬ãƒãƒ¼ãƒˆå¯¾è±¡é€±ã®é¸æŠ")
    # ä»Šé€±ã®æœˆæ›œæ—¥ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã«ã™ã‚‹
    default_monday = get_current_week_monday()
    selected_date = st.date_input(
        "ãƒ¬ãƒãƒ¼ãƒˆã‚’ä½œæˆã™ã‚‹é€±ã®**æœˆæ›œæ—¥**ã‚’é¸æŠã—ã¦ãã ã•ã„ã€‚",
        value=default_monday,
        min_value=date(2023, 1, 1),
        max_value=date.today() + timedelta(days=30), # æœªæ¥ã®æ—¥ä»˜ã‚‚å°‘ã—è¨±å®¹
        format="YYYY/MM/DD"
    )
    
    # é¸æŠã•ã‚ŒãŸæ—¥ä»˜ãŒæœˆæ›œæ—¥ã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã€ãã†ã§ãªã„å ´åˆã¯æœˆæ›œæ—¥ã«è£œæ­£
    if selected_date.weekday() != 0:
        st.warning(f"é¸æŠã•ã‚ŒãŸæ—¥ä»˜ã¯æœˆæ›œæ—¥ã§ã¯ã‚ã‚Šã¾ã›ã‚“ã€‚è‡ªå‹•çš„ã«**{get_monday_of_week(selected_date).strftime('%Yå¹´%mæœˆ%dæ—¥')}**ã®é€±ã¨ã—ã¦å‡¦ç†ã—ã¾ã™ã€‚")
        monday_of_week = get_monday_of_week(selected_date)
    else:
        monday_of_week = selected_date
    
    st.session_state['selected_monday'] = monday_of_week.strftime('%Y-%m-%d')
    st.subheader(f"é¸æŠé€±: {monday_of_week.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {(monday_of_week + timedelta(days=6)).strftime('%Yå¹´%mæœˆ%dæ—¥')}")
    st.markdown("---")

    # æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã®ãƒ­ãƒ¼ãƒ‰
    store_names = [s[1] for s in db_manager.get_all_stores()]
    if 'selected_store_for_report' not in st.session_state:
        st.session_state['selected_store_for_report'] = store_names[0] # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§æœ€åˆã®åº—èˆ—

    # ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿æ§‹é€ ã®åˆæœŸåŒ–
    if 'daily_reports_input' not in st.session_state:
        st.session_state['daily_reports_input'] = {store_name: {} for store_name in store_names}
    if 'topics_input' not in st.session_state:
        st.session_state['topics_input'] = ""
    if 'impact_day_input' not in st.session_state:
        st.session_state['impact_day_input'] = ""
    if 'quantitative_data_input' not in st.session_state:
        st.session_state['quantitative_data_input'] = ""
    if 'generated_report_output' not in st.session_state:
        st.session_state['generated_report_output'] = None
    if 'modified_report_output' not in st.session_state:
        st.session_state['modified_report_output'] = None
    if 'report_id_to_edit' not in st.session_state:
        st.session_state['report_id_to_edit'] = None

    # é¸æŠã•ã‚ŒãŸé€±ã®æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
    # ã¾ãšã€ã‚¹ãƒˆã‚¢é¸æŠã‚¿ãƒ–ã®ç¾åœ¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿æŒ
    if 'active_tab_index' not in st.session_state:
        st.session_state['active_tab_index'] = 0 # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯æœ€åˆã®ã‚¿ãƒ– (RAY)

    # æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ­ãƒ¼ãƒ‰ã™ã‚‹å‰ã«ã€ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹åº—èˆ—åã‚’å–å¾—
    # åˆæœŸè¡¨ç¤ºæ™‚ã‚„æ—¥ä»˜å¤‰æ›´æ™‚ã«ã€é¸æŠåº—èˆ—ã®ãƒ¬ãƒãƒ¼ãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã‚‹ã‚ˆã†ã«èª¿æ•´
    # ãŸã ã—ã€ã‚¿ãƒ–ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒå¤‰æ›´ã•ã‚ŒãŸå ´åˆã¯ã€ãã®ã‚¿ãƒ–ã®åº—èˆ—åã«è¿½å¾“
    # ã“ã“ã§ã¯ã€`selected_store_for_report` ã¨ `active_tab_index` ã®åŒæœŸã‚’å¼·åŒ–
    
    # ãƒ­ãƒ¼ãƒ‰æ™‚ã«ã€ã‚‚ã—æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆãŒå­˜åœ¨ã™ã‚Œã°ã€ãã®åº—èˆ—ã‚’ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã®ã‚¿ãƒ–ã«ã™ã‚‹ãŸã‚ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®š
    current_store_id_for_load = db_manager.get_store_id_by_name(st.session_state['selected_store_for_report'])
    existing_report = db_manager.get_weekly_report(current_store_id_for_load, st.session_state['selected_monday'])

    if existing_report:
        st.info(f"**{st.session_state['selected_store_for_report']}åº—**ã®ã“ã®é€±ã®ãƒ¬ãƒãƒ¼ãƒˆãŒèª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸã€‚")
        st.session_state['daily_reports_input'][st.session_state['selected_store_for_report']] = existing_report['daily_reports']
        st.session_state['topics_input'] = existing_report['topics']
        st.session_state['impact_day_input'] = existing_report['impact_day']
        st.session_state['quantitative_data_input'] = existing_report['quantitative_data']
        st.session_state['generated_report_output'] = existing_report['generated_report']
        st.session_state['modified_report_output'] = existing_report['modified_report']
        st.session_state['report_id_to_edit'] = existing_report['id']
        # æ—¢å­˜ãƒ¬ãƒãƒ¼ãƒˆã®åº—èˆ—ã«åˆã‚ã›ã¦ã‚¿ãƒ–ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹
        if st.session_state['selected_store_for_report'] in store_names:
            st.session_state['active_tab_index'] = store_names.index(st.session_state['selected_store_for_report'])
    else:
        # æ–°è¦ä½œæˆã®å ´åˆã€æ—¢å­˜ã®å…¥åŠ›ã¯ã‚¯ãƒªã‚¢ã—ãªã„ï¼ˆæ—¥ä»˜åˆ‡ã‚Šæ›¿ãˆæ™‚ã®ãƒ‡ãƒ¼ã‚¿æ®‹å­˜ã‚’é˜²ããŸã‚ï¼‰
        # ãŸã ã—ã€é¸æŠé€±ã‚’å¤‰æ›´ã—ãŸå ´åˆã¯å„å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã®å€¤ã‚’ãƒªã‚»ãƒƒãƒˆ
        if 'last_selected_monday' not in st.session_state or st.session_state['last_selected_monday'] != st.session_state['selected_monday']:
            # å…¨åº—èˆ—ã®daily_reports_inputã‚’åˆæœŸåŒ–
            for store_name in store_names:
                st.session_state['daily_reports_input'][store_name] = {
                    (monday_of_week + timedelta(days=i)).strftime('%Y-%m-%d'): {"trend": "", "factors": []} for i in range(7)
                }
            st.session_state['topics_input'] = ""
            st.session_state['impact_day_input'] = ""
            st.session_state['quantitative_data_input'] = ""
            st.session_state['generated_report_output'] = None
            st.session_state['modified_report_output'] = None
            st.session_state['report_id_to_edit'] = None
        st.session_state['last_selected_monday'] = st.session_state['selected_monday']

    st.header("2. æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ã®å…¥åŠ›")
    st.markdown("å„åº—èˆ—ã®**æ—¥ã”ã¨ã®å‹•å‘ã¨è¦å› **ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚è¦å› ã¯è¤‡æ•°å…¥åŠ›å¯èƒ½ã§ã™ï¼ˆã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰ã€‚")
    
    # åº—èˆ—ã”ã¨ã®ã‚¿ãƒ–è¡¨ç¤ºï¼ˆè‰²ãŒå¤‰ã‚ã‚‹ã‚ˆã†ã«ä¿®æ­£ï¼‰
    # `st.tabs` ã®æˆ»ã‚Šå€¤ã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜ã—ã€ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ã‚¿ãƒ–ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã¨ã—ã¦åˆ©ç”¨
    # TypeError: LayoutsMixin.tabs() got an unexpected keyword argument 'key' ã‚¨ãƒ©ãƒ¼å¯¾å¿œ: keyã‚’å‰Šé™¤
    tabs = st.tabs(
        store_names
    )

    # ç¾åœ¨é¸æŠã•ã‚Œã¦ã„ã‚‹ã‚¿ãƒ–ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ (st.tabs() ã¯æœ€å¾Œã«é¸æŠã•ã‚ŒãŸã‚¿ãƒ–ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿”ã™)
    # ã“ã‚Œã‚’ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã«ä¿å­˜ã™ã‚‹ã“ã¨ã§ã€UIã¨å†…éƒ¨çŠ¶æ…‹ã‚’åŒæœŸã•ã›ã‚‹
    # Streamlitã®å‹•ä½œã§ã¯ã€ã‚¿ãƒ–ãŒã‚¯ãƒªãƒƒã‚¯ã•ã‚Œã‚‹ã¨ã€æ¬¡ã«ã‚¹ã‚¯ãƒªãƒ—ãƒˆãŒå†å®Ÿè¡Œã•ã‚Œã‚‹ã¨ãã«
    # st.tabs() ãŒãã®æ–°ã—ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¿”ã™
    
    # ã“ã“ã§ `tabs` å¤‰æ•° (st.tabs() ã®æˆ»ã‚Šå€¤ã§ã‚ã‚‹ã‚¿ãƒ–ã‚ªãƒ–ã‚¸ã‚§ã‚¯ãƒˆã®ãƒªã‚¹ãƒˆ) ã‚’ä½¿ç”¨ã—ã¦ã€
    # å„ã‚¿ãƒ–ã®ã‚³ãƒ³ãƒ†ãƒ³ãƒ„ã‚’è¡¨ç¤ºã™ã‚‹
    for i, tab in enumerate(tabs):
        with tab:
            current_store_name_for_input = store_names[i] # ã“ã®ã‚¿ãƒ–ã«å¯¾å¿œã™ã‚‹åº—èˆ—å
            st.session_state['selected_store_for_report'] = current_store_name_for_input # ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®é¸æŠåº—èˆ—åã‚’æ›´æ–°

            # ã“ã®ã‚¿ãƒ–ãŒé¸æŠã•ã‚Œã¦ã„ã‚‹å ´åˆã«ã®ã¿ã€ãã®åº—èˆ—ã®å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã‚’è¡¨ç¤º
            # st.tabs() ã®æŒ™å‹•ã«ã‚ˆã‚Šã€with tab: ã®ãƒ–ãƒ­ãƒƒã‚¯ã«å…¥ã£ãŸæ™‚ç‚¹ã§ã€ãã®ã‚¿ãƒ–ãŒã‚¢ã‚¯ãƒ†ã‚£ãƒ–ã«ãªã£ã¦ã„ã‚‹
            # ãªã®ã§ã€è¿½åŠ ã® if st.session_state['active_tab_index'] == i: ã¯ä¸è¦
            
            # ã¾ãšã€ç¾åœ¨ã®åº—èˆ—ã®daily_reports_inputã‚’ç¢ºå®Ÿã«åˆæœŸåŒ–
            if current_store_name_for_input not in st.session_state['daily_reports_input']:
                st.session_state['daily_reports_input'][current_store_name_for_input] = {
                    (monday_of_week + timedelta(days=j)).strftime('%Y-%m-%d'): {"trend": "", "factors": []} for j in range(7)
                }

            # é¸æŠã•ã‚ŒãŸåº—èˆ—ã®æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆå…¥åŠ›æ¬„ã‚’è¡¨ç¤º
            for j in range(7): # æœˆæ›œæ—¥ã‹ã‚‰æ—¥æ›œæ—¥ã¾ã§
                current_date = monday_of_week + timedelta(days=j)
                date_str = current_date.strftime('%Y-%m-%d')
                day_name = ["æœˆ", "ç«", "æ°´", "æœ¨", "é‡‘", "åœŸ", "æ—¥"][j]

                st.subheader(f"ğŸ—“ï¸ {current_date.strftime('%Yå¹´%mæœˆ%dæ—¥')} ({day_name})")
                
                # æ—¥æ¬¡å‹•å‘
                st.session_state['daily_reports_input'][current_store_name_for_input][date_str]['trend'] = st.text_area(
                    f"{day_name}æ›œæ—¥ã®å‹•å‘ï¼ˆ{current_store_name_for_input}åº—ï¼‰",
                    value=st.session_state['daily_reports_input'][current_store_name_for_input].get(date_str, {}).get('trend', ''),
                    height=100,
                    key=f"trend_{current_store_name_for_input}_{date_str}"
                )
                
                # æ—¥æ¬¡è¦å› 
                # ãƒªã‚¹ãƒˆã‚’ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šæ–‡å­—åˆ—ã«å¤‰æ›ã—ã¦è¡¨ç¤º
                factors_str = ", ".join(st.session_state['daily_reports_input'][current_store_name_for_input].get(date_str, {}).get('factors', []))
                edited_factors_str = st.text_input(
                    f"{day_name}æ›œæ—¥ã®è¦å› ï¼ˆè¤‡æ•°ã‚ã‚‹å ´åˆã¯ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šã€{current_store_name_for_input}åº—ï¼‰",
                    value=factors_str,
                    key=f"factors_{current_store_name_for_input}_{date_str}"
                )
                # ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒå…¥åŠ›ã—ãŸæ–‡å­—åˆ—ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›ã—ã¦ä¿å­˜
                st.session_state['daily_reports_input'][current_store_name_for_input][date_str]['factors'] = [f.strip() for f in edited_factors_str.split(',') if f.strip()]
                st.markdown("---")

    st.header("3. é€±å…¨ä½“ã®è£œè¶³æƒ…å ±ã®å…¥åŠ›")
    st.markdown("é€±å…¨ä½“ã«ã‚ãŸã‚‹é‡è¦ãªãƒˆãƒ”ãƒƒã‚¯ã‚¹ã€ç‰¹ã«å½±éŸ¿ã®å¤§ãã‹ã£ãŸæ—¥ã€ãŠã‚ˆã³å®šé‡ãƒ‡ãƒ¼ã‚¿ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚")

    st.text_area(
    "ä»Šæ—¥ã®ãƒˆãƒ”ãƒƒã‚¯ï¼ˆä¾‹: å£²ä¸Šå‘ä¸Šç­–ã€é¡§å®¢æº€è¶³åº¦å‘ä¸Šã€æ–°å•†å“é–‹ç™ºï¼‰",
    height=100, # 68pxä»¥ä¸Šã§ã‚ã‚Œã°OK
    key='topics_input',
    value=st.session_state.get('topics_input', '') # ã“ã® value ã¯åˆå›è¡¨ç¤ºæ™‚ã®åˆæœŸå€¤ã¨ã—ã¦æ©Ÿèƒ½
    )
    st.text_area(
    "ç¿Œæ—¥ä»¥é™ã®ã‚¤ãƒ³ãƒ‘ã‚¯ãƒˆï¼ˆç¿Œæ—¥ä»¥é™ã«å½±éŸ¿ã™ã‚‹è¦å› ã‚’å…·ä½“çš„ã«è¨˜å…¥ï¼‰",
    height=100, # ã“ã“ã¯68pxä»¥ä¸Šã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„
    key='impact_day_input',
    value=st.session_state.get('impact_day_input', '')
    )
    st.text_area(
    "å®šé‡ãƒ‡ãƒ¼ã‚¿ï¼ˆä¾‹: å£²ä¸Šé«˜ã€å®¢æ•°ã€å®¢å˜ä¾¡ã€ãƒ­ã‚¹ç‡ãªã©å…·ä½“çš„ãªæ•°å€¤ï¼‰",
    height=100, # ã“ã“ã¯68pxä»¥ä¸Šã§ã‚ã‚‹ã“ã¨ã‚’ç¢ºèªã—ã¦ãã ã•ã„
    key='quantitative_data_input',
    value=st.session_state.get('quantitative_data_input', '')
    )
    st.markdown("---")

    st.header("4. é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆ")
    if st.button("AIã«é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã•ã›ã‚‹", type="primary"):
        with st.spinner("AIãŒãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆä¸­ã§ã™...ã—ã°ã‚‰ããŠå¾…ã¡ãã ã•ã„ã€‚"):
            # é¸æŠä¸­ã®åº—èˆ—ã®æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®ã¿ã‚’æŠ½å‡º
            selected_store_daily_report = {
                st.session_state['selected_store_for_report']: st.session_state['daily_reports_input'][st.session_state['selected_store_for_report']]
            }

            generated_report = report_generator.analyze_trend_factors(
                daily_reports=selected_store_daily_report, # é¸æŠã•ã‚ŒãŸåº—èˆ—ã®æ—¥æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®ã¿ã‚’æ¸¡ã™
                topics=st.session_state['topics_input'],
                impact_day=st.session_state['impact_day_input'],
                quantitative_data=st.session_state['quantitative_data_input']
            )

            if generated_report:
                st.session_state['generated_report_output'] = generated_report
                st.session_state['modified_report_output'] = None # æ–°è¦ç”Ÿæˆæ™‚ã¯ä¿®æ­£ç‰ˆã‚’ãƒªã‚»ãƒƒãƒˆ
                st.success("ãƒ¬ãƒãƒ¼ãƒˆãŒç”Ÿæˆã•ã‚Œã¾ã—ãŸï¼å†…å®¹ã‚’ç¢ºèªã—ã€å¿…è¦ã«å¿œã˜ã¦ä¿®æ­£ã—ã¦ãã ã•ã„ã€‚")
            else:
                st.error("ãƒ¬ãƒãƒ¼ãƒˆã®ç”Ÿæˆã«å¤±æ•—ã—ã¾ã—ãŸã€‚å…¥åŠ›å†…å®¹ã‚’ç¢ºèªã™ã‚‹ã‹ã€å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚")
    
    if st.session_state['generated_report_output']:
        st.subheader("ğŸ“ ç”Ÿæˆã•ã‚ŒãŸé€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆ (AIç”Ÿæˆ)")
        
        # AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆã®è¡¨ç¤º
        trend_ai = st.session_state['generated_report_output'].get('trend', '')
        factors_ai = st.session_state['generated_report_output'].get('factors', [])
        questions_ai = st.session_state['generated_report_output'].get('questions', [])

        st.text_area("å‹•å‘", value=trend_ai, height=200, disabled=True, key="ai_trend")
        st.text_area("è¦å› ", value="\n".join(factors_ai), height=80, disabled=True, key="ai_factors")
        st.text_area("è³ªå•äº‹é …", value="\n".join(questions_ai) if questions_ai else "ãªã—", height=80, disabled=True, key="ai_questions")
        
        st.markdown("---")
        st.header("5. ç”Ÿæˆã•ã‚ŒãŸãƒ¬ãƒãƒ¼ãƒˆã®ä¿®æ­£ã¨ä¿å­˜ (ä»»æ„)")
        st.warning("AIãŒç”Ÿæˆã—ãŸãƒ¬ãƒãƒ¼ãƒˆã¯ã€å¿…è¦ã«å¿œã˜ã¦ä¿®æ­£ã—ã€å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã¨ã—ã¦ã‚·ã‚¹ãƒ†ãƒ ã«ä¿å­˜ã§ãã¾ã™ã€‚")

        # ä¿®æ­£ãƒ•ã‚©ãƒ¼ãƒ 
        with st.form("modify_report_form"):
            modified_trend = st.text_area("å‹•å‘ (ä¿®æ­£)", value=st.session_state['modified_report_output'].get('trend', trend_ai) if st.session_state['modified_report_output'] else trend_ai, height=200)
            modified_factors_str = st.text_area("è¦å›  (ä¿®æ­£ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)", value=", ".join(st.session_state['modified_report_output'].get('factors', factors_ai)) if st.session_state['modified_report_output'] else ", ".join(factors_ai), height=80)
            modified_questions_str = st.text_area("è³ªå•äº‹é … (ä¿®æ­£ã€ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Š)", value=", ".join(st.session_state['modified_report_output'].get('questions', questions_ai)) if st.session_state['modified_report_output'] else ", ".join(questions_ai), height=80)
            edit_reason = st.text_area("ä¿®æ­£ç†ç”±ï¼ˆAIã®å­¦ç¿’ã«åˆ©ç”¨ã•ã‚Œã¾ã™ï¼‰", value=st.session_state['modified_report_output'].get('edit_reason', '') if st.session_state['modified_report_output'] else '', height=100)

            submitted = st.form_submit_button("ä¿®æ­£å†…å®¹ã‚’ä¿å­˜ã—ã€AIã«å­¦ç¿’ã•ã›ã‚‹")
            if submitted:
                # ä¿®æ­£å¾Œã®è¦å› ã¨è³ªå•äº‹é …ã‚’ãƒªã‚¹ãƒˆã«å¤‰æ›
                modified_factors = [f.strip() for f in modified_factors_str.split(',') if f.strip()]
                modified_questions = [q.strip() for q in modified_questions_str.split(',') if q.strip()]

                modified_report = {
                    "trend": modified_trend,
                    "factors": modified_factors,
                    "questions": modified_questions,
                    "edit_reason": edit_reason
                }
                st.session_state['modified_report_output'] = modified_report

                # ãƒ¬ãƒãƒ¼ãƒˆã‚’DBã«ä¿å­˜
                store_id = db_manager.get_store_id_by_name(st.session_state['selected_store_for_report'])
                input_data_for_learning = {
                    'daily_reports': {st.session_state['selected_store_for_report']: st.session_state['daily_reports_input'][st.session_state['selected_store_for_report']]},
                    'topics': st.session_state['topics_input'],
                    'impact_day': st.session_state['impact_day_input'],
                    'quantitative_data': st.session_state['quantitative_data_input']
                }
                
                db_manager.save_weekly_data(
                    store_id=store_id,
                    monday_date_str=st.session_state['selected_monday'],
                    data={
                        'daily_reports': st.session_state['daily_reports_input'][st.session_state['selected_store_for_report']],
                        'topics': st.session_state['topics_input'],
                        'impact_day': st.session_state['impact_day_input'],
                        'quantitative_data': st.session_state['quantitative_data_input']
                    },
                    original_report=st.session_state['generated_report_output'],
                    modified_report=modified_report
                )
                
                # å­¦ç¿’ã‚¨ãƒ³ã‚¸ãƒ³ã«ä¿®æ­£å†…å®¹ã‚’æ¸¡ã™
                learning_engine.learn_from_correction(
                    input_data=input_data_for_learning,
                    original_output=st.session_state['generated_report_output'],
                    modified_output=modified_report
                )
                st.success("ä¿®æ­£å†…å®¹ãŒä¿å­˜ã•ã‚Œã€AIã®å­¦ç¿’ã«åˆ©ç”¨ã•ã‚Œã¾ã—ãŸï¼")
                st.experimental_rerun() # ä¿å­˜å¾Œã«UIã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥

        st.markdown("---")
        st.header("6. ãƒ¬ãƒãƒ¼ãƒˆã®ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
        
        # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆã®é¸æŠ
        export_option = st.radio(
            "ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆã‚’é¸æŠã—ã¦ãã ã•ã„:",
            ("AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ", "ä¿®æ­£æ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆ (å­˜åœ¨ã™ã‚‹å ´åˆ)"),
            index=1 if st.session_state['modified_report_output'] else 0
        )

        report_to_export = {}
        if export_option == "ä¿®æ­£æ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆ (å­˜åœ¨ã™ã‚‹å ´åˆ)" and st.session_state['modified_report_output']:
            report_to_export = st.session_state['modified_report_output']
            report_type_label = "ä¿®æ­£æ¸ˆã¿"
        else:
            report_to_export = st.session_state['generated_report_output']
            report_type_label = "AIç”Ÿæˆ"

        if report_to_export:
            # ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼è¡¨ç¤º
            st.subheader(f"ğŸ“„ {report_type_label}ãƒ¬ãƒãƒ¼ãƒˆ ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼")
            st.write("**å‹•å‘:**")
            st.markdown(report_to_export.get('trend', ''))
            st.write("**è¦å› :**")
            for factor in report_to_export.get('factors', []):
                st.markdown(f"- {factor}")
            st.write("**è³ªå•äº‹é …:**")
            if report_to_export.get('questions'):
                for question in report_to_export.get('questions', []):
                    st.markdown(f"- {question}")
            else:
                st.markdown("ãªã—")
            
            # ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ãƒœã‚¿ãƒ³
            report_text_content = f"é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆ{report_type_label}ï¼‰\n\n" \
                                  f"å¯¾è±¡åº—èˆ—: {st.session_state['selected_store_for_report']}åº—\n" \
                                  f"å¯¾è±¡é€±: {monday_of_week.strftime('%Yå¹´%mæœˆ%dæ—¥')} ã€œ {(monday_of_week + timedelta(days=6)).strftime('%Yå¹´%m%dæ—¥')}\n\n" \
                                  f"â–  å‹•å‘:\n{report_to_export.get('trend', '')}\n\n" \
                                  f"â–  è¦å› :\n" + "\n".join([f"- {f}" for f in report_to_export.get('factors', [])]) + "\n\n" \
                                  f"â–  è³ªå•äº‹é …:\n" + ("\n".join([f"- {q}" for q in report_to_export.get('questions', [])]) if report_to_export.get('questions') else "ãªã—")
            
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            st.download_button(
                label=f"ğŸ“ {report_type_label}ãƒ¬ãƒãƒ¼ãƒˆã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=report_text_content.encode('utf-8'),
                file_name=f"{st.session_state['selected_store_for_report']}_{monday_of_week.strftime('%Y%m%d')}_weekly_report_{report_type_label}.txt",
                mime="text/plain"
            )

            # JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
            report_json_content = json.dumps(report_to_export, ensure_ascii=False, indent=2)
            st.download_button(
                label=f"ğŸ“Š {report_type_label}ãƒ¬ãƒãƒ¼ãƒˆã‚’JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                data=report_json_content.encode('utf-8'),
                file_name=f"{st.session_state['selected_store_for_report']}_{monday_of_week.strftime('%Y%m%d')}_weekly_report_{report_type_label}.json",
                mime="application/json"
            )
        else:
            st.info("ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆå¯èƒ½ãªãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")

def show_report_history_page():
    st.title("ğŸ“š ãƒ¬ãƒãƒ¼ãƒˆå±¥æ­´")
    st.markdown("---")

    st.info("ã“ã‚Œã¾ã§ã«ç”Ÿæˆãƒ»ä¿å­˜ã•ã‚ŒãŸé€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã®ä¸€è¦§ã‚’ç¢ºèªã§ãã¾ã™ã€‚")

    stores = db_manager.get_all_stores()
    store_names = ["å…¨ã¦ã®åº—èˆ—"] + [s[1] for s in stores]
    
    selected_store_name = st.selectbox(
        "è¡¨ç¤ºã™ã‚‹åº—èˆ—ã‚’é¸æŠã—ã¦ãã ã•ã„:",
        store_names,
        key="history_store_select"
    )

    if selected_store_name == "å…¨ã¦ã®åº—èˆ—":
        store_id_filter = None
    else:
        store_id_filter = db_manager.get_store_id_by_name(selected_store_name)
    
    all_reports = db_manager.get_all_weekly_reports(store_id=store_id_filter)

    if not all_reports:
        st.warning("è¡¨ç¤ºã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return

    # ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ¬ãƒ¼ãƒ è¡¨ç¤º
    df_data = []
    for report in all_reports:
        df_data.append({
            "ID": report['id'],
            "åº—èˆ—å": report['store_name'],
            "é€±ã®é–‹å§‹æ—¥": report['monday_date'],
            "AIç”Ÿæˆ": "âœ…" if report['has_generated'] else "âŒ",
            "ä¿®æ­£æ¸ˆã¿": "âœ…" if report['has_modified'] else "âŒ",
            "æœ€çµ‚æ›´æ–°æ—¥æ™‚": datetime.fromisoformat(report['timestamp']).strftime('%Y/%m/%d %H:%M:%S')
        })
    
    df = pd.DataFrame(df_data)
    
    st.dataframe(df, use_container_width=True, hide_row_index=True)

    st.markdown("---")
    st.subheader("ãƒ¬ãƒãƒ¼ãƒˆã®è©³ç´°è¡¨ç¤ºã¨ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ")
    
    report_ids = [str(r['id']) for r in all_reports]
    selected_report_id = st.selectbox("è©³ç´°ã‚’è¡¨ç¤ºãƒ»ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆã®IDã‚’é¸æŠã—ã¦ãã ã•ã„:", report_ids)

    if selected_report_id:
        selected_report_data = next((r for r in all_reports if str(r['id']) == selected_report_id), None)
        if selected_report_data:
            st.write(f"### ID: {selected_report_data['id']} ã®ãƒ¬ãƒãƒ¼ãƒˆè©³ç´°")
            
            # JSONæ–‡å­—åˆ—ã‚’ãƒ­ãƒ¼ãƒ‰ã—ã¦è¡¨ç¤º
            generated_report_content = json.loads(selected_report_data['generated_report_json']) if selected_report_data['generated_report_json'] else None
            modified_report_content = json.loads(selected_report_data['modified_report_json']) if selected_report_data['modified_report_json'] else None
            
            # ã‚¿ãƒ–ã§è¡¨ç¤º
            report_tabs = []
            if generated_report_content:
                report_tabs.append("AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ")
            if modified_report_content:
                report_tabs.append("ä¿®æ­£æ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆ")
            
            if not report_tabs:
                st.warning("ã“ã®ãƒ¬ãƒãƒ¼ãƒˆã«ã¯ã€AIç”Ÿæˆã¾ãŸã¯ä¿®æ­£æ¸ˆã¿ã®ãƒ¬ãƒãƒ¼ãƒˆãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
                return

            selected_report_tab = st.radio("è¡¨ç¤ºã™ã‚‹ãƒ¬ãƒãƒ¼ãƒˆã‚¿ã‚¤ãƒ—:", report_tabs)

            displayed_report = {}
            report_label = ""

            if selected_report_tab == "AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ" and generated_report_content:
                displayed_report = generated_report_content
                report_label = "AIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆ"
            elif selected_report_tab == "ä¿®æ­£æ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆ" and modified_report_content:
                displayed_report = modified_report_content
                report_label = "ä¿®æ­£æ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆ"
            
            if displayed_report:
                st.write(f"#### {report_label}")
                st.write("**å‹•å‘:**")
                st.markdown(displayed_report.get('trend', ''))
                st.write("**è¦å› :**")
                for factor in displayed_report.get('factors', []):
                    st.markdown(f"- {factor}")
                st.write("**è³ªå•äº‹é …:**")
                if displayed_report.get('questions'):
                    for question in displayed_report.get('questions', []):
                        st.markdown(f"- {question}")
                else:
                    st.markdown("ãªã—")

                if 'edit_reason' in displayed_report and displayed_report['edit_reason']:
                    st.write("**ä¿®æ­£ç†ç”±:**")
                    st.markdown(displayed_report['edit_reason'])

                # ã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆãƒœã‚¿ãƒ³
                report_text_content = f"é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆï¼ˆ{report_label}ï¼‰\n\n" \
                                      f"å¯¾è±¡åº—èˆ—: {selected_report_data['store_name']}åº—\n" \
                                      f"å¯¾è±¡é€±: {selected_report_data['monday_date']} ã€œ {(datetime.strptime(selected_report_data['monday_date'], '%Y-%m-%d').date() + timedelta(days=6)).strftime('%Y%m%d')}\n\n" \
                                      f"â–  å‹•å‘:\n{displayed_report.get('trend', '')}\n\n" \
                                      f"â–  è¦å› :\n" + "\n".join([f"- {f}" for f in displayed_report.get('factors', [])]) + "\n\n" \
                                      f"â–  è³ªå•äº‹é …:\n" + ("\n".join([f"- {q}" for q in displayed_report.get('questions', [])]) if displayed_report.get('questions') else "ãªã—")
                
                # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                st.download_button(
                    label=f"ğŸ“ {report_label}ã‚’ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=report_text_content.encode('utf-8'),
                    file_name=f"{selected_report_data['store_name']}_{selected_report_data['monday_date']}_weekly_report_{report_label}.txt",
                    mime="text/plain",
                    key=f"download_txt_{selected_report_id}_{report_label}"
                )

                # JSONãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
                report_json_content = json.dumps(displayed_report, ensure_ascii=False, indent=2)
                st.download_button(
                    label=f"ğŸ“Š {report_label}ã‚’JSONã§ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰",
                    data=report_json_content.encode('utf-8'),
                    file_name=f"{selected_report_data['store_name']}_{selected_report_data['monday_date']}_weekly_report_{report_label}.json",
                    mime="application/json",
                    key=f"download_json_{selected_report_id}_{report_label}"
                )

def show_learning_status_page():
    st.title("ğŸ§  AIå­¦ç¿’çŠ¶æ³")
    st.markdown("---")

    st.info("ã“ã®ãƒšãƒ¼ã‚¸ã§ã¯ã€AIã®å­¦ç¿’ã«é–¢ã™ã‚‹ç¾åœ¨ã®çµ±è¨ˆæƒ…å ±ã‚’ç¢ºèªã§ãã¾ã™ã€‚")

    stats = db_manager.get_learning_stats()

    col1, col2, col3 = st.columns(3)

    with col1:
        st.metric(label="åˆè¨ˆãƒ¬ãƒãƒ¼ãƒˆæ•°", value=stats['total_reports'])
    with col2:
        st.metric(label="ä¿®æ­£æ¸ˆã¿ãƒ¬ãƒãƒ¼ãƒˆæ•° (å­¦ç¿’æ¸ˆã¿)", value=stats['corrections'])
    with col3:
        st.metric(label="å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³æ•°", value=stats['patterns'])
    
    st.markdown("---")
    st.subheader("å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°")
    st.info("å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ã€ãƒ¦ãƒ¼ã‚¶ãƒ¼ãŒAIç”Ÿæˆãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿®æ­£ã—ãŸéš›ã«ã‚·ã‚¹ãƒ†ãƒ ãŒè‡ªå‹•çš„ã«è¨˜éŒ²ã—ãŸã‚‚ã®ã§ã™ã€‚ã“ã‚Œã«ã‚ˆã‚Šã€AIã¯ã‚ˆã‚Šé©åˆ‡ãªãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆã™ã‚‹ã‚ˆã†å­¦ç¿’ã—ã¾ã™ã€‚")
    
    conn = db_manager._get_connection()
    learning_patterns_df = pd.read_sql_query("SELECT * FROM learning_patterns ORDER BY last_used DESC", conn)
    conn.close()

    if not learning_patterns_df.empty:
        # JSONæ–‡å­—åˆ—ã‚’å±•é–‹ã—ã¦è¡¨ç¤º
        display_df = learning_patterns_df.copy()
        
        display_df['å…ƒã®å‡ºåŠ› (æŠœç²‹)'] = display_df['original_output_json'].apply(lambda x: json.loads(x).get('trend', '')[:50] + '...' if x else '')
        display_df['ä¿®æ­£å¾Œã®å‡ºåŠ› (æŠœç²‹)'] = display_df['modified_output_json'].apply(lambda x: json.loads(x).get('trend', '')[:50] + '...' if x else '')
        
        st.dataframe(
            display_df[['id', 'usage_count', 'last_used', 'edit_reason', 'å…ƒã®å‡ºåŠ› (æŠœç²‹)', 'ä¿®æ­£å¾Œã®å‡ºåŠ› (æŠœç²‹)']],
            use_container_width=True,
            hide_row_index=True
        )

        st.markdown("---")
        st.subheader("å€‹åˆ¥ã®å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ã®è©³ç´°")
        pattern_ids = [""] + [str(pid) for pid in learning_patterns_df['id'].tolist()]
        selected_pattern_id = st.selectbox("è©³ç´°ã‚’è¡¨ç¤ºã™ã‚‹å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³IDã‚’é¸æŠ:", pattern_ids)

        if selected_pattern_id:
            selected_pattern = learning_patterns_df[learning_patterns_df['id'] == int(selected_pattern_id)].iloc[0]
            
            st.write(f"#### ãƒ‘ã‚¿ãƒ¼ãƒ³ID: {selected_pattern['id']}")
            st.write(f"**åˆ©ç”¨å›æ•°:** {selected_pattern['usage_count']}")
            st.write(f"**æœ€çµ‚åˆ©ç”¨æ—¥æ™‚:** {selected_pattern['last_used']}")
            st.write(f"**ä¿®æ­£ç†ç”±:** {selected_pattern['edit_reason']}")
            
            st.markdown("---")
            st.write("##### å…ƒã®AIç”Ÿæˆå‡ºåŠ›")
            st.json(json.loads(selected_pattern['original_output_json']))
            
            st.markdown("---")
            st.write("##### ä¿®æ­£å¾Œã®å‡ºåŠ›")
            st.json(json.loads(selected_pattern['modified_output_json']))

    else:
        st.info("ã¾ã å­¦ç¿’ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒä¿å­˜ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ¬ãƒãƒ¼ãƒˆã‚’ä¿®æ­£ã—ã¦ä¿å­˜ã™ã‚‹ã¨ã€ã“ã“ã«ãƒ‘ã‚¿ãƒ¼ãƒ³ãŒè¿½åŠ ã•ã‚Œã¾ã™ã€‚")

def show_settings_page():
    st.title("âš™ï¸ è¨­å®š")
    st.markdown("---")

    st.info("Streamlitã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å‹•ä½œã«å¿…è¦ãªè¨­å®šã‚’è¡Œã„ã¾ã™ã€‚ç‰¹ã«OpenAI APIã‚­ãƒ¼ã¯å¿…é ˆã§ã™ã€‚")

    st.subheader("OpenAI APIã‚­ãƒ¼è¨­å®š")
    openai_api_key = st.text_input(
        "OpenAI API Key (sk-ã‹ã‚‰å§‹ã¾ã‚‹ã‚­ãƒ¼)",
        type="password",
        value=st.session_state.get("openai_api_key", os.getenv("OPENAI_API_KEY", "")), # .envã‹ã‚‰ã‚‚èª­ã¿è¾¼ã‚€
        help="OpenAIã®APIã‚­ãƒ¼ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ã€‚ã“ã‚Œã«ã‚ˆã‚ŠAIãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ©Ÿèƒ½ãŒåˆ©ç”¨å¯èƒ½ã«ãªã‚Šã¾ã™ã€‚"
    )

    if st.button("APIã‚­ãƒ¼ã‚’ä¿å­˜"):
        if openai_api_key:
            st.session_state["openai_api_key"] = openai_api_key
            # ç’°å¢ƒå¤‰æ•°ã«è¨­å®š (ç¾åœ¨ã®ã‚»ãƒƒã‚·ãƒ§ãƒ³ã®ã¿)
            os.environ["OPENAI_API_KEY"] = openai_api_key
            
            # ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå™¨ã«ã‚­ãƒ¼ã‚’è¨­å®š
            if report_generator.initialize_openai(openai_api_key):
                st.success("OpenAI APIã‚­ãƒ¼ãŒæ­£å¸¸ã«è¨­å®šã•ã‚Œã¾ã—ãŸã€‚")
            else:
                st.error("OpenAI APIã‚­ãƒ¼ã®è¨­å®šã«å¤±æ•—ã—ã¾ã—ãŸã€‚ã‚­ãƒ¼ãŒæ­£ã—ã„ã‹ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        else:
            st.error("APIã‚­ãƒ¼ãŒå…¥åŠ›ã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚")
    
    if "openai_api_key" in st.session_state and st.session_state["openai_api_key"]:
        st.success("APIã‚­ãƒ¼ãŒè¨­å®šæ¸ˆã¿ã§ã™ã€‚")
    elif os.getenv("OPENAI_API_KEY"):
        st.success("APIã‚­ãƒ¼ãŒç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šæ¸ˆã¿ã§ã™ã€‚")
        # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰è¨­å®šã•ã‚Œã¦ã„ã‚‹å ´åˆã¯ã€ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆå™¨ã‚‚åˆæœŸåŒ–ã—ã¦ãŠã
        if not report_generator.openai_client:
            report_generator.initialize_openai(os.getenv("OPENAI_API_KEY"))
    else:
        st.warning("OpenAI APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆæ©Ÿèƒ½ã¯åˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚")

    st.markdown("---")
    st.subheader("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰")
    st.info("AIã®å¿œç­”ã‚¹ã‚¿ã‚¤ãƒ«ã‚„å°‚é–€ç”¨èªã‚’èª¿æ•´ã™ã‚‹ãŸã‚ã®å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ï¼ˆCSVå½¢å¼ï¼‰ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã§ãã¾ã™ã€‚æ—¢å­˜ã®CSVã‚’åŸºã«ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’è¡Œã†å ´åˆã«ä½¿ç”¨ã—ã¾ã™ã€‚")

    uploaded_file = st.file_uploader("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰", type=["csv"])

    if uploaded_file:
        if report_generator.load_training_data(uploaded_file):
            st.success("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ãŒæ­£å¸¸ã«èª­ã¿è¾¼ã¾ã‚Œã¾ã—ãŸã€‚")
            st.dataframe(report_generator.training_data.head()) # æœ€åˆã®5è¡Œã‚’è¡¨ç¤º
        else:
            st.error("å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸã€‚CSVãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")

# --- ãƒ¡ã‚¤ãƒ³ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ­ã‚¸ãƒƒã‚¯ ---

# ã‚µã‚¤ãƒ‰ãƒãƒ¼ãƒ¡ãƒ‹ãƒ¥ãƒ¼
with st.sidebar:
    st.image("https://www.streamlit.io/images/brand/streamlit-mark-color.svg", width=50)
    st.title("ã‚¢ãƒ‘ãƒ¬ãƒ«åº—èˆ—é€±æ¬¡ãƒ¬ãƒãƒ¼ãƒˆã‚·ã‚¹ãƒ†ãƒ ")
    st.markdown("---")
    
    menu_options = {
        "ãƒ¬ãƒãƒ¼ãƒˆä½œæˆ": show_report_creation_page,
        "ãƒ¬ãƒãƒ¼ãƒˆå±¥æ­´": show_report_history_page,
        "AIå­¦ç¿’çŠ¶æ³": show_learning_status_page,
        "è¨­å®š": show_settings_page
    }

    selected_menu = st.radio("ãƒ¡ãƒ‹ãƒ¥ãƒ¼", list(menu_options.keys()))

    st.markdown("---")
    st.write("Developed with â¤ï¸ by Streamlit & AI")

# é¸æŠã•ã‚ŒãŸãƒ¡ãƒ‹ãƒ¥ãƒ¼ã«å¿œã˜ãŸãƒšãƒ¼ã‚¸ã‚’è¡¨ç¤º
if selected_menu:
    menu_options[selected_menu]()

# åˆæœŸãƒ­ãƒ¼ãƒ‰æ™‚ã«APIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã‚Œã°ãƒ¬ãƒãƒ¼ãƒˆã‚¸ã‚§ãƒãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’åˆæœŸåŒ–
if "openai_api_key" in st.session_state and st.session_state["openai_api_key"] and not report_generator.openai_client:
    report_generator.initialize_openai(st.session_state["openai_api_key"])
elif os.getenv("OPENAI_API_KEY") and not report_generator.openai_client:
    report_generator.initialize_openai(os.getenv("OPENAI_API_KEY"))